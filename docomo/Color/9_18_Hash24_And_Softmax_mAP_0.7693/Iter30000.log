Log file created at: 2017/09/18 18:08:55
Running on machine: img08
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0918 18:08:55.430104 24660 caffe.cpp:185] Using GPUs 1
I0918 18:08:55.437115 24660 caffe.cpp:190] GPU 1: GeForce GTX TITAN Black
I0918 18:08:55.925673 24660 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.0001
display: 100
max_iter: 30000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0004
snapshot: 1000
snapshot_prefix: "COLOR/color_alexnet_f24"
solver_mode: GPU
device_id: 1
net: "COLOR/finetune_alexnet_model.prototxt"
test_initialization: true
average_loss: 100
stepvalue: 15000
I0918 18:08:55.926038 24660 solver.cpp:91] Creating training net from net file: COLOR/finetune_alexnet_model.prototxt
I0918 18:08:55.926890 24660 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0918 18:08:55.926961 24660 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_at_1_Color
I0918 18:08:55.927235 24660 net.cpp:49] Initializing net from parameters: 
name: "docomo_AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
  }
  data_param {
    source: "COLOR/color_train_lmdb"
    batch_size: 30
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc_binary_Color_f24"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc_binary_Color_f24"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 24
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "fc_classification_Color"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc_classification_Color"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "loss_hashing"
  type: "HashingLoss"
  bottom: "fc_binary_Color_f24"
  bottom: "label"
  top: "loss_hashing"
  loss_weight: 0.4
  hashing_loss_param {
    bi_margin: 48
    tradeoff: 0.01
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_classification_Color"
  bottom: "label"
  top: "loss"
}
I0918 18:08:55.930023 24660 layer_factory.hpp:77] Creating layer data
I0918 18:08:55.930672 24660 net.cpp:91] Creating Layer data
I0918 18:08:55.930713 24660 net.cpp:399] data -> data
I0918 18:08:55.930776 24660 net.cpp:399] data -> label
I0918 18:08:55.931655 24665 db_lmdb.cpp:38] Opened lmdb COLOR/color_train_lmdb
I0918 18:08:55.990995 24660 data_layer.cpp:41] output data size: 30,3,224,224
I0918 18:08:56.035121 24660 net.cpp:141] Setting up data
I0918 18:08:56.035215 24660 net.cpp:148] Top shape: 30 3 224 224 (4515840)
I0918 18:08:56.035251 24660 net.cpp:148] Top shape: 30 1 1 1 (30)
I0918 18:08:56.035279 24660 net.cpp:156] Memory required for data: 18063480
I0918 18:08:56.035315 24660 layer_factory.hpp:77] Creating layer label_data_1_split
I0918 18:08:56.035357 24660 net.cpp:91] Creating Layer label_data_1_split
I0918 18:08:56.035388 24660 net.cpp:425] label_data_1_split <- label
I0918 18:08:56.035434 24660 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0918 18:08:56.035473 24660 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0918 18:08:56.035558 24660 net.cpp:141] Setting up label_data_1_split
I0918 18:08:56.035589 24660 net.cpp:148] Top shape: 30 1 1 1 (30)
I0918 18:08:56.035617 24660 net.cpp:148] Top shape: 30 1 1 1 (30)
I0918 18:08:56.035641 24660 net.cpp:156] Memory required for data: 18063720
I0918 18:08:56.035666 24660 layer_factory.hpp:77] Creating layer conv1
I0918 18:08:56.035719 24660 net.cpp:91] Creating Layer conv1
I0918 18:08:56.035743 24660 net.cpp:425] conv1 <- data
I0918 18:08:56.035779 24660 net.cpp:399] conv1 -> conv1
I0918 18:08:56.038938 24660 net.cpp:141] Setting up conv1
I0918 18:08:56.038976 24660 net.cpp:148] Top shape: 30 96 54 54 (8398080)
I0918 18:08:56.039041 24660 net.cpp:156] Memory required for data: 51656040
I0918 18:08:56.039094 24660 layer_factory.hpp:77] Creating layer relu1
I0918 18:08:56.039127 24660 net.cpp:91] Creating Layer relu1
I0918 18:08:56.039152 24660 net.cpp:425] relu1 <- conv1
I0918 18:08:56.039186 24660 net.cpp:386] relu1 -> conv1 (in-place)
I0918 18:08:56.039221 24660 net.cpp:141] Setting up relu1
I0918 18:08:56.039247 24660 net.cpp:148] Top shape: 30 96 54 54 (8398080)
I0918 18:08:56.039270 24660 net.cpp:156] Memory required for data: 85248360
I0918 18:08:56.039295 24660 layer_factory.hpp:77] Creating layer norm1
I0918 18:08:56.039330 24660 net.cpp:91] Creating Layer norm1
I0918 18:08:56.039352 24660 net.cpp:425] norm1 <- conv1
I0918 18:08:56.039381 24660 net.cpp:399] norm1 -> norm1
I0918 18:08:56.039459 24660 net.cpp:141] Setting up norm1
I0918 18:08:56.039489 24660 net.cpp:148] Top shape: 30 96 54 54 (8398080)
I0918 18:08:56.039515 24660 net.cpp:156] Memory required for data: 118840680
I0918 18:08:56.039538 24660 layer_factory.hpp:77] Creating layer pool1
I0918 18:08:56.039572 24660 net.cpp:91] Creating Layer pool1
I0918 18:08:56.039595 24660 net.cpp:425] pool1 <- norm1
I0918 18:08:56.039625 24660 net.cpp:399] pool1 -> pool1
I0918 18:08:56.039707 24660 net.cpp:141] Setting up pool1
I0918 18:08:56.039737 24660 net.cpp:148] Top shape: 30 96 27 27 (2099520)
I0918 18:08:56.039763 24660 net.cpp:156] Memory required for data: 127238760
I0918 18:08:56.039788 24660 layer_factory.hpp:77] Creating layer conv2
I0918 18:08:56.039829 24660 net.cpp:91] Creating Layer conv2
I0918 18:08:56.039852 24660 net.cpp:425] conv2 <- pool1
I0918 18:08:56.039885 24660 net.cpp:399] conv2 -> conv2
I0918 18:08:56.053048 24660 net.cpp:141] Setting up conv2
I0918 18:08:56.053109 24660 net.cpp:148] Top shape: 30 256 27 27 (5598720)
I0918 18:08:56.053150 24660 net.cpp:156] Memory required for data: 149633640
I0918 18:08:56.053195 24660 layer_factory.hpp:77] Creating layer relu2
I0918 18:08:56.053232 24660 net.cpp:91] Creating Layer relu2
I0918 18:08:56.053259 24660 net.cpp:425] relu2 <- conv2
I0918 18:08:56.053292 24660 net.cpp:386] relu2 -> conv2 (in-place)
I0918 18:08:56.053325 24660 net.cpp:141] Setting up relu2
I0918 18:08:56.053352 24660 net.cpp:148] Top shape: 30 256 27 27 (5598720)
I0918 18:08:56.053376 24660 net.cpp:156] Memory required for data: 172028520
I0918 18:08:56.053401 24660 layer_factory.hpp:77] Creating layer norm2
I0918 18:08:56.053439 24660 net.cpp:91] Creating Layer norm2
I0918 18:08:56.053464 24660 net.cpp:425] norm2 <- conv2
I0918 18:08:56.053493 24660 net.cpp:399] norm2 -> norm2
I0918 18:08:56.053567 24660 net.cpp:141] Setting up norm2
I0918 18:08:56.053597 24660 net.cpp:148] Top shape: 30 256 27 27 (5598720)
I0918 18:08:56.053630 24660 net.cpp:156] Memory required for data: 194423400
I0918 18:08:56.053663 24660 layer_factory.hpp:77] Creating layer pool2
I0918 18:08:56.053696 24660 net.cpp:91] Creating Layer pool2
I0918 18:08:56.053722 24660 net.cpp:425] pool2 <- norm2
I0918 18:08:56.053761 24660 net.cpp:399] pool2 -> pool2
I0918 18:08:56.053833 24660 net.cpp:141] Setting up pool2
I0918 18:08:56.053864 24660 net.cpp:148] Top shape: 30 256 13 13 (1297920)
I0918 18:08:56.053889 24660 net.cpp:156] Memory required for data: 199615080
I0918 18:08:56.053912 24660 layer_factory.hpp:77] Creating layer conv3
I0918 18:08:56.053953 24660 net.cpp:91] Creating Layer conv3
I0918 18:08:56.053982 24660 net.cpp:425] conv3 <- pool2
I0918 18:08:56.054013 24660 net.cpp:399] conv3 -> conv3
I0918 18:08:56.089110 24660 net.cpp:141] Setting up conv3
I0918 18:08:56.089179 24660 net.cpp:148] Top shape: 30 384 13 13 (1946880)
I0918 18:08:56.089203 24660 net.cpp:156] Memory required for data: 207402600
I0918 18:08:56.089252 24660 layer_factory.hpp:77] Creating layer relu3
I0918 18:08:56.089290 24660 net.cpp:91] Creating Layer relu3
I0918 18:08:56.089316 24660 net.cpp:425] relu3 <- conv3
I0918 18:08:56.089349 24660 net.cpp:386] relu3 -> conv3 (in-place)
I0918 18:08:56.089385 24660 net.cpp:141] Setting up relu3
I0918 18:08:56.089452 24660 net.cpp:148] Top shape: 30 384 13 13 (1946880)
I0918 18:08:56.089478 24660 net.cpp:156] Memory required for data: 215190120
I0918 18:08:56.089504 24660 layer_factory.hpp:77] Creating layer conv4
I0918 18:08:56.089550 24660 net.cpp:91] Creating Layer conv4
I0918 18:08:56.089576 24660 net.cpp:425] conv4 <- conv3
I0918 18:08:56.089607 24660 net.cpp:399] conv4 -> conv4
I0918 18:08:56.116094 24660 net.cpp:141] Setting up conv4
I0918 18:08:56.116161 24660 net.cpp:148] Top shape: 30 384 13 13 (1946880)
I0918 18:08:56.116185 24660 net.cpp:156] Memory required for data: 222977640
I0918 18:08:56.116225 24660 layer_factory.hpp:77] Creating layer relu4
I0918 18:08:56.116257 24660 net.cpp:91] Creating Layer relu4
I0918 18:08:56.116284 24660 net.cpp:425] relu4 <- conv4
I0918 18:08:56.116317 24660 net.cpp:386] relu4 -> conv4 (in-place)
I0918 18:08:56.116350 24660 net.cpp:141] Setting up relu4
I0918 18:08:56.116376 24660 net.cpp:148] Top shape: 30 384 13 13 (1946880)
I0918 18:08:56.116400 24660 net.cpp:156] Memory required for data: 230765160
I0918 18:08:56.116422 24660 layer_factory.hpp:77] Creating layer conv5
I0918 18:08:56.116462 24660 net.cpp:91] Creating Layer conv5
I0918 18:08:56.116484 24660 net.cpp:425] conv5 <- conv4
I0918 18:08:56.116519 24660 net.cpp:399] conv5 -> conv5
I0918 18:08:56.133744 24660 net.cpp:141] Setting up conv5
I0918 18:08:56.133785 24660 net.cpp:148] Top shape: 30 256 13 13 (1297920)
I0918 18:08:56.133811 24660 net.cpp:156] Memory required for data: 235956840
I0918 18:08:56.133852 24660 layer_factory.hpp:77] Creating layer relu5
I0918 18:08:56.133879 24660 net.cpp:91] Creating Layer relu5
I0918 18:08:56.133904 24660 net.cpp:425] relu5 <- conv5
I0918 18:08:56.133934 24660 net.cpp:386] relu5 -> conv5 (in-place)
I0918 18:08:56.133970 24660 net.cpp:141] Setting up relu5
I0918 18:08:56.133997 24660 net.cpp:148] Top shape: 30 256 13 13 (1297920)
I0918 18:08:56.134021 24660 net.cpp:156] Memory required for data: 241148520
I0918 18:08:56.134044 24660 layer_factory.hpp:77] Creating layer pool5
I0918 18:08:56.134081 24660 net.cpp:91] Creating Layer pool5
I0918 18:08:56.134104 24660 net.cpp:425] pool5 <- conv5
I0918 18:08:56.134132 24660 net.cpp:399] pool5 -> pool5
I0918 18:08:56.134203 24660 net.cpp:141] Setting up pool5
I0918 18:08:56.134232 24660 net.cpp:148] Top shape: 30 256 6 6 (276480)
I0918 18:08:56.134256 24660 net.cpp:156] Memory required for data: 242254440
I0918 18:08:56.134280 24660 layer_factory.hpp:77] Creating layer fc6
I0918 18:08:56.134318 24660 net.cpp:91] Creating Layer fc6
I0918 18:08:56.134342 24660 net.cpp:425] fc6 <- pool5
I0918 18:08:56.134371 24660 net.cpp:399] fc6 -> fc6
I0918 18:08:57.569658 24660 net.cpp:141] Setting up fc6
I0918 18:08:57.569743 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:57.569782 24660 net.cpp:156] Memory required for data: 242745960
I0918 18:08:57.569829 24660 layer_factory.hpp:77] Creating layer relu6
I0918 18:08:57.569870 24660 net.cpp:91] Creating Layer relu6
I0918 18:08:57.569900 24660 net.cpp:425] relu6 <- fc6
I0918 18:08:57.569934 24660 net.cpp:386] relu6 -> fc6 (in-place)
I0918 18:08:57.569974 24660 net.cpp:141] Setting up relu6
I0918 18:08:57.570000 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:57.570024 24660 net.cpp:156] Memory required for data: 243237480
I0918 18:08:57.570050 24660 layer_factory.hpp:77] Creating layer drop6
I0918 18:08:57.570087 24660 net.cpp:91] Creating Layer drop6
I0918 18:08:57.570111 24660 net.cpp:425] drop6 <- fc6
I0918 18:08:57.570139 24660 net.cpp:386] drop6 -> fc6 (in-place)
I0918 18:08:57.570222 24660 net.cpp:141] Setting up drop6
I0918 18:08:57.570250 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:57.570276 24660 net.cpp:156] Memory required for data: 243729000
I0918 18:08:57.570299 24660 layer_factory.hpp:77] Creating layer fc7
I0918 18:08:57.570332 24660 net.cpp:91] Creating Layer fc7
I0918 18:08:57.570353 24660 net.cpp:425] fc7 <- fc6
I0918 18:08:57.570385 24660 net.cpp:399] fc7 -> fc7
I0918 18:08:58.207841 24660 net.cpp:141] Setting up fc7
I0918 18:08:58.207912 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:58.207979 24660 net.cpp:156] Memory required for data: 244220520
I0918 18:08:58.208019 24660 layer_factory.hpp:77] Creating layer relu7
I0918 18:08:58.208055 24660 net.cpp:91] Creating Layer relu7
I0918 18:08:58.208081 24660 net.cpp:425] relu7 <- fc7
I0918 18:08:58.208117 24660 net.cpp:386] relu7 -> fc7 (in-place)
I0918 18:08:58.208153 24660 net.cpp:141] Setting up relu7
I0918 18:08:58.208178 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:58.208200 24660 net.cpp:156] Memory required for data: 244712040
I0918 18:08:58.208225 24660 layer_factory.hpp:77] Creating layer drop7
I0918 18:08:58.208256 24660 net.cpp:91] Creating Layer drop7
I0918 18:08:58.208277 24660 net.cpp:425] drop7 <- fc7
I0918 18:08:58.208309 24660 net.cpp:386] drop7 -> fc7 (in-place)
I0918 18:08:58.208364 24660 net.cpp:141] Setting up drop7
I0918 18:08:58.208391 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:58.208415 24660 net.cpp:156] Memory required for data: 245203560
I0918 18:08:58.208441 24660 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I0918 18:08:58.208469 24660 net.cpp:91] Creating Layer fc7_drop7_0_split
I0918 18:08:58.208493 24660 net.cpp:425] fc7_drop7_0_split <- fc7
I0918 18:08:58.208526 24660 net.cpp:399] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0918 18:08:58.208565 24660 net.cpp:399] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0918 18:08:58.208634 24660 net.cpp:141] Setting up fc7_drop7_0_split
I0918 18:08:58.208664 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:58.208690 24660 net.cpp:148] Top shape: 30 4096 (122880)
I0918 18:08:58.208714 24660 net.cpp:156] Memory required for data: 246186600
I0918 18:08:58.208736 24660 layer_factory.hpp:77] Creating layer fc_binary_Color_f24
I0918 18:08:58.208770 24660 net.cpp:91] Creating Layer fc_binary_Color_f24
I0918 18:08:58.208792 24660 net.cpp:425] fc_binary_Color_f24 <- fc7_drop7_0_split_0
I0918 18:08:58.208822 24660 net.cpp:399] fc_binary_Color_f24 -> fc_binary_Color_f24
I0918 18:08:58.213189 24660 net.cpp:141] Setting up fc_binary_Color_f24
I0918 18:08:58.213224 24660 net.cpp:148] Top shape: 30 24 (720)
I0918 18:08:58.213253 24660 net.cpp:156] Memory required for data: 246189480
I0918 18:08:58.213286 24660 layer_factory.hpp:77] Creating layer fc_classification_Color
I0918 18:08:58.213323 24660 net.cpp:91] Creating Layer fc_classification_Color
I0918 18:08:58.213348 24660 net.cpp:425] fc_classification_Color <- fc7_drop7_0_split_1
I0918 18:08:58.213378 24660 net.cpp:399] fc_classification_Color -> fc_classification_Color
I0918 18:08:58.214725 24660 net.cpp:141] Setting up fc_classification_Color
I0918 18:08:58.214758 24660 net.cpp:148] Top shape: 30 8 (240)
I0918 18:08:58.214782 24660 net.cpp:156] Memory required for data: 246190440
I0918 18:08:58.214823 24660 layer_factory.hpp:77] Creating layer loss_hashing
I0918 18:08:58.214864 24660 net.cpp:91] Creating Layer loss_hashing
I0918 18:08:58.214886 24660 net.cpp:425] loss_hashing <- fc_binary_Color_f24
I0918 18:08:58.214912 24660 net.cpp:425] loss_hashing <- label_data_1_split_0
I0918 18:08:58.214941 24660 net.cpp:399] loss_hashing -> loss_hashing
I0918 18:08:58.215054 24660 net.cpp:141] Setting up loss_hashing
I0918 18:08:58.215083 24660 net.cpp:148] Top shape: (1)
I0918 18:08:58.215107 24660 net.cpp:151]     with loss weight 0.4
I0918 18:08:58.215171 24660 net.cpp:156] Memory required for data: 246190444
I0918 18:08:58.215196 24660 layer_factory.hpp:77] Creating layer loss
I0918 18:08:58.215232 24660 net.cpp:91] Creating Layer loss
I0918 18:08:58.215255 24660 net.cpp:425] loss <- fc_classification_Color
I0918 18:08:58.215281 24660 net.cpp:425] loss <- label_data_1_split_1
I0918 18:08:58.215309 24660 net.cpp:399] loss -> loss
I0918 18:08:58.215344 24660 layer_factory.hpp:77] Creating layer loss
I0918 18:08:58.215476 24660 net.cpp:141] Setting up loss
I0918 18:08:58.215504 24660 net.cpp:148] Top shape: (1)
I0918 18:08:58.215528 24660 net.cpp:151]     with loss weight 1
I0918 18:08:58.215554 24660 net.cpp:156] Memory required for data: 246190448
I0918 18:08:58.215595 24660 net.cpp:217] loss needs backward computation.
I0918 18:08:58.215621 24660 net.cpp:217] loss_hashing needs backward computation.
I0918 18:08:58.215647 24660 net.cpp:217] fc_classification_Color needs backward computation.
I0918 18:08:58.215672 24660 net.cpp:217] fc_binary_Color_f24 needs backward computation.
I0918 18:08:58.215697 24660 net.cpp:217] fc7_drop7_0_split needs backward computation.
I0918 18:08:58.215721 24660 net.cpp:217] drop7 needs backward computation.
I0918 18:08:58.215745 24660 net.cpp:217] relu7 needs backward computation.
I0918 18:08:58.215768 24660 net.cpp:217] fc7 needs backward computation.
I0918 18:08:58.215792 24660 net.cpp:217] drop6 needs backward computation.
I0918 18:08:58.215816 24660 net.cpp:217] relu6 needs backward computation.
I0918 18:08:58.215839 24660 net.cpp:217] fc6 needs backward computation.
I0918 18:08:58.215863 24660 net.cpp:217] pool5 needs backward computation.
I0918 18:08:58.215888 24660 net.cpp:217] relu5 needs backward computation.
I0918 18:08:58.215910 24660 net.cpp:217] conv5 needs backward computation.
I0918 18:08:58.215934 24660 net.cpp:217] relu4 needs backward computation.
I0918 18:08:58.215956 24660 net.cpp:217] conv4 needs backward computation.
I0918 18:08:58.215981 24660 net.cpp:217] relu3 needs backward computation.
I0918 18:08:58.216004 24660 net.cpp:217] conv3 needs backward computation.
I0918 18:08:58.216028 24660 net.cpp:217] pool2 needs backward computation.
I0918 18:08:58.216053 24660 net.cpp:217] norm2 needs backward computation.
I0918 18:08:58.216076 24660 net.cpp:217] relu2 needs backward computation.
I0918 18:08:58.216102 24660 net.cpp:217] conv2 needs backward computation.
I0918 18:08:58.216126 24660 net.cpp:217] pool1 needs backward computation.
I0918 18:08:58.216150 24660 net.cpp:217] norm1 needs backward computation.
I0918 18:08:58.216174 24660 net.cpp:217] relu1 needs backward computation.
I0918 18:08:58.216197 24660 net.cpp:217] conv1 needs backward computation.
I0918 18:08:58.216223 24660 net.cpp:219] label_data_1_split does not need backward computation.
I0918 18:08:58.216253 24660 net.cpp:219] data does not need backward computation.
I0918 18:08:58.216275 24660 net.cpp:261] This network produces output loss
I0918 18:08:58.216300 24660 net.cpp:261] This network produces output loss_hashing
I0918 18:08:58.216347 24660 net.cpp:274] Network initialization done.
I0918 18:08:58.217247 24660 solver.cpp:181] Creating test net (#0) specified by net file: COLOR/finetune_alexnet_model.prototxt
I0918 18:08:58.217329 24660 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0918 18:08:58.217653 24660 net.cpp:49] Initializing net from parameters: 
name: "docomo_AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
  }
  data_param {
    source: "COLOR/color_val_lmdb"
    batch_size: 40
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc_binary_Color_f24"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc_binary_Color_f24"
  param {
    lr_mult: 10
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 24
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "fc_classification_Color"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc_classification_Color"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.05
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "accuracy_at_1_Color"
  type: "Accuracy"
  bottom: "fc_classification_Color"
  bottom: "label"
  top: "accuracy_at_1_Color"
  include {
    phase: TEST
  }
}
layer {
  name: "loss_hashing"
  type: "HashingLoss"
  bottom: "fc_binary_Color_f24"
  bottom: "label"
  top: "loss_hashing"
  loss_weight: 0.4
  hashing_loss_param {
    bi_margin: 48
    tradeoff: 0.01
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_classification_Color"
  bottom: "label"
  top: "loss"
}
I0918 18:08:58.220392 24660 layer_factory.hpp:77] Creating layer data
I0918 18:08:58.220544 24660 net.cpp:91] Creating Layer data
I0918 18:08:58.220597 24660 net.cpp:399] data -> data
I0918 18:08:58.220633 24660 net.cpp:399] data -> label
I0918 18:08:58.221834 24667 db_lmdb.cpp:38] Opened lmdb COLOR/color_val_lmdb
I0918 18:08:58.222326 24660 data_layer.cpp:41] output data size: 40,3,224,224
I0918 18:08:58.280257 24660 net.cpp:141] Setting up data
I0918 18:08:58.280336 24660 net.cpp:148] Top shape: 40 3 224 224 (6021120)
I0918 18:08:58.280381 24660 net.cpp:148] Top shape: 40 1 1 1 (40)
I0918 18:08:58.280408 24660 net.cpp:156] Memory required for data: 24084640
I0918 18:08:58.280438 24660 layer_factory.hpp:77] Creating layer label_data_1_split
I0918 18:08:58.280478 24660 net.cpp:91] Creating Layer label_data_1_split
I0918 18:08:58.280503 24660 net.cpp:425] label_data_1_split <- label
I0918 18:08:58.280541 24660 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0918 18:08:58.280578 24660 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0918 18:08:58.280608 24660 net.cpp:399] label_data_1_split -> label_data_1_split_2
I0918 18:08:58.280716 24660 net.cpp:141] Setting up label_data_1_split
I0918 18:08:58.280746 24660 net.cpp:148] Top shape: 40 1 1 1 (40)
I0918 18:08:58.280776 24660 net.cpp:148] Top shape: 40 1 1 1 (40)
I0918 18:08:58.280803 24660 net.cpp:148] Top shape: 40 1 1 1 (40)
I0918 18:08:58.280827 24660 net.cpp:156] Memory required for data: 24085120
I0918 18:08:58.280853 24660 layer_factory.hpp:77] Creating layer conv1
I0918 18:08:58.280899 24660 net.cpp:91] Creating Layer conv1
I0918 18:08:58.280923 24660 net.cpp:425] conv1 <- data
I0918 18:08:58.280956 24660 net.cpp:399] conv1 -> conv1
I0918 18:08:58.288414 24660 net.cpp:141] Setting up conv1
I0918 18:08:58.288447 24660 net.cpp:148] Top shape: 40 96 54 54 (11197440)
I0918 18:08:58.288473 24660 net.cpp:156] Memory required for data: 68874880
I0918 18:08:58.288514 24660 layer_factory.hpp:77] Creating layer relu1
I0918 18:08:58.288544 24660 net.cpp:91] Creating Layer relu1
I0918 18:08:58.288576 24660 net.cpp:425] relu1 <- conv1
I0918 18:08:58.288607 24660 net.cpp:386] relu1 -> conv1 (in-place)
I0918 18:08:58.288640 24660 net.cpp:141] Setting up relu1
I0918 18:08:58.288667 24660 net.cpp:148] Top shape: 40 96 54 54 (11197440)
I0918 18:08:58.288691 24660 net.cpp:156] Memory required for data: 113664640
I0918 18:08:58.288717 24660 layer_factory.hpp:77] Creating layer norm1
I0918 18:08:58.288749 24660 net.cpp:91] Creating Layer norm1
I0918 18:08:58.288772 24660 net.cpp:425] norm1 <- conv1
I0918 18:08:58.288805 24660 net.cpp:399] norm1 -> norm1
I0918 18:08:58.288877 24660 net.cpp:141] Setting up norm1
I0918 18:08:58.288906 24660 net.cpp:148] Top shape: 40 96 54 54 (11197440)
I0918 18:08:58.288930 24660 net.cpp:156] Memory required for data: 158454400
I0918 18:08:58.288956 24660 layer_factory.hpp:77] Creating layer pool1
I0918 18:08:58.288990 24660 net.cpp:91] Creating Layer pool1
I0918 18:08:58.289014 24660 net.cpp:425] pool1 <- norm1
I0918 18:08:58.289047 24660 net.cpp:399] pool1 -> pool1
I0918 18:08:58.289117 24660 net.cpp:141] Setting up pool1
I0918 18:08:58.289146 24660 net.cpp:148] Top shape: 40 96 27 27 (2799360)
I0918 18:08:58.289171 24660 net.cpp:156] Memory required for data: 169651840
I0918 18:08:58.289196 24660 layer_factory.hpp:77] Creating layer conv2
I0918 18:08:58.289235 24660 net.cpp:91] Creating Layer conv2
I0918 18:08:58.289259 24660 net.cpp:425] conv2 <- pool1
I0918 18:08:58.289294 24660 net.cpp:399] conv2 -> conv2
I0918 18:08:58.301810 24660 net.cpp:141] Setting up conv2
I0918 18:08:58.301864 24660 net.cpp:148] Top shape: 40 256 27 27 (7464960)
I0918 18:08:58.301901 24660 net.cpp:156] Memory required for data: 199511680
I0918 18:08:58.301944 24660 layer_factory.hpp:77] Creating layer relu2
I0918 18:08:58.302018 24660 net.cpp:91] Creating Layer relu2
I0918 18:08:58.302045 24660 net.cpp:425] relu2 <- conv2
I0918 18:08:58.302078 24660 net.cpp:386] relu2 -> conv2 (in-place)
I0918 18:08:58.302111 24660 net.cpp:141] Setting up relu2
I0918 18:08:58.302139 24660 net.cpp:148] Top shape: 40 256 27 27 (7464960)
I0918 18:08:58.302162 24660 net.cpp:156] Memory required for data: 229371520
I0918 18:08:58.302187 24660 layer_factory.hpp:77] Creating layer norm2
I0918 18:08:58.302224 24660 net.cpp:91] Creating Layer norm2
I0918 18:08:58.302248 24660 net.cpp:425] norm2 <- conv2
I0918 18:08:58.302283 24660 net.cpp:399] norm2 -> norm2
I0918 18:08:58.302356 24660 net.cpp:141] Setting up norm2
I0918 18:08:58.302386 24660 net.cpp:148] Top shape: 40 256 27 27 (7464960)
I0918 18:08:58.302412 24660 net.cpp:156] Memory required for data: 259231360
I0918 18:08:58.302436 24660 layer_factory.hpp:77] Creating layer pool2
I0918 18:08:58.302466 24660 net.cpp:91] Creating Layer pool2
I0918 18:08:58.302490 24660 net.cpp:425] pool2 <- norm2
I0918 18:08:58.302525 24660 net.cpp:399] pool2 -> pool2
I0918 18:08:58.302594 24660 net.cpp:141] Setting up pool2
I0918 18:08:58.302623 24660 net.cpp:148] Top shape: 40 256 13 13 (1730560)
I0918 18:08:58.302649 24660 net.cpp:156] Memory required for data: 266153600
I0918 18:08:58.302672 24660 layer_factory.hpp:77] Creating layer conv3
I0918 18:08:58.302727 24660 net.cpp:91] Creating Layer conv3
I0918 18:08:58.302752 24660 net.cpp:425] conv3 <- pool2
I0918 18:08:58.302784 24660 net.cpp:399] conv3 -> conv3
I0918 18:08:58.337929 24660 net.cpp:141] Setting up conv3
I0918 18:08:58.338014 24660 net.cpp:148] Top shape: 40 384 13 13 (2595840)
I0918 18:08:58.338039 24660 net.cpp:156] Memory required for data: 276536960
I0918 18:08:58.338095 24660 layer_factory.hpp:77] Creating layer relu3
I0918 18:08:58.338129 24660 net.cpp:91] Creating Layer relu3
I0918 18:08:58.338156 24660 net.cpp:425] relu3 <- conv3
I0918 18:08:58.338189 24660 net.cpp:386] relu3 -> conv3 (in-place)
I0918 18:08:58.338224 24660 net.cpp:141] Setting up relu3
I0918 18:08:58.338251 24660 net.cpp:148] Top shape: 40 384 13 13 (2595840)
I0918 18:08:58.338276 24660 net.cpp:156] Memory required for data: 286920320
I0918 18:08:58.338300 24660 layer_factory.hpp:77] Creating layer conv4
I0918 18:08:58.338340 24660 net.cpp:91] Creating Layer conv4
I0918 18:08:58.338366 24660 net.cpp:425] conv4 <- conv3
I0918 18:08:58.338402 24660 net.cpp:399] conv4 -> conv4
I0918 18:08:58.364905 24660 net.cpp:141] Setting up conv4
I0918 18:08:58.364972 24660 net.cpp:148] Top shape: 40 384 13 13 (2595840)
I0918 18:08:58.364997 24660 net.cpp:156] Memory required for data: 297303680
I0918 18:08:58.365036 24660 layer_factory.hpp:77] Creating layer relu4
I0918 18:08:58.365070 24660 net.cpp:91] Creating Layer relu4
I0918 18:08:58.365097 24660 net.cpp:425] relu4 <- conv4
I0918 18:08:58.365135 24660 net.cpp:386] relu4 -> conv4 (in-place)
I0918 18:08:58.365170 24660 net.cpp:141] Setting up relu4
I0918 18:08:58.365198 24660 net.cpp:148] Top shape: 40 384 13 13 (2595840)
I0918 18:08:58.365222 24660 net.cpp:156] Memory required for data: 307687040
I0918 18:08:58.365247 24660 layer_factory.hpp:77] Creating layer conv5
I0918 18:08:58.365288 24660 net.cpp:91] Creating Layer conv5
I0918 18:08:58.365312 24660 net.cpp:425] conv5 <- conv4
I0918 18:08:58.365344 24660 net.cpp:399] conv5 -> conv5
I0918 18:08:58.383250 24660 net.cpp:141] Setting up conv5
I0918 18:08:58.383311 24660 net.cpp:148] Top shape: 40 256 13 13 (1730560)
I0918 18:08:58.383335 24660 net.cpp:156] Memory required for data: 314609280
I0918 18:08:58.383379 24660 layer_factory.hpp:77] Creating layer relu5
I0918 18:08:58.383415 24660 net.cpp:91] Creating Layer relu5
I0918 18:08:58.383441 24660 net.cpp:425] relu5 <- conv5
I0918 18:08:58.383473 24660 net.cpp:386] relu5 -> conv5 (in-place)
I0918 18:08:58.383505 24660 net.cpp:141] Setting up relu5
I0918 18:08:58.383532 24660 net.cpp:148] Top shape: 40 256 13 13 (1730560)
I0918 18:08:58.383554 24660 net.cpp:156] Memory required for data: 321531520
I0918 18:08:58.383579 24660 layer_factory.hpp:77] Creating layer pool5
I0918 18:08:58.383649 24660 net.cpp:91] Creating Layer pool5
I0918 18:08:58.383672 24660 net.cpp:425] pool5 <- conv5
I0918 18:08:58.383705 24660 net.cpp:399] pool5 -> pool5
I0918 18:08:58.383780 24660 net.cpp:141] Setting up pool5
I0918 18:08:58.383810 24660 net.cpp:148] Top shape: 40 256 6 6 (368640)
I0918 18:08:58.383832 24660 net.cpp:156] Memory required for data: 323006080
I0918 18:08:58.383857 24660 layer_factory.hpp:77] Creating layer fc6
I0918 18:08:58.383893 24660 net.cpp:91] Creating Layer fc6
I0918 18:08:58.383915 24660 net.cpp:425] fc6 <- pool5
I0918 18:08:58.383947 24660 net.cpp:399] fc6 -> fc6
I0918 18:08:59.814774 24660 net.cpp:141] Setting up fc6
I0918 18:08:59.814848 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:08:59.814885 24660 net.cpp:156] Memory required for data: 323661440
I0918 18:08:59.814924 24660 layer_factory.hpp:77] Creating layer relu6
I0918 18:08:59.814957 24660 net.cpp:91] Creating Layer relu6
I0918 18:08:59.814982 24660 net.cpp:425] relu6 <- fc6
I0918 18:08:59.815021 24660 net.cpp:386] relu6 -> fc6 (in-place)
I0918 18:08:59.815054 24660 net.cpp:141] Setting up relu6
I0918 18:08:59.815079 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:08:59.815102 24660 net.cpp:156] Memory required for data: 324316800
I0918 18:08:59.815125 24660 layer_factory.hpp:77] Creating layer drop6
I0918 18:08:59.815155 24660 net.cpp:91] Creating Layer drop6
I0918 18:08:59.815177 24660 net.cpp:425] drop6 <- fc6
I0918 18:08:59.815204 24660 net.cpp:386] drop6 -> fc6 (in-place)
I0918 18:08:59.815260 24660 net.cpp:141] Setting up drop6
I0918 18:08:59.815289 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:08:59.815312 24660 net.cpp:156] Memory required for data: 324972160
I0918 18:08:59.815336 24660 layer_factory.hpp:77] Creating layer fc7
I0918 18:08:59.815382 24660 net.cpp:91] Creating Layer fc7
I0918 18:08:59.815405 24660 net.cpp:425] fc7 <- fc6
I0918 18:08:59.815436 24660 net.cpp:399] fc7 -> fc7
I0918 18:09:00.452756 24660 net.cpp:141] Setting up fc7
I0918 18:09:00.452844 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:09:00.452878 24660 net.cpp:156] Memory required for data: 325627520
I0918 18:09:00.452930 24660 layer_factory.hpp:77] Creating layer relu7
I0918 18:09:00.452971 24660 net.cpp:91] Creating Layer relu7
I0918 18:09:00.453002 24660 net.cpp:425] relu7 <- fc7
I0918 18:09:00.453033 24660 net.cpp:386] relu7 -> fc7 (in-place)
I0918 18:09:00.453069 24660 net.cpp:141] Setting up relu7
I0918 18:09:00.453094 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:09:00.453119 24660 net.cpp:156] Memory required for data: 326282880
I0918 18:09:00.453143 24660 layer_factory.hpp:77] Creating layer drop7
I0918 18:09:00.453179 24660 net.cpp:91] Creating Layer drop7
I0918 18:09:00.453202 24660 net.cpp:425] drop7 <- fc7
I0918 18:09:00.453230 24660 net.cpp:386] drop7 -> fc7 (in-place)
I0918 18:09:00.453305 24660 net.cpp:141] Setting up drop7
I0918 18:09:00.453331 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:09:00.453356 24660 net.cpp:156] Memory required for data: 326938240
I0918 18:09:00.453379 24660 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I0918 18:09:00.453408 24660 net.cpp:91] Creating Layer fc7_drop7_0_split
I0918 18:09:00.453430 24660 net.cpp:425] fc7_drop7_0_split <- fc7
I0918 18:09:00.453459 24660 net.cpp:399] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0918 18:09:00.453495 24660 net.cpp:399] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0918 18:09:00.453563 24660 net.cpp:141] Setting up fc7_drop7_0_split
I0918 18:09:00.453591 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:09:00.453619 24660 net.cpp:148] Top shape: 40 4096 (163840)
I0918 18:09:00.453649 24660 net.cpp:156] Memory required for data: 328248960
I0918 18:09:00.453675 24660 layer_factory.hpp:77] Creating layer fc_binary_Color_f24
I0918 18:09:00.453716 24660 net.cpp:91] Creating Layer fc_binary_Color_f24
I0918 18:09:00.453738 24660 net.cpp:425] fc_binary_Color_f24 <- fc7_drop7_0_split_0
I0918 18:09:00.453771 24660 net.cpp:399] fc_binary_Color_f24 -> fc_binary_Color_f24
I0918 18:09:00.457648 24660 net.cpp:141] Setting up fc_binary_Color_f24
I0918 18:09:00.457695 24660 net.cpp:148] Top shape: 40 24 (960)
I0918 18:09:00.457722 24660 net.cpp:156] Memory required for data: 328252800
I0918 18:09:00.457754 24660 layer_factory.hpp:77] Creating layer fc_classification_Color
I0918 18:09:00.457787 24660 net.cpp:91] Creating Layer fc_classification_Color
I0918 18:09:00.457811 24660 net.cpp:425] fc_classification_Color <- fc7_drop7_0_split_1
I0918 18:09:00.457840 24660 net.cpp:399] fc_classification_Color -> fc_classification_Color
I0918 18:09:00.459177 24660 net.cpp:141] Setting up fc_classification_Color
I0918 18:09:00.459208 24660 net.cpp:148] Top shape: 40 8 (320)
I0918 18:09:00.459233 24660 net.cpp:156] Memory required for data: 328254080
I0918 18:09:00.459280 24660 layer_factory.hpp:77] Creating layer fc_classification_Color_fc_classification_Color_0_split
I0918 18:09:00.459307 24660 net.cpp:91] Creating Layer fc_classification_Color_fc_classification_Color_0_split
I0918 18:09:00.459333 24660 net.cpp:425] fc_classification_Color_fc_classification_Color_0_split <- fc_classification_Color
I0918 18:09:00.459365 24660 net.cpp:399] fc_classification_Color_fc_classification_Color_0_split -> fc_classification_Color_fc_classification_Color_0_split_0
I0918 18:09:00.459396 24660 net.cpp:399] fc_classification_Color_fc_classification_Color_0_split -> fc_classification_Color_fc_classification_Color_0_split_1
I0918 18:09:00.459468 24660 net.cpp:141] Setting up fc_classification_Color_fc_classification_Color_0_split
I0918 18:09:00.459501 24660 net.cpp:148] Top shape: 40 8 (320)
I0918 18:09:00.459528 24660 net.cpp:148] Top shape: 40 8 (320)
I0918 18:09:00.459552 24660 net.cpp:156] Memory required for data: 328256640
I0918 18:09:00.459574 24660 layer_factory.hpp:77] Creating layer accuracy_at_1_Color
I0918 18:09:00.459612 24660 net.cpp:91] Creating Layer accuracy_at_1_Color
I0918 18:09:00.459635 24660 net.cpp:425] accuracy_at_1_Color <- fc_classification_Color_fc_classification_Color_0_split_0
I0918 18:09:00.459661 24660 net.cpp:425] accuracy_at_1_Color <- label_data_1_split_0
I0918 18:09:00.459692 24660 net.cpp:399] accuracy_at_1_Color -> accuracy_at_1_Color
I0918 18:09:00.459731 24660 net.cpp:141] Setting up accuracy_at_1_Color
I0918 18:09:00.459758 24660 net.cpp:148] Top shape: (1)
I0918 18:09:00.459780 24660 net.cpp:156] Memory required for data: 328256644
I0918 18:09:00.459803 24660 layer_factory.hpp:77] Creating layer loss_hashing
I0918 18:09:00.459838 24660 net.cpp:91] Creating Layer loss_hashing
I0918 18:09:00.459861 24660 net.cpp:425] loss_hashing <- fc_binary_Color_f24
I0918 18:09:00.459888 24660 net.cpp:425] loss_hashing <- label_data_1_split_1
I0918 18:09:00.459916 24660 net.cpp:399] loss_hashing -> loss_hashing
I0918 18:09:00.460023 24660 net.cpp:141] Setting up loss_hashing
I0918 18:09:00.460052 24660 net.cpp:148] Top shape: (1)
I0918 18:09:00.460078 24660 net.cpp:151]     with loss weight 0.4
I0918 18:09:00.460121 24660 net.cpp:156] Memory required for data: 328256648
I0918 18:09:00.460146 24660 layer_factory.hpp:77] Creating layer loss
I0918 18:09:00.460180 24660 net.cpp:91] Creating Layer loss
I0918 18:09:00.460203 24660 net.cpp:425] loss <- fc_classification_Color_fc_classification_Color_0_split_1
I0918 18:09:00.460229 24660 net.cpp:425] loss <- label_data_1_split_2
I0918 18:09:00.460263 24660 net.cpp:399] loss -> loss
I0918 18:09:00.460296 24660 layer_factory.hpp:77] Creating layer loss
I0918 18:09:00.460417 24660 net.cpp:141] Setting up loss
I0918 18:09:00.460445 24660 net.cpp:148] Top shape: (1)
I0918 18:09:00.460469 24660 net.cpp:151]     with loss weight 1
I0918 18:09:00.460496 24660 net.cpp:156] Memory required for data: 328256652
I0918 18:09:00.460532 24660 net.cpp:217] loss needs backward computation.
I0918 18:09:00.460557 24660 net.cpp:217] loss_hashing needs backward computation.
I0918 18:09:00.460582 24660 net.cpp:219] accuracy_at_1_Color does not need backward computation.
I0918 18:09:00.460608 24660 net.cpp:217] fc_classification_Color_fc_classification_Color_0_split needs backward computation.
I0918 18:09:00.460654 24660 net.cpp:217] fc_classification_Color needs backward computation.
I0918 18:09:00.460682 24660 net.cpp:217] fc_binary_Color_f24 needs backward computation.
I0918 18:09:00.460707 24660 net.cpp:217] fc7_drop7_0_split needs backward computation.
I0918 18:09:00.460732 24660 net.cpp:217] drop7 needs backward computation.
I0918 18:09:00.460757 24660 net.cpp:217] relu7 needs backward computation.
I0918 18:09:00.460781 24660 net.cpp:217] fc7 needs backward computation.
I0918 18:09:00.460806 24660 net.cpp:217] drop6 needs backward computation.
I0918 18:09:00.460830 24660 net.cpp:217] relu6 needs backward computation.
I0918 18:09:00.460867 24660 net.cpp:217] fc6 needs backward computation.
I0918 18:09:00.460891 24660 net.cpp:217] pool5 needs backward computation.
I0918 18:09:00.460916 24660 net.cpp:217] relu5 needs backward computation.
I0918 18:09:00.460938 24660 net.cpp:217] conv5 needs backward computation.
I0918 18:09:00.460963 24660 net.cpp:217] relu4 needs backward computation.
I0918 18:09:00.460985 24660 net.cpp:217] conv4 needs backward computation.
I0918 18:09:00.461009 24660 net.cpp:217] relu3 needs backward computation.
I0918 18:09:00.461032 24660 net.cpp:217] conv3 needs backward computation.
I0918 18:09:00.461060 24660 net.cpp:217] pool2 needs backward computation.
I0918 18:09:00.461083 24660 net.cpp:217] norm2 needs backward computation.
I0918 18:09:00.461107 24660 net.cpp:217] relu2 needs backward computation.
I0918 18:09:00.461132 24660 net.cpp:217] conv2 needs backward computation.
I0918 18:09:00.461158 24660 net.cpp:217] pool1 needs backward computation.
I0918 18:09:00.461181 24660 net.cpp:217] norm1 needs backward computation.
I0918 18:09:00.461205 24660 net.cpp:217] relu1 needs backward computation.
I0918 18:09:00.461230 24660 net.cpp:217] conv1 needs backward computation.
I0918 18:09:00.461254 24660 net.cpp:219] label_data_1_split does not need backward computation.
I0918 18:09:00.461279 24660 net.cpp:219] data does not need backward computation.
I0918 18:09:00.461303 24660 net.cpp:261] This network produces output accuracy_at_1_Color
I0918 18:09:00.461328 24660 net.cpp:261] This network produces output loss
I0918 18:09:00.461352 24660 net.cpp:261] This network produces output loss_hashing
I0918 18:09:00.461400 24660 net.cpp:274] Network initialization done.
I0918 18:09:00.461567 24660 solver.cpp:60] Solver scaffolding done.
I0918 18:09:00.462244 24660 caffe.cpp:129] Finetuning from COLOR/extra/color_alexnet_iter_50000.caffemodel
I0918 18:09:01.038085 24660 net.cpp:753] Ignoring source layer fc_binary_Color
I0918 18:09:01.038200 24660 net.cpp:753] Ignoring source layer loss_classification
I0918 18:09:01.614533 24660 net.cpp:753] Ignoring source layer fc_binary_Color
I0918 18:09:01.614665 24660 net.cpp:753] Ignoring source layer loss_classification
I0918 18:09:01.616451 24660 caffe.cpp:219] Starting Optimization
I0918 18:09:01.616492 24660 solver.cpp:279] Solving docomo_AlexNet
I0918 18:09:01.616518 24660 solver.cpp:280] Learning Rate Policy: multistep
I0918 18:09:01.618921 24660 solver.cpp:337] Iteration 0, Testing net (#0)
I0918 18:09:20.446425 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82925
I0918 18:09:20.446518 24660 solver.cpp:404]     Test net output #1: loss = 0.536612 (* 1 = 0.536612 loss)
I0918 18:09:20.446568 24660 solver.cpp:404]     Test net output #2: loss_hashing = 21.1323 (* 0.4 = 8.45292 loss)
I0918 18:09:20.639042 24660 solver.cpp:228] Iteration 0, loss = 8.65123
I0918 18:09:20.639120 24660 solver.cpp:244]     Train net output #0: loss = 0.222204 (* 1 = 0.222204 loss)
I0918 18:09:20.639161 24660 solver.cpp:244]     Train net output #1: loss_hashing = 21.0726 (* 0.4 = 8.42903 loss)
I0918 18:09:20.639219 24660 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0918 18:10:00.576048 24660 solver.cpp:228] Iteration 100, loss = 5.12461
I0918 18:10:00.576305 24660 solver.cpp:244]     Train net output #0: loss = 0.673464 (* 1 = 0.673464 loss)
I0918 18:10:00.576340 24660 solver.cpp:244]     Train net output #1: loss_hashing = 4.3565 (* 0.4 = 1.7426 loss)
I0918 18:10:00.576364 24660 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0918 18:10:40.446707 24660 solver.cpp:228] Iteration 200, loss = 1.62794
I0918 18:10:40.446931 24660 solver.cpp:244]     Train net output #0: loss = 0.126396 (* 1 = 0.126396 loss)
I0918 18:10:40.446961 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.2786 (* 0.4 = 0.911438 loss)
I0918 18:10:40.446977 24660 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0918 18:11:20.395728 24660 solver.cpp:228] Iteration 300, loss = 1.41674
I0918 18:11:20.395959 24660 solver.cpp:244]     Train net output #0: loss = 0.454497 (* 1 = 0.454497 loss)
I0918 18:11:20.395992 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.9784 (* 0.4 = 1.19136 loss)
I0918 18:11:20.396006 24660 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0918 18:12:00.336024 24660 solver.cpp:228] Iteration 400, loss = 1.3385
I0918 18:12:00.336273 24660 solver.cpp:244]     Train net output #0: loss = 0.249073 (* 1 = 0.249073 loss)
I0918 18:12:00.336304 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.59969 (* 0.4 = 1.03988 loss)
I0918 18:12:00.336320 24660 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0918 18:12:40.314779 24660 solver.cpp:228] Iteration 500, loss = 1.4551
I0918 18:12:40.314986 24660 solver.cpp:244]     Train net output #0: loss = 0.274421 (* 1 = 0.274421 loss)
I0918 18:12:40.315013 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.89075 (* 0.4 = 1.1563 loss)
I0918 18:12:40.315035 24660 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0918 18:13:20.200549 24660 solver.cpp:228] Iteration 600, loss = 1.30392
I0918 18:13:20.200750 24660 solver.cpp:244]     Train net output #0: loss = 0.119769 (* 1 = 0.119769 loss)
I0918 18:13:20.200776 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.84495 (* 0.4 = 1.13798 loss)
I0918 18:13:20.200798 24660 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0918 18:14:00.008527 24660 solver.cpp:228] Iteration 700, loss = 1.32723
I0918 18:14:00.008788 24660 solver.cpp:244]     Train net output #0: loss = 0.0515939 (* 1 = 0.0515939 loss)
I0918 18:14:00.008819 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.36599 (* 0.4 = 0.946396 loss)
I0918 18:14:00.008839 24660 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0918 18:14:39.927520 24660 solver.cpp:228] Iteration 800, loss = 1.37254
I0918 18:14:39.927705 24660 solver.cpp:244]     Train net output #0: loss = 0.445643 (* 1 = 0.445643 loss)
I0918 18:14:39.927729 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.82466 (* 0.4 = 1.12986 loss)
I0918 18:14:39.927758 24660 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0918 18:15:19.794446 24660 solver.cpp:228] Iteration 900, loss = 1.27228
I0918 18:15:19.794718 24660 solver.cpp:244]     Train net output #0: loss = 0.389381 (* 1 = 0.389381 loss)
I0918 18:15:19.794749 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.51045 (* 0.4 = 1.00418 loss)
I0918 18:15:19.794762 24660 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0918 18:15:59.286337 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_1000.caffemodel
I0918 18:16:00.762521 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_1000.solverstate
I0918 18:16:01.406358 24660 solver.cpp:337] Iteration 1000, Testing net (#0)
I0918 18:16:20.207270 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82075
I0918 18:16:20.207366 24660 solver.cpp:404]     Test net output #1: loss = 0.597972 (* 1 = 0.597972 loss)
I0918 18:16:20.207391 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.86539 (* 0.4 = 1.14616 loss)
I0918 18:16:20.364923 24660 solver.cpp:228] Iteration 1000, loss = 1.25836
I0918 18:16:20.365016 24660 solver.cpp:244]     Train net output #0: loss = 0.122923 (* 1 = 0.122923 loss)
I0918 18:16:20.365041 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.82435 (* 0.4 = 0.729741 loss)
I0918 18:16:20.365068 24660 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0918 18:16:37.628330 24660 solver.cpp:228] Iteration 1100, loss = 1.22352
I0918 18:16:37.628540 24660 solver.cpp:244]     Train net output #0: loss = 0.209156 (* 1 = 0.209156 loss)
I0918 18:16:37.628566 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.69984 (* 0.4 = 1.07993 loss)
I0918 18:16:37.628588 24660 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0918 18:17:11.358515 24660 solver.cpp:228] Iteration 1200, loss = 1.2
I0918 18:17:11.358805 24660 solver.cpp:244]     Train net output #0: loss = 0.101729 (* 1 = 0.101729 loss)
I0918 18:17:11.358836 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.27181 (* 0.4 = 0.908726 loss)
I0918 18:17:11.358851 24660 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0918 18:17:45.257395 24660 solver.cpp:228] Iteration 1300, loss = 1.25826
I0918 18:17:45.257597 24660 solver.cpp:244]     Train net output #0: loss = 0.351713 (* 1 = 0.351713 loss)
I0918 18:17:45.257628 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.64066 (* 0.4 = 1.05626 loss)
I0918 18:17:45.257654 24660 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0918 18:18:19.205708 24660 solver.cpp:228] Iteration 1400, loss = 1.17664
I0918 18:18:19.205971 24660 solver.cpp:244]     Train net output #0: loss = 0.0863722 (* 1 = 0.0863722 loss)
I0918 18:18:19.206010 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.41865 (* 0.4 = 0.967461 loss)
I0918 18:18:19.206034 24660 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0918 18:18:53.135732 24660 solver.cpp:228] Iteration 1500, loss = 1.2057
I0918 18:18:53.135911 24660 solver.cpp:244]     Train net output #0: loss = 0.162008 (* 1 = 0.162008 loss)
I0918 18:18:53.135938 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.47228 (* 0.4 = 0.988911 loss)
I0918 18:18:53.135959 24660 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0918 18:19:27.026499 24660 solver.cpp:228] Iteration 1600, loss = 1.2826
I0918 18:19:27.026767 24660 solver.cpp:244]     Train net output #0: loss = 0.35466 (* 1 = 0.35466 loss)
I0918 18:19:27.026798 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.86649 (* 0.4 = 1.1466 loss)
I0918 18:19:27.026813 24660 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0918 18:20:04.227522 24660 solver.cpp:228] Iteration 1700, loss = 1.15747
I0918 18:20:04.227730 24660 solver.cpp:244]     Train net output #0: loss = 0.360302 (* 1 = 0.360302 loss)
I0918 18:20:04.227757 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.39448 (* 0.4 = 0.957792 loss)
I0918 18:20:04.227783 24660 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0918 18:20:44.145463 24660 solver.cpp:228] Iteration 1800, loss = 1.18277
I0918 18:20:44.145686 24660 solver.cpp:244]     Train net output #0: loss = 0.0774223 (* 1 = 0.0774223 loss)
I0918 18:20:44.145712 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.73439 (* 0.4 = 0.693755 loss)
I0918 18:20:44.145745 24660 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0918 18:21:24.065196 24660 solver.cpp:228] Iteration 1900, loss = 1.10569
I0918 18:21:24.065385 24660 solver.cpp:244]     Train net output #0: loss = 0.221998 (* 1 = 0.221998 loss)
I0918 18:21:24.065410 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.69547 (* 0.4 = 1.07819 loss)
I0918 18:21:24.065433 24660 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0918 18:22:03.788708 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_2000.caffemodel
I0918 18:22:05.062567 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_2000.solverstate
I0918 18:22:05.528113 24660 solver.cpp:337] Iteration 2000, Testing net (#0)
I0918 18:22:24.351480 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8265
I0918 18:22:24.351575 24660 solver.cpp:404]     Test net output #1: loss = 0.565794 (* 1 = 0.565794 loss)
I0918 18:22:24.351598 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.77579 (* 0.4 = 1.11032 loss)
I0918 18:22:24.580082 24660 solver.cpp:228] Iteration 2000, loss = 1.11161
I0918 18:22:24.580166 24660 solver.cpp:244]     Train net output #0: loss = 0.190038 (* 1 = 0.190038 loss)
I0918 18:22:24.580191 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.19449 (* 0.4 = 0.877795 loss)
I0918 18:22:24.580215 24660 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0918 18:23:04.347743 24660 solver.cpp:228] Iteration 2100, loss = 1.15721
I0918 18:23:04.348043 24660 solver.cpp:244]     Train net output #0: loss = 0.128098 (* 1 = 0.128098 loss)
I0918 18:23:04.348073 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.03935 (* 0.4 = 0.815741 loss)
I0918 18:23:04.348088 24660 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0918 18:23:44.245601 24660 solver.cpp:228] Iteration 2200, loss = 1.10587
I0918 18:23:44.245826 24660 solver.cpp:244]     Train net output #0: loss = 0.0649501 (* 1 = 0.0649501 loss)
I0918 18:23:44.245853 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.80699 (* 0.4 = 0.722797 loss)
I0918 18:23:44.245880 24660 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0918 18:24:24.065227 24660 solver.cpp:228] Iteration 2300, loss = 1.10903
I0918 18:24:24.065405 24660 solver.cpp:244]     Train net output #0: loss = 0.161681 (* 1 = 0.161681 loss)
I0918 18:24:24.065433 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.55323 (* 0.4 = 1.02129 loss)
I0918 18:24:24.065454 24660 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0918 18:25:03.867398 24660 solver.cpp:228] Iteration 2400, loss = 1.19292
I0918 18:25:03.867647 24660 solver.cpp:244]     Train net output #0: loss = 0.312211 (* 1 = 0.312211 loss)
I0918 18:25:03.867693 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.71414 (* 0.4 = 1.08565 loss)
I0918 18:25:03.867727 24660 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0918 18:25:43.637186 24660 solver.cpp:228] Iteration 2500, loss = 1.07301
I0918 18:25:43.637377 24660 solver.cpp:244]     Train net output #0: loss = 0.266153 (* 1 = 0.266153 loss)
I0918 18:25:43.637404 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.06812 (* 0.4 = 0.827249 loss)
I0918 18:25:43.637434 24660 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0918 18:26:23.414207 24660 solver.cpp:228] Iteration 2600, loss = 1.11138
I0918 18:26:23.414446 24660 solver.cpp:244]     Train net output #0: loss = 0.126648 (* 1 = 0.126648 loss)
I0918 18:26:23.414476 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.68586 (* 0.4 = 0.674343 loss)
I0918 18:26:23.414490 24660 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0918 18:27:03.357617 24660 solver.cpp:228] Iteration 2700, loss = 1.05224
I0918 18:27:03.357827 24660 solver.cpp:244]     Train net output #0: loss = 0.143386 (* 1 = 0.143386 loss)
I0918 18:27:03.357857 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.50312 (* 0.4 = 1.00125 loss)
I0918 18:27:03.357880 24660 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0918 18:27:43.183691 24660 solver.cpp:228] Iteration 2800, loss = 1.07342
I0918 18:27:43.183864 24660 solver.cpp:244]     Train net output #0: loss = 0.174985 (* 1 = 0.174985 loss)
I0918 18:27:43.183892 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.02825 (* 0.4 = 0.811299 loss)
I0918 18:27:43.183915 24660 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0918 18:28:23.168906 24660 solver.cpp:228] Iteration 2900, loss = 1.11922
I0918 18:28:23.169154 24660 solver.cpp:244]     Train net output #0: loss = 0.239397 (* 1 = 0.239397 loss)
I0918 18:28:23.169184 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.29605 (* 0.4 = 0.918418 loss)
I0918 18:28:23.169199 24660 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0918 18:29:02.626843 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_3000.caffemodel
I0918 18:29:03.894912 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_3000.solverstate
I0918 18:29:04.344005 24660 solver.cpp:337] Iteration 3000, Testing net (#0)
I0918 18:29:23.160281 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82675
I0918 18:29:23.160382 24660 solver.cpp:404]     Test net output #1: loss = 0.561157 (* 1 = 0.561157 loss)
I0918 18:29:23.160405 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.72668 (* 0.4 = 1.09067 loss)
I0918 18:29:23.333838 24660 solver.cpp:228] Iteration 3000, loss = 1.07172
I0918 18:29:23.333917 24660 solver.cpp:244]     Train net output #0: loss = 0.122111 (* 1 = 0.122111 loss)
I0918 18:29:23.333941 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.95615 (* 0.4 = 0.782459 loss)
I0918 18:29:23.333967 24660 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0918 18:30:03.280071 24660 solver.cpp:228] Iteration 3100, loss = 1.05743
I0918 18:30:03.280371 24660 solver.cpp:244]     Train net output #0: loss = 0.0775355 (* 1 = 0.0775355 loss)
I0918 18:30:03.280413 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.26946 (* 0.4 = 0.907786 loss)
I0918 18:30:03.280447 24660 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0918 18:30:43.181731 24660 solver.cpp:228] Iteration 3200, loss = 1.12401
I0918 18:30:43.181994 24660 solver.cpp:244]     Train net output #0: loss = 0.287881 (* 1 = 0.287881 loss)
I0918 18:30:43.182024 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.39407 (* 0.4 = 0.957627 loss)
I0918 18:30:43.182039 24660 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0918 18:31:22.930757 24660 solver.cpp:228] Iteration 3300, loss = 1.0246
I0918 18:31:22.930968 24660 solver.cpp:244]     Train net output #0: loss = 0.337934 (* 1 = 0.337934 loss)
I0918 18:31:22.930997 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.38397 (* 0.4 = 0.953589 loss)
I0918 18:31:22.931020 24660 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0918 18:32:02.810423 24660 solver.cpp:228] Iteration 3400, loss = 1.03562
I0918 18:32:02.810624 24660 solver.cpp:244]     Train net output #0: loss = 0.062593 (* 1 = 0.062593 loss)
I0918 18:32:02.810657 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.5939 (* 0.4 = 0.63756 loss)
I0918 18:32:02.810680 24660 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0918 18:32:42.693429 24660 solver.cpp:228] Iteration 3500, loss = 1.00856
I0918 18:32:42.693706 24660 solver.cpp:244]     Train net output #0: loss = 0.210647 (* 1 = 0.210647 loss)
I0918 18:32:42.693737 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.71058 (* 0.4 = 1.08423 loss)
I0918 18:32:42.693753 24660 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0918 18:33:22.577316 24660 solver.cpp:228] Iteration 3600, loss = 0.974932
I0918 18:33:22.577524 24660 solver.cpp:244]     Train net output #0: loss = 0.0543092 (* 1 = 0.0543092 loss)
I0918 18:33:22.577551 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.62686 (* 0.4 = 0.650742 loss)
I0918 18:33:22.577574 24660 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0918 18:34:02.551720 24660 solver.cpp:228] Iteration 3700, loss = 1.04071
I0918 18:34:02.551903 24660 solver.cpp:244]     Train net output #0: loss = 0.122548 (* 1 = 0.122548 loss)
I0918 18:34:02.551930 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.01862 (* 0.4 = 0.807449 loss)
I0918 18:34:02.551954 24660 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0918 18:34:42.450028 24660 solver.cpp:228] Iteration 3800, loss = 1.02649
I0918 18:34:42.450286 24660 solver.cpp:244]     Train net output #0: loss = 0.0255448 (* 1 = 0.0255448 loss)
I0918 18:34:42.450316 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.80179 (* 0.4 = 0.720718 loss)
I0918 18:34:42.450336 24660 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0918 18:35:22.292058 24660 solver.cpp:228] Iteration 3900, loss = 1.02491
I0918 18:35:22.292249 24660 solver.cpp:244]     Train net output #0: loss = 0.0823208 (* 1 = 0.0823208 loss)
I0918 18:35:22.292277 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.06559 (* 0.4 = 0.826238 loss)
I0918 18:35:22.292299 24660 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0918 18:36:01.657157 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_4000.caffemodel
I0918 18:36:02.928642 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_4000.solverstate
I0918 18:36:03.374539 24660 solver.cpp:337] Iteration 4000, Testing net (#0)
I0918 18:36:22.170708 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82275
I0918 18:36:22.170811 24660 solver.cpp:404]     Test net output #1: loss = 0.580579 (* 1 = 0.580579 loss)
I0918 18:36:22.170835 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.81273 (* 0.4 = 1.12509 loss)
I0918 18:36:22.344844 24660 solver.cpp:228] Iteration 4000, loss = 1.07248
I0918 18:36:22.344934 24660 solver.cpp:244]     Train net output #0: loss = 0.246272 (* 1 = 0.246272 loss)
I0918 18:36:22.344959 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.31835 (* 0.4 = 0.92734 loss)
I0918 18:36:22.344985 24660 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0918 18:37:02.251008 24660 solver.cpp:228] Iteration 4100, loss = 0.964605
I0918 18:37:02.251210 24660 solver.cpp:244]     Train net output #0: loss = 0.300657 (* 1 = 0.300657 loss)
I0918 18:37:02.251238 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.69834 (* 0.4 = 0.679334 loss)
I0918 18:37:02.251260 24660 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0918 18:37:40.203615 24660 solver.cpp:228] Iteration 4200, loss = 1.00555
I0918 18:37:40.203819 24660 solver.cpp:244]     Train net output #0: loss = 0.0381437 (* 1 = 0.0381437 loss)
I0918 18:37:40.203847 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.27023 (* 0.4 = 0.508092 loss)
I0918 18:37:40.203871 24660 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0918 18:38:01.481367 24660 solver.cpp:228] Iteration 4300, loss = 0.957199
I0918 18:38:01.481467 24660 solver.cpp:244]     Train net output #0: loss = 0.131468 (* 1 = 0.131468 loss)
I0918 18:38:01.481490 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.24141 (* 0.4 = 0.896565 loss)
I0918 18:38:01.481513 24660 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0918 18:38:35.354434 24660 solver.cpp:228] Iteration 4400, loss = 0.955188
I0918 18:38:35.354622 24660 solver.cpp:244]     Train net output #0: loss = 0.0892359 (* 1 = 0.0892359 loss)
I0918 18:38:35.354653 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.95983 (* 0.4 = 0.783932 loss)
I0918 18:38:35.354676 24660 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0918 18:39:09.280755 24660 solver.cpp:228] Iteration 4500, loss = 1.01631
I0918 18:39:09.281025 24660 solver.cpp:244]     Train net output #0: loss = 0.147965 (* 1 = 0.147965 loss)
I0918 18:39:09.281056 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.98359 (* 0.4 = 0.793438 loss)
I0918 18:39:09.281070 24660 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0918 18:39:43.217523 24660 solver.cpp:228] Iteration 4600, loss = 0.945467
I0918 18:39:43.217782 24660 solver.cpp:244]     Train net output #0: loss = 0.135868 (* 1 = 0.135868 loss)
I0918 18:39:43.217809 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.86324 (* 0.4 = 0.745297 loss)
I0918 18:39:43.217831 24660 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0918 18:40:17.145304 24660 solver.cpp:228] Iteration 4700, loss = 0.998673
I0918 18:40:17.145596 24660 solver.cpp:244]     Train net output #0: loss = 0.0992704 (* 1 = 0.0992704 loss)
I0918 18:40:17.145663 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.05819 (* 0.4 = 0.823275 loss)
I0918 18:40:17.145689 24660 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0918 18:40:51.096484 24660 solver.cpp:228] Iteration 4800, loss = 1.02514
I0918 18:40:51.096683 24660 solver.cpp:244]     Train net output #0: loss = 0.400265 (* 1 = 0.400265 loss)
I0918 18:40:51.096709 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.40358 (* 0.4 = 0.961434 loss)
I0918 18:40:51.096731 24660 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0918 18:41:30.088752 24660 solver.cpp:228] Iteration 4900, loss = 0.918741
I0918 18:41:30.088977 24660 solver.cpp:244]     Train net output #0: loss = 0.211506 (* 1 = 0.211506 loss)
I0918 18:41:30.089005 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.56846 (* 0.4 = 0.627385 loss)
I0918 18:41:30.089033 24660 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0918 18:42:09.512962 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_5000.caffemodel
I0918 18:42:10.789413 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_5000.solverstate
I0918 18:42:11.255750 24660 solver.cpp:337] Iteration 5000, Testing net (#0)
I0918 18:42:30.051380 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.825
I0918 18:42:30.051476 24660 solver.cpp:404]     Test net output #1: loss = 0.600756 (* 1 = 0.600756 loss)
I0918 18:42:30.051501 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.66345 (* 0.4 = 1.06538 loss)
I0918 18:42:30.228291 24660 solver.cpp:228] Iteration 5000, loss = 0.949565
I0918 18:42:30.228379 24660 solver.cpp:244]     Train net output #0: loss = 0.112456 (* 1 = 0.112456 loss)
I0918 18:42:30.228402 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.92834 (* 0.4 = 0.771337 loss)
I0918 18:42:30.228427 24660 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0918 18:43:10.147622 24660 solver.cpp:228] Iteration 5100, loss = 0.906833
I0918 18:43:10.147797 24660 solver.cpp:244]     Train net output #0: loss = 0.289261 (* 1 = 0.289261 loss)
I0918 18:43:10.147825 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.28367 (* 0.4 = 0.913468 loss)
I0918 18:43:10.147851 24660 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0918 18:43:50.070647 24660 solver.cpp:228] Iteration 5200, loss = 0.896583
I0918 18:43:50.070925 24660 solver.cpp:244]     Train net output #0: loss = 0.0386268 (* 1 = 0.0386268 loss)
I0918 18:43:50.070955 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.48107 (* 0.4 = 0.592427 loss)
I0918 18:43:50.070971 24660 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0918 18:44:30.134436 24660 solver.cpp:228] Iteration 5300, loss = 0.931676
I0918 18:44:30.134606 24660 solver.cpp:244]     Train net output #0: loss = 0.152859 (* 1 = 0.152859 loss)
I0918 18:44:30.134634 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.71359 (* 0.4 = 0.685438 loss)
I0918 18:44:30.134656 24660 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0918 18:45:10.015238 24660 solver.cpp:228] Iteration 5400, loss = 0.886517
I0918 18:45:10.015450 24660 solver.cpp:244]     Train net output #0: loss = 0.0416925 (* 1 = 0.0416925 loss)
I0918 18:45:10.015480 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.15509 (* 0.4 = 0.462037 loss)
I0918 18:45:10.015494 24660 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0918 18:45:49.832777 24660 solver.cpp:228] Iteration 5500, loss = 0.936204
I0918 18:45:49.832972 24660 solver.cpp:244]     Train net output #0: loss = 0.0308156 (* 1 = 0.0308156 loss)
I0918 18:45:49.833005 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.89152 (* 0.4 = 0.756608 loss)
I0918 18:45:49.833029 24660 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0918 18:46:29.787565 24660 solver.cpp:228] Iteration 5600, loss = 0.971746
I0918 18:46:29.787766 24660 solver.cpp:244]     Train net output #0: loss = 0.155756 (* 1 = 0.155756 loss)
I0918 18:46:29.787798 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.35765 (* 0.4 = 0.943058 loss)
I0918 18:46:29.787822 24660 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0918 18:47:09.461484 24660 solver.cpp:228] Iteration 5700, loss = 0.895025
I0918 18:47:09.461695 24660 solver.cpp:244]     Train net output #0: loss = 0.227436 (* 1 = 0.227436 loss)
I0918 18:47:09.461727 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.77798 (* 0.4 = 0.711193 loss)
I0918 18:47:09.461753 24660 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0918 18:47:49.355152 24660 solver.cpp:228] Iteration 5800, loss = 0.899988
I0918 18:47:49.355406 24660 solver.cpp:244]     Train net output #0: loss = 0.0970887 (* 1 = 0.0970887 loss)
I0918 18:47:49.355437 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.70209 (* 0.4 = 0.680837 loss)
I0918 18:47:49.355461 24660 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0918 18:48:29.294993 24660 solver.cpp:228] Iteration 5900, loss = 0.85863
I0918 18:48:29.295235 24660 solver.cpp:244]     Train net output #0: loss = 0.160191 (* 1 = 0.160191 loss)
I0918 18:48:29.295266 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.30183 (* 0.4 = 0.920731 loss)
I0918 18:48:29.295281 24660 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0918 18:49:08.793577 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_6000.caffemodel
I0918 18:49:10.111372 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_6000.solverstate
I0918 18:49:10.557988 24660 solver.cpp:337] Iteration 6000, Testing net (#0)
I0918 18:49:29.411765 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82775
I0918 18:49:29.411866 24660 solver.cpp:404]     Test net output #1: loss = 0.605191 (* 1 = 0.605191 loss)
I0918 18:49:29.411891 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.63061 (* 0.4 = 1.05224 loss)
I0918 18:49:29.607156 24660 solver.cpp:228] Iteration 6000, loss = 0.851382
I0918 18:49:29.607244 24660 solver.cpp:244]     Train net output #0: loss = 0.0966406 (* 1 = 0.0966406 loss)
I0918 18:49:29.607269 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.01516 (* 0.4 = 0.806063 loss)
I0918 18:49:29.607293 24660 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0918 18:50:09.369981 24660 solver.cpp:228] Iteration 6100, loss = 0.932282
I0918 18:50:09.370198 24660 solver.cpp:244]     Train net output #0: loss = 0.0799642 (* 1 = 0.0799642 loss)
I0918 18:50:09.370229 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.76395 (* 0.4 = 0.705582 loss)
I0918 18:50:09.370249 24660 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0918 18:50:49.318013 24660 solver.cpp:228] Iteration 6200, loss = 0.877301
I0918 18:50:49.318255 24660 solver.cpp:244]     Train net output #0: loss = 0.0475432 (* 1 = 0.0475432 loss)
I0918 18:50:49.318285 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.54312 (* 0.4 = 0.617248 loss)
I0918 18:50:49.318300 24660 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0918 18:51:29.335708 24660 solver.cpp:228] Iteration 6300, loss = 0.897873
I0918 18:51:29.335923 24660 solver.cpp:244]     Train net output #0: loss = 0.168051 (* 1 = 0.168051 loss)
I0918 18:51:29.335950 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.07615 (* 0.4 = 0.830459 loss)
I0918 18:51:29.335979 24660 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0918 18:52:09.197115 24660 solver.cpp:228] Iteration 6400, loss = 0.918491
I0918 18:52:09.197373 24660 solver.cpp:244]     Train net output #0: loss = 0.424755 (* 1 = 0.424755 loss)
I0918 18:52:09.197404 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.50228 (* 0.4 = 1.00091 loss)
I0918 18:52:09.197419 24660 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0918 18:52:49.075820 24660 solver.cpp:228] Iteration 6500, loss = 0.846592
I0918 18:52:49.076066 24660 solver.cpp:244]     Train net output #0: loss = 0.330616 (* 1 = 0.330616 loss)
I0918 18:52:49.076097 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.80422 (* 0.4 = 0.721687 loss)
I0918 18:52:49.076112 24660 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0918 18:53:28.750344 24660 solver.cpp:228] Iteration 6600, loss = 0.895007
I0918 18:53:28.750612 24660 solver.cpp:244]     Train net output #0: loss = 0.0932039 (* 1 = 0.0932039 loss)
I0918 18:53:28.750643 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.3424 (* 0.4 = 0.536961 loss)
I0918 18:53:28.750663 24660 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0918 18:54:08.950275 24660 solver.cpp:228] Iteration 6700, loss = 0.82708
I0918 18:54:08.950525 24660 solver.cpp:244]     Train net output #0: loss = 0.0968025 (* 1 = 0.0968025 loss)
I0918 18:54:08.950553 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.18347 (* 0.4 = 0.87339 loss)
I0918 18:54:08.950582 24660 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0918 18:54:48.764655 24660 solver.cpp:228] Iteration 6800, loss = 0.817901
I0918 18:54:48.764948 24660 solver.cpp:244]     Train net output #0: loss = 0.0480662 (* 1 = 0.0480662 loss)
I0918 18:54:48.764978 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.51057 (* 0.4 = 0.604229 loss)
I0918 18:54:48.764993 24660 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0918 18:55:28.523772 24660 solver.cpp:228] Iteration 6900, loss = 0.873329
I0918 18:55:28.523968 24660 solver.cpp:244]     Train net output #0: loss = 0.207733 (* 1 = 0.207733 loss)
I0918 18:55:28.523994 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.96115 (* 0.4 = 0.784462 loss)
I0918 18:55:28.524019 24660 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0918 18:56:07.945216 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_7000.caffemodel
I0918 18:56:09.255484 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_7000.solverstate
I0918 18:56:09.704584 24660 solver.cpp:337] Iteration 7000, Testing net (#0)
I0918 18:56:28.475250 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82425
I0918 18:56:28.475344 24660 solver.cpp:404]     Test net output #1: loss = 0.622427 (* 1 = 0.622427 loss)
I0918 18:56:28.475368 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.71176 (* 0.4 = 1.0847 loss)
I0918 18:56:28.679621 24660 solver.cpp:228] Iteration 7000, loss = 0.835895
I0918 18:56:28.679714 24660 solver.cpp:244]     Train net output #0: loss = 0.0685432 (* 1 = 0.0685432 loss)
I0918 18:56:28.679744 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.60957 (* 0.4 = 0.643828 loss)
I0918 18:56:28.679780 24660 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0918 18:57:08.524441 24660 solver.cpp:228] Iteration 7100, loss = 0.868439
I0918 18:57:08.524619 24660 solver.cpp:244]     Train net output #0: loss = 0.0432008 (* 1 = 0.0432008 loss)
I0918 18:57:08.524644 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.97517 (* 0.4 = 0.790068 loss)
I0918 18:57:08.524667 24660 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0918 18:57:48.369102 24660 solver.cpp:228] Iteration 7200, loss = 0.86795
I0918 18:57:48.369369 24660 solver.cpp:244]     Train net output #0: loss = 0.151626 (* 1 = 0.151626 loss)
I0918 18:57:48.369400 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.87161 (* 0.4 = 0.748643 loss)
I0918 18:57:48.369417 24660 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0918 18:58:28.138449 24660 solver.cpp:228] Iteration 7300, loss = 0.79113
I0918 18:58:28.138636 24660 solver.cpp:244]     Train net output #0: loss = 0.166483 (* 1 = 0.166483 loss)
I0918 18:58:28.138664 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.64892 (* 0.4 = 0.65957 loss)
I0918 18:58:28.138685 24660 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0918 18:58:58.300832 24660 solver.cpp:228] Iteration 7400, loss = 0.858159
I0918 18:58:58.301000 24660 solver.cpp:244]     Train net output #0: loss = 0.0287295 (* 1 = 0.0287295 loss)
I0918 18:58:58.301026 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.09951 (* 0.4 = 0.439804 loss)
I0918 18:58:58.301048 24660 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0918 18:59:20.932694 24660 solver.cpp:228] Iteration 7500, loss = 0.796969
I0918 18:59:20.932791 24660 solver.cpp:244]     Train net output #0: loss = 0.130257 (* 1 = 0.130257 loss)
I0918 18:59:20.932816 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.86388 (* 0.4 = 0.745554 loss)
I0918 18:59:20.932837 24660 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0918 18:59:54.856992 24660 solver.cpp:228] Iteration 7600, loss = 0.809188
I0918 18:59:54.857239 24660 solver.cpp:244]     Train net output #0: loss = 0.126359 (* 1 = 0.126359 loss)
I0918 18:59:54.857269 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.59588 (* 0.4 = 0.638352 loss)
I0918 18:59:54.857283 24660 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0918 19:00:28.854817 24660 solver.cpp:228] Iteration 7700, loss = 0.810604
I0918 19:00:28.855006 24660 solver.cpp:244]     Train net output #0: loss = 0.14375 (* 1 = 0.14375 loss)
I0918 19:00:28.855048 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.6763 (* 0.4 = 0.67052 loss)
I0918 19:00:28.855073 24660 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0918 19:01:02.769191 24660 solver.cpp:228] Iteration 7800, loss = 0.781613
I0918 19:01:02.769403 24660 solver.cpp:244]     Train net output #0: loss = 0.0228423 (* 1 = 0.0228423 loss)
I0918 19:01:02.769430 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.938938 (* 0.4 = 0.375575 loss)
I0918 19:01:02.769459 24660 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0918 19:01:36.681555 24660 solver.cpp:228] Iteration 7900, loss = 0.820472
I0918 19:01:36.681736 24660 solver.cpp:244]     Train net output #0: loss = 0.039854 (* 1 = 0.039854 loss)
I0918 19:01:36.681764 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.051 (* 0.4 = 0.820399 loss)
I0918 19:01:36.681787 24660 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0918 19:02:10.244266 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_8000.caffemodel
I0918 19:02:11.504204 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_8000.solverstate
I0918 19:02:12.000442 24660 solver.cpp:337] Iteration 8000, Testing net (#0)
I0918 19:02:30.732738 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82525
I0918 19:02:30.732837 24660 solver.cpp:404]     Test net output #1: loss = 0.63307 (* 1 = 0.63307 loss)
I0918 19:02:30.732861 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.70967 (* 0.4 = 1.08387 loss)
I0918 19:02:30.893928 24660 solver.cpp:228] Iteration 8000, loss = 0.851219
I0918 19:02:30.894026 24660 solver.cpp:244]     Train net output #0: loss = 0.109096 (* 1 = 0.109096 loss)
I0918 19:02:30.894054 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.25724 (* 0.4 = 0.902897 loss)
I0918 19:02:30.894091 24660 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0918 19:03:10.741303 24660 solver.cpp:228] Iteration 8100, loss = 0.793669
I0918 19:03:10.741513 24660 solver.cpp:244]     Train net output #0: loss = 0.100719 (* 1 = 0.100719 loss)
I0918 19:03:10.741539 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.44949 (* 0.4 = 0.579796 loss)
I0918 19:03:10.741562 24660 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0918 19:03:50.699226 24660 solver.cpp:228] Iteration 8200, loss = 0.787637
I0918 19:03:50.699411 24660 solver.cpp:244]     Train net output #0: loss = 0.0291476 (* 1 = 0.0291476 loss)
I0918 19:03:50.699439 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.20912 (* 0.4 = 0.48365 loss)
I0918 19:03:50.699460 24660 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0918 19:04:30.741575 24660 solver.cpp:228] Iteration 8300, loss = 0.754173
I0918 19:04:30.741849 24660 solver.cpp:244]     Train net output #0: loss = 0.138933 (* 1 = 0.138933 loss)
I0918 19:04:30.741879 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.95032 (* 0.4 = 0.780128 loss)
I0918 19:04:30.741894 24660 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0918 19:05:10.637173 24660 solver.cpp:228] Iteration 8400, loss = 0.765782
I0918 19:05:10.637429 24660 solver.cpp:244]     Train net output #0: loss = 0.0839284 (* 1 = 0.0839284 loss)
I0918 19:05:10.637460 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.73554 (* 0.4 = 0.694216 loss)
I0918 19:05:10.637481 24660 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0918 19:05:50.331634 24660 solver.cpp:228] Iteration 8500, loss = 0.769055
I0918 19:05:50.331840 24660 solver.cpp:244]     Train net output #0: loss = 0.0602872 (* 1 = 0.0602872 loss)
I0918 19:05:50.331868 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.48409 (* 0.4 = 0.593636 loss)
I0918 19:05:50.331890 24660 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0918 19:06:30.137188 24660 solver.cpp:228] Iteration 8600, loss = 0.741747
I0918 19:06:30.137442 24660 solver.cpp:244]     Train net output #0: loss = 0.109095 (* 1 = 0.109095 loss)
I0918 19:06:30.137470 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.4502 (* 0.4 = 0.580082 loss)
I0918 19:06:30.137492 24660 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0918 19:07:10.025267 24660 solver.cpp:228] Iteration 8700, loss = 0.773772
I0918 19:07:10.025471 24660 solver.cpp:244]     Train net output #0: loss = 0.0417108 (* 1 = 0.0417108 loss)
I0918 19:07:10.025498 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.92793 (* 0.4 = 0.771171 loss)
I0918 19:07:10.025522 24660 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0918 19:07:49.760234 24660 solver.cpp:228] Iteration 8800, loss = 0.782674
I0918 19:07:49.760500 24660 solver.cpp:244]     Train net output #0: loss = 0.0477477 (* 1 = 0.0477477 loss)
I0918 19:07:49.760531 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.64382 (* 0.4 = 0.657529 loss)
I0918 19:07:49.760546 24660 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0918 19:08:29.767832 24660 solver.cpp:228] Iteration 8900, loss = 0.748511
I0918 19:08:29.768023 24660 solver.cpp:244]     Train net output #0: loss = 0.158094 (* 1 = 0.158094 loss)
I0918 19:08:29.768049 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.62928 (* 0.4 = 0.651713 loss)
I0918 19:08:29.768081 24660 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0918 19:09:09.231650 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_9000.caffemodel
I0918 19:09:10.480373 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_9000.solverstate
I0918 19:09:10.940847 24660 solver.cpp:337] Iteration 9000, Testing net (#0)
I0918 19:09:29.813058 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.822
I0918 19:09:29.813158 24660 solver.cpp:404]     Test net output #1: loss = 0.678069 (* 1 = 0.678069 loss)
I0918 19:09:29.813181 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.66071 (* 0.4 = 1.06428 loss)
I0918 19:09:29.980309 24660 solver.cpp:228] Iteration 9000, loss = 0.771935
I0918 19:09:29.980393 24660 solver.cpp:244]     Train net output #0: loss = 0.0265645 (* 1 = 0.0265645 loss)
I0918 19:09:29.980418 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.07455 (* 0.4 = 0.429822 loss)
I0918 19:09:29.980443 24660 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0918 19:10:09.875077 24660 solver.cpp:228] Iteration 9100, loss = 0.725018
I0918 19:10:09.875291 24660 solver.cpp:244]     Train net output #0: loss = 0.237757 (* 1 = 0.237757 loss)
I0918 19:10:09.875336 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.11579 (* 0.4 = 0.846314 loss)
I0918 19:10:09.875370 24660 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0918 19:10:49.826851 24660 solver.cpp:228] Iteration 9200, loss = 0.705793
I0918 19:10:49.827057 24660 solver.cpp:244]     Train net output #0: loss = 0.0835748 (* 1 = 0.0835748 loss)
I0918 19:10:49.827102 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.83898 (* 0.4 = 0.73559 loss)
I0918 19:10:49.827148 24660 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0918 19:11:29.686280 24660 solver.cpp:228] Iteration 9300, loss = 0.781054
I0918 19:11:29.686478 24660 solver.cpp:244]     Train net output #0: loss = 0.184081 (* 1 = 0.184081 loss)
I0918 19:11:29.686506 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.73039 (* 0.4 = 0.692158 loss)
I0918 19:11:29.686529 24660 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0918 19:12:09.461016 24660 solver.cpp:228] Iteration 9400, loss = 0.707115
I0918 19:12:09.461220 24660 solver.cpp:244]     Train net output #0: loss = 0.0286678 (* 1 = 0.0286678 loss)
I0918 19:12:09.461246 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.17196 (* 0.4 = 0.468783 loss)
I0918 19:12:09.461277 24660 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0918 19:12:49.393285 24660 solver.cpp:228] Iteration 9500, loss = 0.724919
I0918 19:12:49.393631 24660 solver.cpp:244]     Train net output #0: loss = 0.0779285 (* 1 = 0.0779285 loss)
I0918 19:12:49.393664 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.6521 (* 0.4 = 0.660841 loss)
I0918 19:12:49.393679 24660 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0918 19:13:29.372974 24660 solver.cpp:228] Iteration 9600, loss = 0.80621
I0918 19:13:29.373195 24660 solver.cpp:244]     Train net output #0: loss = 0.150874 (* 1 = 0.150874 loss)
I0918 19:13:29.373225 24660 solver.cpp:244]     Train net output #1: loss_hashing = 2.08201 (* 0.4 = 0.832805 loss)
I0918 19:13:29.373239 24660 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0918 19:14:09.311570 24660 solver.cpp:228] Iteration 9700, loss = 0.709195
I0918 19:14:09.311770 24660 solver.cpp:244]     Train net output #0: loss = 0.202258 (* 1 = 0.202258 loss)
I0918 19:14:09.311796 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.95804 (* 0.4 = 0.783216 loss)
I0918 19:14:09.311818 24660 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0918 19:14:49.291297 24660 solver.cpp:228] Iteration 9800, loss = 0.716416
I0918 19:14:49.291538 24660 solver.cpp:244]     Train net output #0: loss = 0.0199163 (* 1 = 0.0199163 loss)
I0918 19:14:49.291569 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.900977 (* 0.4 = 0.360391 loss)
I0918 19:14:49.291584 24660 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0918 19:15:29.132843 24660 solver.cpp:228] Iteration 9900, loss = 0.666398
I0918 19:15:29.133043 24660 solver.cpp:244]     Train net output #0: loss = 0.0938838 (* 1 = 0.0938838 loss)
I0918 19:15:29.133069 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.44194 (* 0.4 = 0.576776 loss)
I0918 19:15:29.133091 24660 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0918 19:16:08.446750 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_10000.caffemodel
I0918 19:16:09.825672 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_10000.solverstate
I0918 19:16:10.311503 24660 solver.cpp:337] Iteration 10000, Testing net (#0)
I0918 19:16:29.125033 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82925
I0918 19:16:29.125133 24660 solver.cpp:404]     Test net output #1: loss = 0.645855 (* 1 = 0.645855 loss)
I0918 19:16:29.125156 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.68211 (* 0.4 = 1.07284 loss)
I0918 19:16:29.282301 24660 solver.cpp:228] Iteration 10000, loss = 0.698628
I0918 19:16:29.282387 24660 solver.cpp:244]     Train net output #0: loss = 0.0280846 (* 1 = 0.0280846 loss)
I0918 19:16:29.282410 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.27705 (* 0.4 = 0.510822 loss)
I0918 19:16:29.282436 24660 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0918 19:17:09.172925 24660 solver.cpp:228] Iteration 10100, loss = 0.707263
I0918 19:17:09.173192 24660 solver.cpp:244]     Train net output #0: loss = 0.0156432 (* 1 = 0.0156432 loss)
I0918 19:17:09.173223 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.31259 (* 0.4 = 0.525037 loss)
I0918 19:17:09.173238 24660 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0918 19:17:49.007427 24660 solver.cpp:228] Iteration 10200, loss = 0.704228
I0918 19:17:49.007663 24660 solver.cpp:244]     Train net output #0: loss = 0.0197306 (* 1 = 0.0197306 loss)
I0918 19:17:49.007694 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.21931 (* 0.4 = 0.487723 loss)
I0918 19:17:49.007714 24660 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0918 19:18:28.745131 24660 solver.cpp:228] Iteration 10300, loss = 0.715591
I0918 19:18:28.745326 24660 solver.cpp:244]     Train net output #0: loss = 0.0566999 (* 1 = 0.0566999 loss)
I0918 19:18:28.745352 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.41708 (* 0.4 = 0.566834 loss)
I0918 19:18:28.745373 24660 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0918 19:19:08.566730 24660 solver.cpp:228] Iteration 10400, loss = 0.731693
I0918 19:19:08.567070 24660 solver.cpp:244]     Train net output #0: loss = 0.0868878 (* 1 = 0.0868878 loss)
I0918 19:19:08.567101 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.57165 (* 0.4 = 0.628658 loss)
I0918 19:19:08.567116 24660 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0918 19:19:48.395345 24660 solver.cpp:228] Iteration 10500, loss = 0.695723
I0918 19:19:48.395542 24660 solver.cpp:244]     Train net output #0: loss = 0.18133 (* 1 = 0.18133 loss)
I0918 19:19:48.395570 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.84194 (* 0.4 = 0.736776 loss)
I0918 19:19:48.395601 24660 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0918 19:20:16.401003 24660 solver.cpp:228] Iteration 10600, loss = 0.705236
I0918 19:20:16.401110 24660 solver.cpp:244]     Train net output #0: loss = 0.0171873 (* 1 = 0.0171873 loss)
I0918 19:20:16.401135 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.858216 (* 0.4 = 0.343286 loss)
I0918 19:20:16.401157 24660 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0918 19:20:46.221181 24660 solver.cpp:228] Iteration 10700, loss = 0.679282
I0918 19:20:46.221360 24660 solver.cpp:244]     Train net output #0: loss = 0.115109 (* 1 = 0.115109 loss)
I0918 19:20:46.221392 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.93626 (* 0.4 = 0.774506 loss)
I0918 19:20:46.221415 24660 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0918 19:21:20.211797 24660 solver.cpp:228] Iteration 10800, loss = 0.680425
I0918 19:21:20.212054 24660 solver.cpp:244]     Train net output #0: loss = 0.0507874 (* 1 = 0.0507874 loss)
I0918 19:21:20.212085 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.21995 (* 0.4 = 0.487978 loss)
I0918 19:21:20.212108 24660 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0918 19:21:54.119655 24660 solver.cpp:228] Iteration 10900, loss = 0.723537
I0918 19:21:54.119915 24660 solver.cpp:244]     Train net output #0: loss = 0.0593915 (* 1 = 0.0593915 loss)
I0918 19:21:54.119945 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.48978 (* 0.4 = 0.595911 loss)
I0918 19:21:54.119961 24660 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0918 19:22:27.726014 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_11000.caffemodel
I0918 19:22:37.536905 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_11000.solverstate
I0918 19:22:38.084105 24660 solver.cpp:337] Iteration 11000, Testing net (#0)
I0918 19:22:54.021239 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82375
I0918 19:22:54.021349 24660 solver.cpp:404]     Test net output #1: loss = 0.66231 (* 1 = 0.66231 loss)
I0918 19:22:54.021374 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.68908 (* 0.4 = 1.07563 loss)
I0918 19:22:54.190590 24660 solver.cpp:228] Iteration 11000, loss = 0.647819
I0918 19:22:54.190682 24660 solver.cpp:244]     Train net output #0: loss = 0.0338798 (* 1 = 0.0338798 loss)
I0918 19:22:54.190707 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.20083 (* 0.4 = 0.480333 loss)
I0918 19:22:54.190732 24660 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0918 19:23:30.547448 24660 solver.cpp:228] Iteration 11100, loss = 0.674732
I0918 19:23:30.547636 24660 solver.cpp:244]     Train net output #0: loss = 0.116386 (* 1 = 0.116386 loss)
I0918 19:23:30.547662 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.78969 (* 0.4 = 0.715877 loss)
I0918 19:23:30.547684 24660 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0918 19:24:10.328968 24660 solver.cpp:228] Iteration 11200, loss = 0.697277
I0918 19:24:10.329146 24660 solver.cpp:244]     Train net output #0: loss = 0.0773291 (* 1 = 0.0773291 loss)
I0918 19:24:10.329179 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.56454 (* 0.4 = 0.625815 loss)
I0918 19:24:10.329201 24660 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0918 19:24:50.243826 24660 solver.cpp:228] Iteration 11300, loss = 0.628785
I0918 19:24:50.244055 24660 solver.cpp:244]     Train net output #0: loss = 0.285194 (* 1 = 0.285194 loss)
I0918 19:24:50.244082 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.84786 (* 0.4 = 0.739143 loss)
I0918 19:24:50.244104 24660 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0918 19:25:30.219718 24660 solver.cpp:228] Iteration 11400, loss = 0.675389
I0918 19:25:30.219924 24660 solver.cpp:244]     Train net output #0: loss = 0.0243068 (* 1 = 0.0243068 loss)
I0918 19:25:30.219951 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.02624 (* 0.4 = 0.410497 loss)
I0918 19:25:30.219972 24660 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0918 19:26:09.992496 24660 solver.cpp:228] Iteration 11500, loss = 0.631871
I0918 19:26:09.992703 24660 solver.cpp:244]     Train net output #0: loss = 0.100373 (* 1 = 0.100373 loss)
I0918 19:26:09.992733 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.90786 (* 0.4 = 0.763144 loss)
I0918 19:26:09.992759 24660 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0918 19:26:50.026099 24660 solver.cpp:228] Iteration 11600, loss = 0.641539
I0918 19:26:50.026362 24660 solver.cpp:244]     Train net output #0: loss = 0.0483177 (* 1 = 0.0483177 loss)
I0918 19:26:50.026392 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.74504 (* 0.4 = 0.698016 loss)
I0918 19:26:50.026407 24660 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0918 19:27:29.998205 24660 solver.cpp:228] Iteration 11700, loss = 0.651779
I0918 19:27:29.998456 24660 solver.cpp:244]     Train net output #0: loss = 0.0741323 (* 1 = 0.0741323 loss)
I0918 19:27:29.998486 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.41786 (* 0.4 = 0.567145 loss)
I0918 19:27:29.998502 24660 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0918 19:28:09.906280 24660 solver.cpp:228] Iteration 11800, loss = 0.638894
I0918 19:28:09.906539 24660 solver.cpp:244]     Train net output #0: loss = 0.058631 (* 1 = 0.058631 loss)
I0918 19:28:09.906570 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.19652 (* 0.4 = 0.478607 loss)
I0918 19:28:09.906586 24660 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0918 19:28:49.743242 24660 solver.cpp:228] Iteration 11900, loss = 0.648834
I0918 19:28:49.743407 24660 solver.cpp:244]     Train net output #0: loss = 0.0127236 (* 1 = 0.0127236 loss)
I0918 19:28:49.743434 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.07068 (* 0.4 = 0.428271 loss)
I0918 19:28:49.743455 24660 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0918 19:29:29.019559 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_12000.caffemodel
I0918 19:29:48.567540 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_12000.solverstate
I0918 19:29:49.059602 24660 solver.cpp:337] Iteration 12000, Testing net (#0)
I0918 19:30:07.818915 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8295
I0918 19:30:07.819102 24660 solver.cpp:404]     Test net output #1: loss = 0.652099 (* 1 = 0.652099 loss)
I0918 19:30:07.819128 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.68604 (* 0.4 = 1.07442 loss)
I0918 19:30:07.993731 24660 solver.cpp:228] Iteration 12000, loss = 0.672064
I0918 19:30:07.993811 24660 solver.cpp:244]     Train net output #0: loss = 0.0477766 (* 1 = 0.0477766 loss)
I0918 19:30:07.993835 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.64611 (* 0.4 = 0.658445 loss)
I0918 19:30:07.993860 24660 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0918 19:30:47.786933 24660 solver.cpp:228] Iteration 12100, loss = 0.630962
I0918 19:30:47.787109 24660 solver.cpp:244]     Train net output #0: loss = 0.212408 (* 1 = 0.212408 loss)
I0918 19:30:47.787137 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.4513 (* 0.4 = 0.58052 loss)
I0918 19:30:47.787158 24660 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0918 19:31:27.519700 24660 solver.cpp:228] Iteration 12200, loss = 0.648976
I0918 19:31:27.519990 24660 solver.cpp:244]     Train net output #0: loss = 0.0344369 (* 1 = 0.0344369 loss)
I0918 19:31:27.520018 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.11257 (* 0.4 = 0.445027 loss)
I0918 19:31:27.520047 24660 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0918 19:32:07.509910 24660 solver.cpp:228] Iteration 12300, loss = 0.614012
I0918 19:32:07.510165 24660 solver.cpp:244]     Train net output #0: loss = 0.0882848 (* 1 = 0.0882848 loss)
I0918 19:32:07.510196 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.66263 (* 0.4 = 0.665052 loss)
I0918 19:32:07.510211 24660 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0918 19:32:47.446204 24660 solver.cpp:228] Iteration 12400, loss = 0.625305
I0918 19:32:47.446399 24660 solver.cpp:244]     Train net output #0: loss = 0.0113694 (* 1 = 0.0113694 loss)
I0918 19:32:47.446427 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.973207 (* 0.4 = 0.389283 loss)
I0918 19:32:47.446451 24660 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0918 19:33:27.280905 24660 solver.cpp:228] Iteration 12500, loss = 0.626775
I0918 19:33:27.281106 24660 solver.cpp:244]     Train net output #0: loss = 0.0401412 (* 1 = 0.0401412 loss)
I0918 19:33:27.281134 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.244 (* 0.4 = 0.497599 loss)
I0918 19:33:27.281159 24660 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0918 19:34:07.220381 24660 solver.cpp:228] Iteration 12600, loss = 0.59136
I0918 19:34:07.220620 24660 solver.cpp:244]     Train net output #0: loss = 0.0316426 (* 1 = 0.0316426 loss)
I0918 19:34:07.220655 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.03577 (* 0.4 = 0.41431 loss)
I0918 19:34:07.220679 24660 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0918 19:34:47.119393 24660 solver.cpp:228] Iteration 12700, loss = 0.632279
I0918 19:34:47.119653 24660 solver.cpp:244]     Train net output #0: loss = 0.0237216 (* 1 = 0.0237216 loss)
I0918 19:34:47.119684 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.52137 (* 0.4 = 0.608548 loss)
I0918 19:34:47.119699 24660 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0918 19:35:26.965646 24660 solver.cpp:228] Iteration 12800, loss = 0.656613
I0918 19:35:26.965896 24660 solver.cpp:244]     Train net output #0: loss = 0.0383793 (* 1 = 0.0383793 loss)
I0918 19:35:26.965929 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.53812 (* 0.4 = 0.615247 loss)
I0918 19:35:26.965943 24660 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0918 19:36:06.873782 24660 solver.cpp:228] Iteration 12900, loss = 0.595428
I0918 19:36:06.873988 24660 solver.cpp:244]     Train net output #0: loss = 0.154992 (* 1 = 0.154992 loss)
I0918 19:36:06.874014 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.02765 (* 0.4 = 0.411059 loss)
I0918 19:36:06.874045 24660 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0918 19:36:46.372156 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_13000.caffemodel
I0918 19:36:51.974509 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_13000.solverstate
I0918 19:36:52.461493 24660 solver.cpp:337] Iteration 13000, Testing net (#0)
I0918 19:37:11.301367 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.831
I0918 19:37:11.301453 24660 solver.cpp:404]     Test net output #1: loss = 0.661862 (* 1 = 0.661862 loss)
I0918 19:37:11.301479 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.61826 (* 0.4 = 1.04731 loss)
I0918 19:37:11.472120 24660 solver.cpp:228] Iteration 13000, loss = 0.623054
I0918 19:37:11.472206 24660 solver.cpp:244]     Train net output #0: loss = 0.0148051 (* 1 = 0.0148051 loss)
I0918 19:37:11.472231 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.769053 (* 0.4 = 0.307621 loss)
I0918 19:37:11.472261 24660 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0918 19:37:51.340525 24660 solver.cpp:228] Iteration 13100, loss = 0.581414
I0918 19:37:51.340806 24660 solver.cpp:244]     Train net output #0: loss = 0.0773455 (* 1 = 0.0773455 loss)
I0918 19:37:51.340833 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.67504 (* 0.4 = 0.670018 loss)
I0918 19:37:51.340867 24660 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0918 19:38:31.267382 24660 solver.cpp:228] Iteration 13200, loss = 0.578887
I0918 19:38:31.267586 24660 solver.cpp:244]     Train net output #0: loss = 0.0137857 (* 1 = 0.0137857 loss)
I0918 19:38:31.267614 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.08136 (* 0.4 = 0.432543 loss)
I0918 19:38:31.267643 24660 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0918 19:39:11.099108 24660 solver.cpp:228] Iteration 13300, loss = 0.624742
I0918 19:39:11.099339 24660 solver.cpp:244]     Train net output #0: loss = 0.124641 (* 1 = 0.124641 loss)
I0918 19:39:11.099370 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.48874 (* 0.4 = 0.595494 loss)
I0918 19:39:11.099385 24660 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0918 19:39:50.977115 24660 solver.cpp:228] Iteration 13400, loss = 0.566969
I0918 19:39:50.977377 24660 solver.cpp:244]     Train net output #0: loss = 0.0118522 (* 1 = 0.0118522 loss)
I0918 19:39:50.977408 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.956737 (* 0.4 = 0.382695 loss)
I0918 19:39:50.977422 24660 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0918 19:40:30.974225 24660 solver.cpp:228] Iteration 13500, loss = 0.591276
I0918 19:40:30.974416 24660 solver.cpp:244]     Train net output #0: loss = 0.032865 (* 1 = 0.032865 loss)
I0918 19:40:30.974442 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.20279 (* 0.4 = 0.481117 loss)
I0918 19:40:30.974467 24660 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0918 19:41:02.682327 24660 solver.cpp:228] Iteration 13600, loss = 0.641986
I0918 19:41:02.682528 24660 solver.cpp:244]     Train net output #0: loss = 0.267131 (* 1 = 0.267131 loss)
I0918 19:41:02.682555 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.8957 (* 0.4 = 0.758281 loss)
I0918 19:41:02.682579 24660 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0918 19:41:31.980116 24660 solver.cpp:228] Iteration 13700, loss = 0.54575
I0918 19:41:31.980213 24660 solver.cpp:244]     Train net output #0: loss = 0.21408 (* 1 = 0.21408 loss)
I0918 19:41:31.980238 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.54655 (* 0.4 = 0.618621 loss)
I0918 19:41:31.980260 24660 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0918 19:42:05.882871 24660 solver.cpp:228] Iteration 13800, loss = 0.59918
I0918 19:42:05.883074 24660 solver.cpp:244]     Train net output #0: loss = 0.0134245 (* 1 = 0.0134245 loss)
I0918 19:42:05.883100 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.735582 (* 0.4 = 0.294233 loss)
I0918 19:42:05.883136 24660 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0918 19:42:39.835719 24660 solver.cpp:228] Iteration 13900, loss = 0.540801
I0918 19:42:39.835985 24660 solver.cpp:244]     Train net output #0: loss = 0.0765314 (* 1 = 0.0765314 loss)
I0918 19:42:39.836015 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.28378 (* 0.4 = 0.513512 loss)
I0918 19:42:39.836030 24660 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0918 19:43:13.404640 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_14000.caffemodel
I0918 19:43:22.277559 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_14000.solverstate
I0918 19:43:22.794661 24660 solver.cpp:337] Iteration 14000, Testing net (#0)
I0918 19:43:38.728255 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.82925
I0918 19:43:38.728353 24660 solver.cpp:404]     Test net output #1: loss = 0.670533 (* 1 = 0.670533 loss)
I0918 19:43:38.728375 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.66487 (* 0.4 = 1.06595 loss)
I0918 19:43:38.892001 24660 solver.cpp:228] Iteration 14000, loss = 0.565881
I0918 19:43:38.892084 24660 solver.cpp:244]     Train net output #0: loss = 0.028566 (* 1 = 0.028566 loss)
I0918 19:43:38.892107 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.50798 (* 0.4 = 0.603193 loss)
I0918 19:43:38.892132 24660 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0918 19:44:14.539496 24660 solver.cpp:228] Iteration 14100, loss = 0.583802
I0918 19:44:14.539755 24660 solver.cpp:244]     Train net output #0: loss = 0.020887 (* 1 = 0.020887 loss)
I0918 19:44:14.539783 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.5054 (* 0.4 = 0.602158 loss)
I0918 19:44:14.539810 24660 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0918 19:44:54.403667 24660 solver.cpp:228] Iteration 14200, loss = 0.559722
I0918 19:44:54.403842 24660 solver.cpp:244]     Train net output #0: loss = 0.00661627 (* 1 = 0.00661627 loss)
I0918 19:44:54.403869 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.696201 (* 0.4 = 0.27848 loss)
I0918 19:44:54.403892 24660 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0918 19:45:34.234869 24660 solver.cpp:228] Iteration 14300, loss = 0.551863
I0918 19:45:34.235129 24660 solver.cpp:244]     Train net output #0: loss = 0.0297739 (* 1 = 0.0297739 loss)
I0918 19:45:34.235160 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.01877 (* 0.4 = 0.407509 loss)
I0918 19:45:34.235174 24660 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0918 19:46:13.965652 24660 solver.cpp:228] Iteration 14400, loss = 0.583157
I0918 19:46:13.965864 24660 solver.cpp:244]     Train net output #0: loss = 0.0646873 (* 1 = 0.0646873 loss)
I0918 19:46:13.965891 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.47087 (* 0.4 = 0.58835 loss)
I0918 19:46:13.965914 24660 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0918 19:46:53.858921 24660 solver.cpp:228] Iteration 14500, loss = 0.574672
I0918 19:46:53.859102 24660 solver.cpp:244]     Train net output #0: loss = 0.163576 (* 1 = 0.163576 loss)
I0918 19:46:53.859128 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.29975 (* 0.4 = 0.5199 loss)
I0918 19:46:53.859153 24660 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0918 19:47:33.721757 24660 solver.cpp:228] Iteration 14600, loss = 0.570711
I0918 19:47:33.722018 24660 solver.cpp:244]     Train net output #0: loss = 0.00918855 (* 1 = 0.00918855 loss)
I0918 19:47:33.722048 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.599374 (* 0.4 = 0.23975 loss)
I0918 19:47:33.722062 24660 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0918 19:48:13.520519 24660 solver.cpp:228] Iteration 14700, loss = 0.531869
I0918 19:48:13.520759 24660 solver.cpp:244]     Train net output #0: loss = 0.014814 (* 1 = 0.014814 loss)
I0918 19:48:13.520789 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.18166 (* 0.4 = 0.472663 loss)
I0918 19:48:13.520805 24660 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0918 19:48:53.455843 24660 solver.cpp:228] Iteration 14800, loss = 0.547403
I0918 19:48:53.456117 24660 solver.cpp:244]     Train net output #0: loss = 0.0683888 (* 1 = 0.0683888 loss)
I0918 19:48:53.456147 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.20945 (* 0.4 = 0.483782 loss)
I0918 19:48:53.456164 24660 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0918 19:49:33.377895 24660 solver.cpp:228] Iteration 14900, loss = 0.56223
I0918 19:49:33.378098 24660 solver.cpp:244]     Train net output #0: loss = 0.0111686 (* 1 = 0.0111686 loss)
I0918 19:49:33.378125 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.03125 (* 0.4 = 0.4125 loss)
I0918 19:49:33.378147 24660 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0918 19:50:12.734081 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_15000.caffemodel
I0918 19:50:16.787418 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_15000.solverstate
I0918 19:50:17.286253 24660 solver.cpp:337] Iteration 15000, Testing net (#0)
I0918 19:50:36.042798 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8305
I0918 19:50:36.042896 24660 solver.cpp:404]     Test net output #1: loss = 0.676519 (* 1 = 0.676519 loss)
I0918 19:50:36.042919 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.67672 (* 0.4 = 1.07069 loss)
I0918 19:50:36.219877 24660 solver.cpp:228] Iteration 15000, loss = 0.529276
I0918 19:50:36.219962 24660 solver.cpp:244]     Train net output #0: loss = 0.00778997 (* 1 = 0.00778997 loss)
I0918 19:50:36.219990 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.95422 (* 0.4 = 0.381688 loss)
I0918 19:50:36.220015 24660 sgd_solver.cpp:46] MultiStep Status: Iteration 15000, step = 1
I0918 19:50:36.220042 24660 sgd_solver.cpp:106] Iteration 15000, lr = 1e-05
I0918 19:51:16.206171 24660 solver.cpp:228] Iteration 15100, loss = 0.545942
I0918 19:51:16.206492 24660 solver.cpp:244]     Train net output #0: loss = 0.0245462 (* 1 = 0.0245462 loss)
I0918 19:51:16.206522 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.26702 (* 0.4 = 0.506809 loss)
I0918 19:51:16.206537 24660 sgd_solver.cpp:106] Iteration 15100, lr = 1e-05
I0918 19:51:56.143589 24660 solver.cpp:228] Iteration 15200, loss = 0.593037
I0918 19:51:56.143798 24660 solver.cpp:244]     Train net output #0: loss = 0.0705696 (* 1 = 0.0705696 loss)
I0918 19:51:56.143824 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.79566 (* 0.4 = 0.718265 loss)
I0918 19:51:56.143846 24660 sgd_solver.cpp:106] Iteration 15200, lr = 1e-05
I0918 19:52:36.042160 24660 solver.cpp:228] Iteration 15300, loss = 0.524439
I0918 19:52:36.042356 24660 solver.cpp:244]     Train net output #0: loss = 0.105424 (* 1 = 0.105424 loss)
I0918 19:52:36.042382 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.42748 (* 0.4 = 0.570993 loss)
I0918 19:52:36.042403 24660 sgd_solver.cpp:106] Iteration 15300, lr = 1e-05
I0918 19:53:15.965514 24660 solver.cpp:228] Iteration 15400, loss = 0.526026
I0918 19:53:15.965708 24660 solver.cpp:244]     Train net output #0: loss = 0.0151946 (* 1 = 0.0151946 loss)
I0918 19:53:15.965736 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.81378 (* 0.4 = 0.325512 loss)
I0918 19:53:15.965760 24660 sgd_solver.cpp:106] Iteration 15400, lr = 1e-05
I0918 19:53:55.775804 24660 solver.cpp:228] Iteration 15500, loss = 0.488572
I0918 19:53:55.775993 24660 solver.cpp:244]     Train net output #0: loss = 0.0560028 (* 1 = 0.0560028 loss)
I0918 19:53:55.776020 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.38972 (* 0.4 = 0.555886 loss)
I0918 19:53:55.776041 24660 sgd_solver.cpp:106] Iteration 15500, lr = 1e-05
I0918 19:54:35.629298 24660 solver.cpp:228] Iteration 15600, loss = 0.49229
I0918 19:54:35.629523 24660 solver.cpp:244]     Train net output #0: loss = 0.0461953 (* 1 = 0.0461953 loss)
I0918 19:54:35.629554 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.32699 (* 0.4 = 0.530795 loss)
I0918 19:54:35.629568 24660 sgd_solver.cpp:106] Iteration 15600, lr = 1e-05
I0918 19:55:15.402834 24660 solver.cpp:228] Iteration 15700, loss = 0.506162
I0918 19:55:15.403096 24660 solver.cpp:244]     Train net output #0: loss = 0.0425532 (* 1 = 0.0425532 loss)
I0918 19:55:15.403128 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.31657 (* 0.4 = 0.526627 loss)
I0918 19:55:15.403142 24660 sgd_solver.cpp:106] Iteration 15700, lr = 1e-05
I0918 19:55:55.378561 24660 solver.cpp:228] Iteration 15800, loss = 0.463099
I0918 19:55:55.378756 24660 solver.cpp:244]     Train net output #0: loss = 0.0190063 (* 1 = 0.0190063 loss)
I0918 19:55:55.378782 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.05262 (* 0.4 = 0.42105 loss)
I0918 19:55:55.378804 24660 sgd_solver.cpp:106] Iteration 15800, lr = 1e-05
I0918 19:56:35.356401 24660 solver.cpp:228] Iteration 15900, loss = 0.51291
I0918 19:56:35.356643 24660 solver.cpp:244]     Train net output #0: loss = 0.0266063 (* 1 = 0.0266063 loss)
I0918 19:56:35.356674 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.23324 (* 0.4 = 0.493297 loss)
I0918 19:56:35.356689 24660 sgd_solver.cpp:106] Iteration 15900, lr = 1e-05
I0918 19:57:14.866446 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_16000.caffemodel
I0918 19:57:18.993787 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_16000.solverstate
I0918 19:57:19.736591 24660 solver.cpp:337] Iteration 16000, Testing net (#0)
I0918 19:57:38.492411 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.833
I0918 19:57:38.492511 24660 solver.cpp:404]     Test net output #1: loss = 0.662192 (* 1 = 0.662192 loss)
I0918 19:57:38.492533 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.63239 (* 0.4 = 1.05296 loss)
I0918 19:57:38.699268 24660 solver.cpp:228] Iteration 16000, loss = 0.56146
I0918 19:57:38.699352 24660 solver.cpp:244]     Train net output #0: loss = 0.0406493 (* 1 = 0.0406493 loss)
I0918 19:57:38.699379 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.47851 (* 0.4 = 0.591405 loss)
I0918 19:57:38.699417 24660 sgd_solver.cpp:106] Iteration 16000, lr = 1e-05
I0918 19:58:18.567939 24660 solver.cpp:228] Iteration 16100, loss = 0.492995
I0918 19:58:18.568181 24660 solver.cpp:244]     Train net output #0: loss = 0.0477554 (* 1 = 0.0477554 loss)
I0918 19:58:18.568212 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.39878 (* 0.4 = 0.559513 loss)
I0918 19:58:18.568226 24660 sgd_solver.cpp:106] Iteration 16100, lr = 1e-05
I0918 19:58:58.516867 24660 solver.cpp:228] Iteration 16200, loss = 0.520345
I0918 19:58:58.517112 24660 solver.cpp:244]     Train net output #0: loss = 0.0408735 (* 1 = 0.0408735 loss)
I0918 19:58:58.517143 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.20434 (* 0.4 = 0.481736 loss)
I0918 19:58:58.517158 24660 sgd_solver.cpp:106] Iteration 16200, lr = 1e-05
I0918 19:59:38.468188 24660 solver.cpp:228] Iteration 16300, loss = 0.48226
I0918 19:59:38.468423 24660 solver.cpp:244]     Train net output #0: loss = 0.0117472 (* 1 = 0.0117472 loss)
I0918 19:59:38.468454 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.09265 (* 0.4 = 0.43706 loss)
I0918 19:59:38.468474 24660 sgd_solver.cpp:106] Iteration 16300, lr = 1e-05
I0918 20:00:18.300248 24660 solver.cpp:228] Iteration 16400, loss = 0.484708
I0918 20:00:18.300438 24660 solver.cpp:244]     Train net output #0: loss = 0.0775838 (* 1 = 0.0775838 loss)
I0918 20:00:18.300465 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.32645 (* 0.4 = 0.530579 loss)
I0918 20:00:18.300487 24660 sgd_solver.cpp:106] Iteration 16400, lr = 1e-05
I0918 20:00:58.202556 24660 solver.cpp:228] Iteration 16500, loss = 0.485001
I0918 20:00:58.202754 24660 solver.cpp:244]     Train net output #0: loss = 0.0200362 (* 1 = 0.0200362 loss)
I0918 20:00:58.202781 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.09707 (* 0.4 = 0.438827 loss)
I0918 20:00:58.202810 24660 sgd_solver.cpp:106] Iteration 16500, lr = 1e-05
I0918 20:01:38.041826 24660 solver.cpp:228] Iteration 16600, loss = 0.460398
I0918 20:01:38.042074 24660 solver.cpp:244]     Train net output #0: loss = 0.0142179 (* 1 = 0.0142179 loss)
I0918 20:01:38.042105 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04102 (* 0.4 = 0.416409 loss)
I0918 20:01:38.042120 24660 sgd_solver.cpp:106] Iteration 16600, lr = 1e-05
I0918 20:02:04.959942 24660 solver.cpp:228] Iteration 16700, loss = 0.503427
I0918 20:02:04.960036 24660 solver.cpp:244]     Train net output #0: loss = 0.0172409 (* 1 = 0.0172409 loss)
I0918 20:02:04.960060 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.13701 (* 0.4 = 0.454803 loss)
I0918 20:02:04.960083 24660 sgd_solver.cpp:106] Iteration 16700, lr = 1e-05
I0918 20:02:36.566562 24660 solver.cpp:228] Iteration 16800, loss = 0.5543
I0918 20:02:36.566823 24660 solver.cpp:244]     Train net output #0: loss = 0.030021 (* 1 = 0.030021 loss)
I0918 20:02:36.566851 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.34009 (* 0.4 = 0.536038 loss)
I0918 20:02:36.566867 24660 sgd_solver.cpp:106] Iteration 16800, lr = 1e-05
I0918 20:03:10.493762 24660 solver.cpp:228] Iteration 16900, loss = 0.503429
I0918 20:03:10.494087 24660 solver.cpp:244]     Train net output #0: loss = 0.108873 (* 1 = 0.108873 loss)
I0918 20:03:10.494118 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.34417 (* 0.4 = 0.537668 loss)
I0918 20:03:10.494134 24660 sgd_solver.cpp:106] Iteration 16900, lr = 1e-05
I0918 20:03:44.080474 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_17000.caffemodel
I0918 20:03:47.688875 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_17000.solverstate
I0918 20:03:48.182442 24660 solver.cpp:337] Iteration 17000, Testing net (#0)
I0918 20:04:04.128139 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.83325
I0918 20:04:04.128242 24660 solver.cpp:404]     Test net output #1: loss = 0.656632 (* 1 = 0.656632 loss)
I0918 20:04:04.128267 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.6348 (* 0.4 = 1.05392 loss)
I0918 20:04:04.284453 24660 solver.cpp:228] Iteration 17000, loss = 0.494026
I0918 20:04:04.284546 24660 solver.cpp:244]     Train net output #0: loss = 0.00882153 (* 1 = 0.00882153 loss)
I0918 20:04:04.284571 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.805708 (* 0.4 = 0.322283 loss)
I0918 20:04:04.284595 24660 sgd_solver.cpp:106] Iteration 17000, lr = 1e-05
I0918 20:04:38.234606 24660 solver.cpp:228] Iteration 17100, loss = 0.482731
I0918 20:04:38.234791 24660 solver.cpp:244]     Train net output #0: loss = 0.106506 (* 1 = 0.106506 loss)
I0918 20:04:38.234820 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.57952 (* 0.4 = 0.631809 loss)
I0918 20:04:38.234843 24660 sgd_solver.cpp:106] Iteration 17100, lr = 1e-05
I0918 20:05:13.016496 24660 solver.cpp:228] Iteration 17200, loss = 0.492956
I0918 20:05:13.016696 24660 solver.cpp:244]     Train net output #0: loss = 0.00703688 (* 1 = 0.00703688 loss)
I0918 20:05:13.016727 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.10487 (* 0.4 = 0.441948 loss)
I0918 20:05:13.016751 24660 sgd_solver.cpp:106] Iteration 17200, lr = 1e-05
I0918 20:05:52.690138 24660 solver.cpp:228] Iteration 17300, loss = 0.491651
I0918 20:05:52.690337 24660 solver.cpp:244]     Train net output #0: loss = 0.0270538 (* 1 = 0.0270538 loss)
I0918 20:05:52.690369 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.848317 (* 0.4 = 0.339327 loss)
I0918 20:05:52.690392 24660 sgd_solver.cpp:106] Iteration 17300, lr = 1e-05
I0918 20:06:32.551430 24660 solver.cpp:228] Iteration 17400, loss = 0.470262
I0918 20:06:32.551697 24660 solver.cpp:244]     Train net output #0: loss = 0.0101044 (* 1 = 0.0101044 loss)
I0918 20:06:32.551728 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.924737 (* 0.4 = 0.369895 loss)
I0918 20:06:32.551743 24660 sgd_solver.cpp:106] Iteration 17400, lr = 1e-05
I0918 20:07:12.511576 24660 solver.cpp:228] Iteration 17500, loss = 0.495991
I0918 20:07:12.511785 24660 solver.cpp:244]     Train net output #0: loss = 0.0145553 (* 1 = 0.0145553 loss)
I0918 20:07:12.511816 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.19471 (* 0.4 = 0.477885 loss)
I0918 20:07:12.511831 24660 sgd_solver.cpp:106] Iteration 17500, lr = 1e-05
I0918 20:07:52.443284 24660 solver.cpp:228] Iteration 17600, loss = 0.543422
I0918 20:07:52.443475 24660 solver.cpp:244]     Train net output #0: loss = 0.0491399 (* 1 = 0.0491399 loss)
I0918 20:07:52.443505 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.61996 (* 0.4 = 0.647985 loss)
I0918 20:07:52.443527 24660 sgd_solver.cpp:106] Iteration 17600, lr = 1e-05
I0918 20:08:32.104655 24660 solver.cpp:228] Iteration 17700, loss = 0.493488
I0918 20:08:32.104861 24660 solver.cpp:244]     Train net output #0: loss = 0.0479342 (* 1 = 0.0479342 loss)
I0918 20:08:32.104892 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.39479 (* 0.4 = 0.557918 loss)
I0918 20:08:32.104914 24660 sgd_solver.cpp:106] Iteration 17700, lr = 1e-05
I0918 20:09:12.037209 24660 solver.cpp:228] Iteration 17800, loss = 0.505683
I0918 20:09:12.037470 24660 solver.cpp:244]     Train net output #0: loss = 0.0198614 (* 1 = 0.0198614 loss)
I0918 20:09:12.037506 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.965956 (* 0.4 = 0.386382 loss)
I0918 20:09:12.037529 24660 sgd_solver.cpp:106] Iteration 17800, lr = 1e-05
I0918 20:09:51.930308 24660 solver.cpp:228] Iteration 17900, loss = 0.476087
I0918 20:09:51.930506 24660 solver.cpp:244]     Train net output #0: loss = 0.0605328 (* 1 = 0.0605328 loss)
I0918 20:09:51.930536 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.67626 (* 0.4 = 0.670506 loss)
I0918 20:09:51.930559 24660 sgd_solver.cpp:106] Iteration 17900, lr = 1e-05
I0918 20:10:31.394443 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_18000.caffemodel
I0918 20:10:34.925570 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_18000.solverstate
I0918 20:10:35.415051 24660 solver.cpp:337] Iteration 18000, Testing net (#0)
I0918 20:10:54.292287 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.83775
I0918 20:10:54.292389 24660 solver.cpp:404]     Test net output #1: loss = 0.664335 (* 1 = 0.664335 loss)
I0918 20:10:54.292413 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.6047 (* 0.4 = 1.04188 loss)
I0918 20:10:54.467195 24660 solver.cpp:228] Iteration 18000, loss = 0.487618
I0918 20:10:54.467284 24660 solver.cpp:244]     Train net output #0: loss = 0.014641 (* 1 = 0.014641 loss)
I0918 20:10:54.467310 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.06221 (* 0.4 = 0.424882 loss)
I0918 20:10:54.467335 24660 sgd_solver.cpp:106] Iteration 18000, lr = 1e-05
I0918 20:11:34.445118 24660 solver.cpp:228] Iteration 18100, loss = 0.488003
I0918 20:11:34.445355 24660 solver.cpp:244]     Train net output #0: loss = 0.0173054 (* 1 = 0.0173054 loss)
I0918 20:11:34.445386 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04777 (* 0.4 = 0.419109 loss)
I0918 20:11:34.445408 24660 sgd_solver.cpp:106] Iteration 18100, lr = 1e-05
I0918 20:12:14.270469 24660 solver.cpp:228] Iteration 18200, loss = 0.478142
I0918 20:12:14.270714 24660 solver.cpp:244]     Train net output #0: loss = 0.013383 (* 1 = 0.013383 loss)
I0918 20:12:14.270743 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.01767 (* 0.4 = 0.407069 loss)
I0918 20:12:14.270759 24660 sgd_solver.cpp:106] Iteration 18200, lr = 1e-05
I0918 20:12:54.272927 24660 solver.cpp:228] Iteration 18300, loss = 0.49568
I0918 20:12:54.273190 24660 solver.cpp:244]     Train net output #0: loss = 0.015842 (* 1 = 0.015842 loss)
I0918 20:12:54.273221 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.08028 (* 0.4 = 0.432111 loss)
I0918 20:12:54.273236 24660 sgd_solver.cpp:106] Iteration 18300, lr = 1e-05
I0918 20:13:33.981871 24660 solver.cpp:228] Iteration 18400, loss = 0.538366
I0918 20:13:33.982096 24660 solver.cpp:244]     Train net output #0: loss = 0.0172323 (* 1 = 0.0172323 loss)
I0918 20:13:33.982122 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.28965 (* 0.4 = 0.515861 loss)
I0918 20:13:33.982144 24660 sgd_solver.cpp:106] Iteration 18400, lr = 1e-05
I0918 20:14:13.730077 24660 solver.cpp:228] Iteration 18500, loss = 0.480031
I0918 20:14:13.730326 24660 solver.cpp:244]     Train net output #0: loss = 0.112952 (* 1 = 0.112952 loss)
I0918 20:14:13.730357 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.15499 (* 0.4 = 0.461998 loss)
I0918 20:14:13.730374 24660 sgd_solver.cpp:106] Iteration 18500, lr = 1e-05
I0918 20:14:53.554497 24660 solver.cpp:228] Iteration 18600, loss = 0.502334
I0918 20:14:53.554690 24660 solver.cpp:244]     Train net output #0: loss = 0.0501426 (* 1 = 0.0501426 loss)
I0918 20:14:53.554718 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04545 (* 0.4 = 0.418179 loss)
I0918 20:14:53.554739 24660 sgd_solver.cpp:106] Iteration 18600, lr = 1e-05
I0918 20:15:33.375838 24660 solver.cpp:228] Iteration 18700, loss = 0.474282
I0918 20:15:33.376106 24660 solver.cpp:244]     Train net output #0: loss = 0.112056 (* 1 = 0.112056 loss)
I0918 20:15:33.376135 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.986166 (* 0.4 = 0.394466 loss)
I0918 20:15:33.376149 24660 sgd_solver.cpp:106] Iteration 18700, lr = 1e-05
I0918 20:16:13.273834 24660 solver.cpp:228] Iteration 18800, loss = 0.462353
I0918 20:16:13.274101 24660 solver.cpp:244]     Train net output #0: loss = 0.0114325 (* 1 = 0.0114325 loss)
I0918 20:16:13.274132 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.0621 (* 0.4 = 0.424839 loss)
I0918 20:16:13.274147 24660 sgd_solver.cpp:106] Iteration 18800, lr = 1e-05
I0918 20:16:53.041609 24660 solver.cpp:228] Iteration 18900, loss = 0.487403
I0918 20:16:53.041872 24660 solver.cpp:244]     Train net output #0: loss = 0.0405896 (* 1 = 0.0405896 loss)
I0918 20:16:53.041903 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.05761 (* 0.4 = 0.423043 loss)
I0918 20:16:53.041918 24660 sgd_solver.cpp:106] Iteration 18900, lr = 1e-05
I0918 20:17:32.425544 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_19000.caffemodel
I0918 20:17:35.888576 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_19000.solverstate
I0918 20:17:36.373775 24660 solver.cpp:337] Iteration 19000, Testing net (#0)
I0918 20:17:55.151237 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.83375
I0918 20:17:55.151332 24660 solver.cpp:404]     Test net output #1: loss = 0.659724 (* 1 = 0.659724 loss)
I0918 20:17:55.151355 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.61148 (* 0.4 = 1.04459 loss)
I0918 20:17:55.394876 24660 solver.cpp:228] Iteration 19000, loss = 0.463911
I0918 20:17:55.394954 24660 solver.cpp:244]     Train net output #0: loss = 0.0109169 (* 1 = 0.0109169 loss)
I0918 20:17:55.394978 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.838308 (* 0.4 = 0.335323 loss)
I0918 20:17:55.395004 24660 sgd_solver.cpp:106] Iteration 19000, lr = 1e-05
I0918 20:18:35.340041 24660 solver.cpp:228] Iteration 19100, loss = 0.488904
I0918 20:18:35.340225 24660 solver.cpp:244]     Train net output #0: loss = 0.046935 (* 1 = 0.046935 loss)
I0918 20:18:35.340251 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.39066 (* 0.4 = 0.556265 loss)
I0918 20:18:35.340272 24660 sgd_solver.cpp:106] Iteration 19100, lr = 1e-05
I0918 20:19:15.304450 24660 solver.cpp:228] Iteration 19200, loss = 0.531031
I0918 20:19:15.304631 24660 solver.cpp:244]     Train net output #0: loss = 0.0178253 (* 1 = 0.0178253 loss)
I0918 20:19:15.304657 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.30789 (* 0.4 = 0.523158 loss)
I0918 20:19:15.304679 24660 sgd_solver.cpp:106] Iteration 19200, lr = 1e-05
I0918 20:19:55.066244 24660 solver.cpp:228] Iteration 19300, loss = 0.475738
I0918 20:19:55.066429 24660 solver.cpp:244]     Train net output #0: loss = 0.118161 (* 1 = 0.118161 loss)
I0918 20:19:55.066449 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.801933 (* 0.4 = 0.320773 loss)
I0918 20:19:55.066463 24660 sgd_solver.cpp:106] Iteration 19300, lr = 1e-05
I0918 20:20:34.945199 24660 solver.cpp:228] Iteration 19400, loss = 0.501933
I0918 20:20:34.945405 24660 solver.cpp:244]     Train net output #0: loss = 0.0068049 (* 1 = 0.0068049 loss)
I0918 20:20:34.945436 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.746939 (* 0.4 = 0.298775 loss)
I0918 20:20:34.945457 24660 sgd_solver.cpp:106] Iteration 19400, lr = 1e-05
I0918 20:21:14.812250 24660 solver.cpp:228] Iteration 19500, loss = 0.468808
I0918 20:21:14.812373 24660 solver.cpp:244]     Train net output #0: loss = 0.0170446 (* 1 = 0.0170446 loss)
I0918 20:21:14.812399 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.796546 (* 0.4 = 0.318618 loss)
I0918 20:21:14.812419 24660 sgd_solver.cpp:106] Iteration 19500, lr = 1e-05
I0918 20:21:54.745375 24660 solver.cpp:228] Iteration 19600, loss = 0.464914
I0918 20:21:54.745628 24660 solver.cpp:244]     Train net output #0: loss = 0.0360688 (* 1 = 0.0360688 loss)
I0918 20:21:54.745658 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.02124 (* 0.4 = 0.408496 loss)
I0918 20:21:54.745683 24660 sgd_solver.cpp:106] Iteration 19600, lr = 1e-05
I0918 20:22:34.753309 24660 solver.cpp:228] Iteration 19700, loss = 0.489128
I0918 20:22:34.753576 24660 solver.cpp:244]     Train net output #0: loss = 0.0143257 (* 1 = 0.0143257 loss)
I0918 20:22:34.753607 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.753074 (* 0.4 = 0.30123 loss)
I0918 20:22:34.753621 24660 sgd_solver.cpp:106] Iteration 19700, lr = 1e-05
I0918 20:23:07.312171 24660 solver.cpp:228] Iteration 19800, loss = 0.466821
I0918 20:23:07.312374 24660 solver.cpp:244]     Train net output #0: loss = 0.0092907 (* 1 = 0.0092907 loss)
I0918 20:23:07.312402 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.739647 (* 0.4 = 0.295859 loss)
I0918 20:23:07.312430 24660 sgd_solver.cpp:106] Iteration 19800, lr = 1e-05
I0918 20:23:29.995098 24660 solver.cpp:228] Iteration 19900, loss = 0.489788
I0918 20:23:29.995195 24660 solver.cpp:244]     Train net output #0: loss = 0.0354015 (* 1 = 0.0354015 loss)
I0918 20:23:29.995219 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.12568 (* 0.4 = 0.450273 loss)
I0918 20:23:29.995239 24660 sgd_solver.cpp:106] Iteration 19900, lr = 1e-05
I0918 20:24:03.609864 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_20000.caffemodel
I0918 20:24:08.670430 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_20000.solverstate
I0918 20:24:09.243562 24660 solver.cpp:337] Iteration 20000, Testing net (#0)
I0918 20:24:25.186914 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8335
I0918 20:24:25.187013 24660 solver.cpp:404]     Test net output #1: loss = 0.666309 (* 1 = 0.666309 loss)
I0918 20:24:25.187036 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.64365 (* 0.4 = 1.05746 loss)
I0918 20:24:25.356047 24660 solver.cpp:228] Iteration 20000, loss = 0.514054
I0918 20:24:25.356135 24660 solver.cpp:244]     Train net output #0: loss = 0.0943713 (* 1 = 0.0943713 loss)
I0918 20:24:25.356159 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.47916 (* 0.4 = 0.591664 loss)
I0918 20:24:25.356184 24660 sgd_solver.cpp:106] Iteration 20000, lr = 1e-05
I0918 20:24:59.304034 24660 solver.cpp:228] Iteration 20100, loss = 0.479014
I0918 20:24:59.304224 24660 solver.cpp:244]     Train net output #0: loss = 0.0678488 (* 1 = 0.0678488 loss)
I0918 20:24:59.304251 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.14898 (* 0.4 = 0.459593 loss)
I0918 20:24:59.304281 24660 sgd_solver.cpp:106] Iteration 20100, lr = 1e-05
I0918 20:25:33.279451 24660 solver.cpp:228] Iteration 20200, loss = 0.498325
I0918 20:25:33.279605 24660 solver.cpp:244]     Train net output #0: loss = 0.0464266 (* 1 = 0.0464266 loss)
I0918 20:25:33.279642 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.883517 (* 0.4 = 0.353407 loss)
I0918 20:25:33.279675 24660 sgd_solver.cpp:106] Iteration 20200, lr = 1e-05
I0918 20:26:07.255040 24660 solver.cpp:228] Iteration 20300, loss = 0.467985
I0918 20:26:07.255247 24660 solver.cpp:244]     Train net output #0: loss = 0.0299934 (* 1 = 0.0299934 loss)
I0918 20:26:07.255297 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.22176 (* 0.4 = 0.488703 loss)
I0918 20:26:07.255331 24660 sgd_solver.cpp:106] Iteration 20300, lr = 1e-05
I0918 20:26:45.689852 24660 solver.cpp:228] Iteration 20400, loss = 0.47158
I0918 20:26:45.690106 24660 solver.cpp:244]     Train net output #0: loss = 0.0236014 (* 1 = 0.0236014 loss)
I0918 20:26:45.690147 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.11952 (* 0.4 = 0.447809 loss)
I0918 20:26:45.690183 24660 sgd_solver.cpp:106] Iteration 20400, lr = 1e-05
I0918 20:27:25.627140 24660 solver.cpp:228] Iteration 20500, loss = 0.466235
I0918 20:27:25.627341 24660 solver.cpp:244]     Train net output #0: loss = 0.0345289 (* 1 = 0.0345289 loss)
I0918 20:27:25.627368 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.02371 (* 0.4 = 0.409485 loss)
I0918 20:27:25.627394 24660 sgd_solver.cpp:106] Iteration 20500, lr = 1e-05
I0918 20:28:05.458593 24660 solver.cpp:228] Iteration 20600, loss = 0.468962
I0918 20:28:05.458796 24660 solver.cpp:244]     Train net output #0: loss = 0.022611 (* 1 = 0.022611 loss)
I0918 20:28:05.458825 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.826174 (* 0.4 = 0.33047 loss)
I0918 20:28:05.458847 24660 sgd_solver.cpp:106] Iteration 20600, lr = 1e-05
I0918 20:28:45.304358 24660 solver.cpp:228] Iteration 20700, loss = 0.483761
I0918 20:28:45.304535 24660 solver.cpp:244]     Train net output #0: loss = 0.0192989 (* 1 = 0.0192989 loss)
I0918 20:28:45.304563 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.11431 (* 0.4 = 0.445725 loss)
I0918 20:28:45.304584 24660 sgd_solver.cpp:106] Iteration 20700, lr = 1e-05
I0918 20:29:25.088673 24660 solver.cpp:228] Iteration 20800, loss = 0.522258
I0918 20:29:25.088873 24660 solver.cpp:244]     Train net output #0: loss = 0.0432294 (* 1 = 0.0432294 loss)
I0918 20:29:25.088899 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.49535 (* 0.4 = 0.59814 loss)
I0918 20:29:25.088922 24660 sgd_solver.cpp:106] Iteration 20800, lr = 1e-05
I0918 20:30:04.990622 24660 solver.cpp:228] Iteration 20900, loss = 0.454055
I0918 20:30:04.990844 24660 solver.cpp:244]     Train net output #0: loss = 0.0963187 (* 1 = 0.0963187 loss)
I0918 20:30:04.990875 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04342 (* 0.4 = 0.417368 loss)
I0918 20:30:04.990890 24660 sgd_solver.cpp:106] Iteration 20900, lr = 1e-05
I0918 20:30:44.362818 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_21000.caffemodel
I0918 20:30:52.518779 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_21000.solverstate
I0918 20:30:53.018048 24660 solver.cpp:337] Iteration 21000, Testing net (#0)
I0918 20:31:11.867749 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8335
I0918 20:31:11.867828 24660 solver.cpp:404]     Test net output #1: loss = 0.664279 (* 1 = 0.664279 loss)
I0918 20:31:11.867852 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.63586 (* 0.4 = 1.05434 loss)
I0918 20:31:12.037896 24660 solver.cpp:228] Iteration 21000, loss = 0.48997
I0918 20:31:12.037997 24660 solver.cpp:244]     Train net output #0: loss = 0.00745044 (* 1 = 0.00745044 loss)
I0918 20:31:12.038025 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.669254 (* 0.4 = 0.267702 loss)
I0918 20:31:12.038064 24660 sgd_solver.cpp:106] Iteration 21000, lr = 1e-05
I0918 20:31:51.767824 24660 solver.cpp:228] Iteration 21100, loss = 0.460236
I0918 20:31:51.768015 24660 solver.cpp:244]     Train net output #0: loss = 0.0424571 (* 1 = 0.0424571 loss)
I0918 20:31:51.768041 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.16064 (* 0.4 = 0.464254 loss)
I0918 20:31:51.768070 24660 sgd_solver.cpp:106] Iteration 21100, lr = 1e-05
I0918 20:32:31.689671 24660 solver.cpp:228] Iteration 21200, loss = 0.466709
I0918 20:32:31.689868 24660 solver.cpp:244]     Train net output #0: loss = 0.0189996 (* 1 = 0.0189996 loss)
I0918 20:32:31.689895 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.13054 (* 0.4 = 0.452216 loss)
I0918 20:32:31.689918 24660 sgd_solver.cpp:106] Iteration 21200, lr = 1e-05
I0918 20:33:11.861033 24660 solver.cpp:228] Iteration 21300, loss = 0.477561
I0918 20:33:11.861219 24660 solver.cpp:244]     Train net output #0: loss = 0.0937321 (* 1 = 0.0937321 loss)
I0918 20:33:11.861244 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.18768 (* 0.4 = 0.475071 loss)
I0918 20:33:11.861264 24660 sgd_solver.cpp:106] Iteration 21300, lr = 1e-05
I0918 20:33:51.711797 24660 solver.cpp:228] Iteration 21400, loss = 0.456624
I0918 20:33:51.712014 24660 solver.cpp:244]     Train net output #0: loss = 0.00465061 (* 1 = 0.00465061 loss)
I0918 20:33:51.712040 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.721966 (* 0.4 = 0.288786 loss)
I0918 20:33:51.712062 24660 sgd_solver.cpp:106] Iteration 21400, lr = 1e-05
I0918 20:34:31.640280 24660 solver.cpp:228] Iteration 21500, loss = 0.486584
I0918 20:34:31.640540 24660 solver.cpp:244]     Train net output #0: loss = 0.02988 (* 1 = 0.02988 loss)
I0918 20:34:31.640568 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.32421 (* 0.4 = 0.529684 loss)
I0918 20:34:31.640599 24660 sgd_solver.cpp:106] Iteration 21500, lr = 1e-05
I0918 20:35:11.631086 24660 solver.cpp:228] Iteration 21600, loss = 0.519393
I0918 20:35:11.631235 24660 solver.cpp:244]     Train net output #0: loss = 0.0494905 (* 1 = 0.0494905 loss)
I0918 20:35:11.631260 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.40902 (* 0.4 = 0.563607 loss)
I0918 20:35:11.631281 24660 sgd_solver.cpp:106] Iteration 21600, lr = 1e-05
I0918 20:35:51.524335 24660 solver.cpp:228] Iteration 21700, loss = 0.465896
I0918 20:35:51.524533 24660 solver.cpp:244]     Train net output #0: loss = 0.144369 (* 1 = 0.144369 loss)
I0918 20:35:51.524559 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.50093 (* 0.4 = 0.600371 loss)
I0918 20:35:51.524587 24660 sgd_solver.cpp:106] Iteration 21700, lr = 1e-05
I0918 20:36:31.426153 24660 solver.cpp:228] Iteration 21800, loss = 0.487861
I0918 20:36:31.426385 24660 solver.cpp:244]     Train net output #0: loss = 0.0243275 (* 1 = 0.0243275 loss)
I0918 20:36:31.426416 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.990258 (* 0.4 = 0.396103 loss)
I0918 20:36:31.426430 24660 sgd_solver.cpp:106] Iteration 21800, lr = 1e-05
I0918 20:37:11.499874 24660 solver.cpp:228] Iteration 21900, loss = 0.463191
I0918 20:37:11.500080 24660 solver.cpp:244]     Train net output #0: loss = 0.126362 (* 1 = 0.126362 loss)
I0918 20:37:11.500108 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.3672 (* 0.4 = 0.546881 loss)
I0918 20:37:11.500138 24660 sgd_solver.cpp:106] Iteration 21900, lr = 1e-05
I0918 20:37:50.948562 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_22000.caffemodel
I0918 20:37:55.541121 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_22000.solverstate
I0918 20:37:56.027735 24660 solver.cpp:337] Iteration 22000, Testing net (#0)
I0918 20:38:14.930131 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.837
I0918 20:38:14.930229 24660 solver.cpp:404]     Test net output #1: loss = 0.670256 (* 1 = 0.670256 loss)
I0918 20:38:14.930251 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.62434 (* 0.4 = 1.04974 loss)
I0918 20:38:15.104406 24660 solver.cpp:228] Iteration 22000, loss = 0.458765
I0918 20:38:15.104482 24660 solver.cpp:244]     Train net output #0: loss = 0.0153963 (* 1 = 0.0153963 loss)
I0918 20:38:15.104508 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.822211 (* 0.4 = 0.328884 loss)
I0918 20:38:15.104534 24660 sgd_solver.cpp:106] Iteration 22000, lr = 1e-05
I0918 20:38:55.037994 24660 solver.cpp:228] Iteration 22100, loss = 0.463431
I0918 20:38:55.038242 24660 solver.cpp:244]     Train net output #0: loss = 0.0146933 (* 1 = 0.0146933 loss)
I0918 20:38:55.038272 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.00754 (* 0.4 = 0.403014 loss)
I0918 20:38:55.038288 24660 sgd_solver.cpp:106] Iteration 22100, lr = 1e-05
I0918 20:39:34.946883 24660 solver.cpp:228] Iteration 22200, loss = 0.455232
I0918 20:39:34.947103 24660 solver.cpp:244]     Train net output #0: loss = 0.0129292 (* 1 = 0.0129292 loss)
I0918 20:39:34.947130 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.02235 (* 0.4 = 0.408942 loss)
I0918 20:39:34.947161 24660 sgd_solver.cpp:106] Iteration 22200, lr = 1e-05
I0918 20:40:14.721402 24660 solver.cpp:228] Iteration 22300, loss = 0.465835
I0918 20:40:14.721608 24660 solver.cpp:244]     Train net output #0: loss = 0.0094213 (* 1 = 0.0094213 loss)
I0918 20:40:14.721642 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.21644 (* 0.4 = 0.486576 loss)
I0918 20:40:14.721664 24660 sgd_solver.cpp:106] Iteration 22300, lr = 1e-05
I0918 20:40:54.443318 24660 solver.cpp:228] Iteration 22400, loss = 0.510794
I0918 20:40:54.443553 24660 solver.cpp:244]     Train net output #0: loss = 0.117519 (* 1 = 0.117519 loss)
I0918 20:40:54.443581 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.66444 (* 0.4 = 0.665778 loss)
I0918 20:40:54.443605 24660 sgd_solver.cpp:106] Iteration 22400, lr = 1e-05
I0918 20:41:34.271317 24660 solver.cpp:228] Iteration 22500, loss = 0.470526
I0918 20:41:34.271503 24660 solver.cpp:244]     Train net output #0: loss = 0.132848 (* 1 = 0.132848 loss)
I0918 20:41:34.271529 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.19629 (* 0.4 = 0.478516 loss)
I0918 20:41:34.271551 24660 sgd_solver.cpp:106] Iteration 22500, lr = 1e-05
I0918 20:42:13.999341 24660 solver.cpp:228] Iteration 22600, loss = 0.484829
I0918 20:42:13.999516 24660 solver.cpp:244]     Train net output #0: loss = 0.016714 (* 1 = 0.016714 loss)
I0918 20:42:13.999542 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.88512 (* 0.4 = 0.354048 loss)
I0918 20:42:13.999570 24660 sgd_solver.cpp:106] Iteration 22600, lr = 1e-05
I0918 20:42:53.706775 24660 solver.cpp:228] Iteration 22700, loss = 0.440497
I0918 20:42:53.706969 24660 solver.cpp:244]     Train net output #0: loss = 0.0918731 (* 1 = 0.0918731 loss)
I0918 20:42:53.706995 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.34213 (* 0.4 = 0.536852 loss)
I0918 20:42:53.707016 24660 sgd_solver.cpp:106] Iteration 22700, lr = 1e-05
I0918 20:43:33.629139 24660 solver.cpp:228] Iteration 22800, loss = 0.457683
I0918 20:43:33.629324 24660 solver.cpp:244]     Train net output #0: loss = 0.0302502 (* 1 = 0.0302502 loss)
I0918 20:43:33.629351 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.12038 (* 0.4 = 0.448154 loss)
I0918 20:43:33.629382 24660 sgd_solver.cpp:106] Iteration 22800, lr = 1e-05
I0918 20:44:09.498796 24660 solver.cpp:228] Iteration 22900, loss = 0.48046
I0918 20:44:09.498965 24660 solver.cpp:244]     Train net output #0: loss = 0.0315681 (* 1 = 0.0315681 loss)
I0918 20:44:09.498989 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.40346 (* 0.4 = 0.561382 loss)
I0918 20:44:09.499011 24660 sgd_solver.cpp:106] Iteration 22900, lr = 1e-05
I0918 20:44:33.384080 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_23000.caffemodel
I0918 20:44:37.450314 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_23000.solverstate
I0918 20:44:37.948391 24660 solver.cpp:337] Iteration 23000, Testing net (#0)
I0918 20:44:53.886086 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.83525
I0918 20:44:53.886297 24660 solver.cpp:404]     Test net output #1: loss = 0.669779 (* 1 = 0.669779 loss)
I0918 20:44:53.886323 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.61785 (* 0.4 = 1.04714 loss)
I0918 20:44:54.060900 24660 solver.cpp:228] Iteration 23000, loss = 0.463397
I0918 20:44:54.060986 24660 solver.cpp:244]     Train net output #0: loss = 0.0161255 (* 1 = 0.0161255 loss)
I0918 20:44:54.061015 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.738251 (* 0.4 = 0.295301 loss)
I0918 20:44:54.061051 24660 sgd_solver.cpp:106] Iteration 23000, lr = 1e-05
I0918 20:45:27.977299 24660 solver.cpp:228] Iteration 23100, loss = 0.475186
I0918 20:45:27.977491 24660 solver.cpp:244]     Train net output #0: loss = 0.0136403 (* 1 = 0.0136403 loss)
I0918 20:45:27.977516 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.964039 (* 0.4 = 0.385616 loss)
I0918 20:45:27.977538 24660 sgd_solver.cpp:106] Iteration 23100, lr = 1e-05
I0918 20:46:01.896579 24660 solver.cpp:228] Iteration 23200, loss = 0.498441
I0918 20:46:01.896791 24660 solver.cpp:244]     Train net output #0: loss = 0.0149691 (* 1 = 0.0149691 loss)
I0918 20:46:01.896818 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.09924 (* 0.4 = 0.439696 loss)
I0918 20:46:01.896849 24660 sgd_solver.cpp:106] Iteration 23200, lr = 1e-05
I0918 20:46:35.796656 24660 solver.cpp:228] Iteration 23300, loss = 0.457357
I0918 20:46:35.796906 24660 solver.cpp:244]     Train net output #0: loss = 0.089109 (* 1 = 0.089109 loss)
I0918 20:46:35.796934 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.0763 (* 0.4 = 0.430519 loss)
I0918 20:46:35.796957 24660 sgd_solver.cpp:106] Iteration 23300, lr = 1e-05
I0918 20:47:09.740470 24660 solver.cpp:228] Iteration 23400, loss = 0.486426
I0918 20:47:09.740650 24660 solver.cpp:244]     Train net output #0: loss = 0.0242609 (* 1 = 0.0242609 loss)
I0918 20:47:09.740677 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.701205 (* 0.4 = 0.280482 loss)
I0918 20:47:09.740706 24660 sgd_solver.cpp:106] Iteration 23400, lr = 1e-05
I0918 20:47:48.117143 24660 solver.cpp:228] Iteration 23500, loss = 0.455074
I0918 20:47:48.117357 24660 solver.cpp:244]     Train net output #0: loss = 0.0746865 (* 1 = 0.0746865 loss)
I0918 20:47:48.117400 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.18279 (* 0.4 = 0.473116 loss)
I0918 20:47:48.117439 24660 sgd_solver.cpp:106] Iteration 23500, lr = 1e-05
I0918 20:48:28.024965 24660 solver.cpp:228] Iteration 23600, loss = 0.444187
I0918 20:48:28.025187 24660 solver.cpp:244]     Train net output #0: loss = 0.0317787 (* 1 = 0.0317787 loss)
I0918 20:48:28.025239 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.10586 (* 0.4 = 0.442343 loss)
I0918 20:48:28.025274 24660 sgd_solver.cpp:106] Iteration 23600, lr = 1e-05
I0918 20:49:07.875280 24660 solver.cpp:228] Iteration 23700, loss = 0.468337
I0918 20:49:07.875424 24660 solver.cpp:244]     Train net output #0: loss = 0.0120032 (* 1 = 0.0120032 loss)
I0918 20:49:07.875449 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.927624 (* 0.4 = 0.371049 loss)
I0918 20:49:07.875470 24660 sgd_solver.cpp:106] Iteration 23700, lr = 1e-05
I0918 20:49:47.559864 24660 solver.cpp:228] Iteration 23800, loss = 0.451465
I0918 20:49:47.560046 24660 solver.cpp:244]     Train net output #0: loss = 0.00391394 (* 1 = 0.00391394 loss)
I0918 20:49:47.560072 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.585827 (* 0.4 = 0.234331 loss)
I0918 20:49:47.560094 24660 sgd_solver.cpp:106] Iteration 23800, lr = 1e-05
I0918 20:50:27.582504 24660 solver.cpp:228] Iteration 23900, loss = 0.464191
I0918 20:50:27.582746 24660 solver.cpp:244]     Train net output #0: loss = 0.0078321 (* 1 = 0.0078321 loss)
I0918 20:50:27.582777 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.92136 (* 0.4 = 0.368544 loss)
I0918 20:50:27.582792 24660 sgd_solver.cpp:106] Iteration 23900, lr = 1e-05
I0918 20:51:07.004246 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_24000.caffemodel
I0918 20:51:17.628227 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_24000.solverstate
I0918 20:51:18.165593 24660 solver.cpp:337] Iteration 24000, Testing net (#0)
I0918 20:51:37.029567 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.83575
I0918 20:51:37.029770 24660 solver.cpp:404]     Test net output #1: loss = 0.670391 (* 1 = 0.670391 loss)
I0918 20:51:37.029795 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.62883 (* 0.4 = 1.05153 loss)
I0918 20:51:37.274302 24660 solver.cpp:228] Iteration 24000, loss = 0.515138
I0918 20:51:37.274374 24660 solver.cpp:244]     Train net output #0: loss = 0.0197866 (* 1 = 0.0197866 loss)
I0918 20:51:37.274396 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.23931 (* 0.4 = 0.495725 loss)
I0918 20:51:37.274421 24660 sgd_solver.cpp:106] Iteration 24000, lr = 1e-05
I0918 20:52:16.947274 24660 solver.cpp:228] Iteration 24100, loss = 0.461732
I0918 20:52:16.947491 24660 solver.cpp:244]     Train net output #0: loss = 0.110578 (* 1 = 0.110578 loss)
I0918 20:52:16.947543 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.12513 (* 0.4 = 0.450052 loss)
I0918 20:52:16.947577 24660 sgd_solver.cpp:106] Iteration 24100, lr = 1e-05
I0918 20:52:56.835430 24660 solver.cpp:228] Iteration 24200, loss = 0.476076
I0918 20:52:56.835685 24660 solver.cpp:244]     Train net output #0: loss = 0.0163196 (* 1 = 0.0163196 loss)
I0918 20:52:56.835712 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.877729 (* 0.4 = 0.351092 loss)
I0918 20:52:56.835734 24660 sgd_solver.cpp:106] Iteration 24200, lr = 1e-05
I0918 20:53:36.648284 24660 solver.cpp:228] Iteration 24300, loss = 0.454965
I0918 20:53:36.648499 24660 solver.cpp:244]     Train net output #0: loss = 0.0363014 (* 1 = 0.0363014 loss)
I0918 20:53:36.648530 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.955163 (* 0.4 = 0.382065 loss)
I0918 20:53:36.648556 24660 sgd_solver.cpp:106] Iteration 24300, lr = 1e-05
I0918 20:54:16.360370 24660 solver.cpp:228] Iteration 24400, loss = 0.448422
I0918 20:54:16.360544 24660 solver.cpp:244]     Train net output #0: loss = 0.0366212 (* 1 = 0.0366212 loss)
I0918 20:54:16.360570 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.01867 (* 0.4 = 0.407467 loss)
I0918 20:54:16.360591 24660 sgd_solver.cpp:106] Iteration 24400, lr = 1e-05
I0918 20:54:56.362426 24660 solver.cpp:228] Iteration 24500, loss = 0.46873
I0918 20:54:56.362620 24660 solver.cpp:244]     Train net output #0: loss = 0.0122543 (* 1 = 0.0122543 loss)
I0918 20:54:56.362646 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.782376 (* 0.4 = 0.31295 loss)
I0918 20:54:56.362679 24660 sgd_solver.cpp:106] Iteration 24500, lr = 1e-05
I0918 20:55:36.177155 24660 solver.cpp:228] Iteration 24600, loss = 0.452686
I0918 20:55:36.177368 24660 solver.cpp:244]     Train net output #0: loss = 0.0023056 (* 1 = 0.0023056 loss)
I0918 20:55:36.177397 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.6268 (* 0.4 = 0.25072 loss)
I0918 20:55:36.177426 24660 sgd_solver.cpp:106] Iteration 24600, lr = 1e-05
I0918 20:56:15.953999 24660 solver.cpp:228] Iteration 24700, loss = 0.481952
I0918 20:56:15.954177 24660 solver.cpp:244]     Train net output #0: loss = 0.0571775 (* 1 = 0.0571775 loss)
I0918 20:56:15.954205 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.31915 (* 0.4 = 0.527658 loss)
I0918 20:56:15.954226 24660 sgd_solver.cpp:106] Iteration 24700, lr = 1e-05
I0918 20:56:55.827885 24660 solver.cpp:228] Iteration 24800, loss = 0.491827
I0918 20:56:55.828083 24660 solver.cpp:244]     Train net output #0: loss = 0.0223943 (* 1 = 0.0223943 loss)
I0918 20:56:55.828109 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.24811 (* 0.4 = 0.499243 loss)
I0918 20:56:55.828130 24660 sgd_solver.cpp:106] Iteration 24800, lr = 1e-05
I0918 20:57:35.588891 24660 solver.cpp:228] Iteration 24900, loss = 0.453242
I0918 20:57:35.589082 24660 solver.cpp:244]     Train net output #0: loss = 0.151918 (* 1 = 0.151918 loss)
I0918 20:57:35.589109 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.143 (* 0.4 = 0.4572 loss)
I0918 20:57:35.589139 24660 sgd_solver.cpp:106] Iteration 24900, lr = 1e-05
I0918 20:58:15.209033 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_25000.caffemodel
I0918 20:58:16.565359 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_25000.solverstate
I0918 20:58:17.043395 24660 solver.cpp:337] Iteration 25000, Testing net (#0)
I0918 20:58:35.866284 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.836
I0918 20:58:35.866406 24660 solver.cpp:404]     Test net output #1: loss = 0.669911 (* 1 = 0.669911 loss)
I0918 20:58:35.866431 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.63722 (* 0.4 = 1.05489 loss)
I0918 20:58:36.027586 24660 solver.cpp:228] Iteration 25000, loss = 0.465612
I0918 20:58:36.027667 24660 solver.cpp:244]     Train net output #0: loss = 0.00757289 (* 1 = 0.00757289 loss)
I0918 20:58:36.027695 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.797253 (* 0.4 = 0.318901 loss)
I0918 20:58:36.027747 24660 sgd_solver.cpp:106] Iteration 25000, lr = 1e-05
I0918 20:59:15.932739 24660 solver.cpp:228] Iteration 25100, loss = 0.443074
I0918 20:59:15.933060 24660 solver.cpp:244]     Train net output #0: loss = 0.0526966 (* 1 = 0.0526966 loss)
I0918 20:59:15.933089 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.03114 (* 0.4 = 0.412454 loss)
I0918 20:59:15.933115 24660 sgd_solver.cpp:106] Iteration 25100, lr = 1e-05
I0918 20:59:55.873200 24660 solver.cpp:228] Iteration 25200, loss = 0.454657
I0918 20:59:55.873411 24660 solver.cpp:244]     Train net output #0: loss = 0.0243382 (* 1 = 0.0243382 loss)
I0918 20:59:55.873437 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.9857 (* 0.4 = 0.39428 loss)
I0918 20:59:55.873458 24660 sgd_solver.cpp:106] Iteration 25200, lr = 1e-05
I0918 21:00:35.675011 24660 solver.cpp:228] Iteration 25300, loss = 0.449204
I0918 21:00:35.675271 24660 solver.cpp:244]     Train net output #0: loss = 0.0272491 (* 1 = 0.0272491 loss)
I0918 21:00:35.675298 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.976488 (* 0.4 = 0.390595 loss)
I0918 21:00:35.675328 24660 sgd_solver.cpp:106] Iteration 25300, lr = 1e-05
I0918 21:01:15.520874 24660 solver.cpp:228] Iteration 25400, loss = 0.439934
I0918 21:01:15.521100 24660 solver.cpp:244]     Train net output #0: loss = 0.00613673 (* 1 = 0.00613673 loss)
I0918 21:01:15.521127 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.725678 (* 0.4 = 0.290271 loss)
I0918 21:01:15.521157 24660 sgd_solver.cpp:106] Iteration 25400, lr = 1e-05
I0918 21:01:55.382462 24660 solver.cpp:228] Iteration 25500, loss = 0.462237
I0918 21:01:55.382656 24660 solver.cpp:244]     Train net output #0: loss = 0.0378768 (* 1 = 0.0378768 loss)
I0918 21:01:55.382683 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.12022 (* 0.4 = 0.448087 loss)
I0918 21:01:55.382710 24660 sgd_solver.cpp:106] Iteration 25500, lr = 1e-05
I0918 21:02:35.343626 24660 solver.cpp:228] Iteration 25600, loss = 0.498293
I0918 21:02:35.343852 24660 solver.cpp:244]     Train net output #0: loss = 0.0429621 (* 1 = 0.0429621 loss)
I0918 21:02:35.343878 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.36652 (* 0.4 = 0.54661 loss)
I0918 21:02:35.343907 24660 sgd_solver.cpp:106] Iteration 25600, lr = 1e-05
I0918 21:03:15.203133 24660 solver.cpp:228] Iteration 25700, loss = 0.444099
I0918 21:03:15.203330 24660 solver.cpp:244]     Train net output #0: loss = 0.0869891 (* 1 = 0.0869891 loss)
I0918 21:03:15.203357 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04664 (* 0.4 = 0.418658 loss)
I0918 21:03:15.203382 24660 sgd_solver.cpp:106] Iteration 25700, lr = 1e-05
I0918 21:03:55.090536 24660 solver.cpp:228] Iteration 25800, loss = 0.469469
I0918 21:03:55.090798 24660 solver.cpp:244]     Train net output #0: loss = 0.0235188 (* 1 = 0.0235188 loss)
I0918 21:03:55.090826 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.803781 (* 0.4 = 0.321512 loss)
I0918 21:03:55.090847 24660 sgd_solver.cpp:106] Iteration 25800, lr = 1e-05
I0918 21:04:34.929986 24660 solver.cpp:228] Iteration 25900, loss = 0.447489
I0918 21:04:34.930181 24660 solver.cpp:244]     Train net output #0: loss = 0.0392817 (* 1 = 0.0392817 loss)
I0918 21:04:34.930208 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.36628 (* 0.4 = 0.546513 loss)
I0918 21:04:34.930233 24660 sgd_solver.cpp:106] Iteration 25900, lr = 1e-05
I0918 21:05:11.636203 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_26000.caffemodel
I0918 21:05:14.522913 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_26000.solverstate
I0918 21:05:15.116061 24660 solver.cpp:337] Iteration 26000, Testing net (#0)
I0918 21:05:24.834451 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8365
I0918 21:05:24.834589 24660 solver.cpp:404]     Test net output #1: loss = 0.673294 (* 1 = 0.673294 loss)
I0918 21:05:24.834615 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.60942 (* 0.4 = 1.04377 loss)
I0918 21:05:25.001293 24660 solver.cpp:228] Iteration 26000, loss = 0.453625
I0918 21:05:25.001375 24660 solver.cpp:244]     Train net output #0: loss = 0.0240461 (* 1 = 0.0240461 loss)
I0918 21:05:25.001399 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04633 (* 0.4 = 0.418532 loss)
I0918 21:05:25.001431 24660 sgd_solver.cpp:106] Iteration 26000, lr = 1e-05
I0918 21:05:58.985271 24660 solver.cpp:228] Iteration 26100, loss = 0.446785
I0918 21:05:58.985599 24660 solver.cpp:244]     Train net output #0: loss = 0.0921484 (* 1 = 0.0921484 loss)
I0918 21:05:58.985635 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.29009 (* 0.4 = 0.516034 loss)
I0918 21:05:58.985658 24660 sgd_solver.cpp:106] Iteration 26100, lr = 1e-05
I0918 21:06:32.957502 24660 solver.cpp:228] Iteration 26200, loss = 0.453078
I0918 21:06:32.957736 24660 solver.cpp:244]     Train net output #0: loss = 0.0211843 (* 1 = 0.0211843 loss)
I0918 21:06:32.957764 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.921925 (* 0.4 = 0.36877 loss)
I0918 21:06:32.957788 24660 sgd_solver.cpp:106] Iteration 26200, lr = 1e-05
I0918 21:07:06.904909 24660 solver.cpp:228] Iteration 26300, loss = 0.468725
I0918 21:07:06.905094 24660 solver.cpp:244]     Train net output #0: loss = 0.0415584 (* 1 = 0.0415584 loss)
I0918 21:07:06.905122 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.38023 (* 0.4 = 0.552091 loss)
I0918 21:07:06.905148 24660 sgd_solver.cpp:106] Iteration 26300, lr = 1e-05
I0918 21:07:40.829403 24660 solver.cpp:228] Iteration 26400, loss = 0.501202
I0918 21:07:40.829612 24660 solver.cpp:244]     Train net output #0: loss = 0.0361683 (* 1 = 0.0361683 loss)
I0918 21:07:40.829646 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.47545 (* 0.4 = 0.59018 loss)
I0918 21:07:40.829671 24660 sgd_solver.cpp:106] Iteration 26400, lr = 1e-05
I0918 21:08:14.781738 24660 solver.cpp:228] Iteration 26500, loss = 0.444502
I0918 21:08:14.782003 24660 solver.cpp:244]     Train net output #0: loss = 0.182412 (* 1 = 0.182412 loss)
I0918 21:08:14.782033 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.11523 (* 0.4 = 0.446093 loss)
I0918 21:08:14.782054 24660 sgd_solver.cpp:106] Iteration 26500, lr = 1e-05
I0918 21:08:53.101969 24660 solver.cpp:228] Iteration 26600, loss = 0.454196
I0918 21:08:53.102188 24660 solver.cpp:244]     Train net output #0: loss = 0.0112611 (* 1 = 0.0112611 loss)
I0918 21:08:53.102216 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.862885 (* 0.4 = 0.345154 loss)
I0918 21:08:53.102243 24660 sgd_solver.cpp:106] Iteration 26600, lr = 1e-05
I0918 21:09:32.972858 24660 solver.cpp:228] Iteration 26700, loss = 0.433197
I0918 21:09:32.973120 24660 solver.cpp:244]     Train net output #0: loss = 0.0197909 (* 1 = 0.0197909 loss)
I0918 21:09:32.973147 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.01346 (* 0.4 = 0.405385 loss)
I0918 21:09:32.973171 24660 sgd_solver.cpp:106] Iteration 26700, lr = 1e-05
I0918 21:10:12.820693 24660 solver.cpp:228] Iteration 26800, loss = 0.444172
I0918 21:10:12.820847 24660 solver.cpp:244]     Train net output #0: loss = 0.0998378 (* 1 = 0.0998378 loss)
I0918 21:10:12.820871 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.44821 (* 0.4 = 0.579283 loss)
I0918 21:10:12.820897 24660 sgd_solver.cpp:106] Iteration 26800, lr = 1e-05
I0918 21:10:52.570574 24660 solver.cpp:228] Iteration 26900, loss = 0.435863
I0918 21:10:52.570780 24660 solver.cpp:244]     Train net output #0: loss = 0.0389829 (* 1 = 0.0389829 loss)
I0918 21:10:52.570806 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.12599 (* 0.4 = 0.450396 loss)
I0918 21:10:52.570827 24660 sgd_solver.cpp:106] Iteration 26900, lr = 1e-05
I0918 21:11:32.012830 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_27000.caffemodel
I0918 21:11:36.667486 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_27000.solverstate
I0918 21:11:37.151124 24660 solver.cpp:337] Iteration 27000, Testing net (#0)
I0918 21:11:55.907665 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.83325
I0918 21:11:55.907760 24660 solver.cpp:404]     Test net output #1: loss = 0.672948 (* 1 = 0.672948 loss)
I0918 21:11:55.907783 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.62725 (* 0.4 = 1.0509 loss)
I0918 21:11:56.082315 24660 solver.cpp:228] Iteration 27000, loss = 0.437368
I0918 21:11:56.082402 24660 solver.cpp:244]     Train net output #0: loss = 0.021992 (* 1 = 0.021992 loss)
I0918 21:11:56.082427 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.04157 (* 0.4 = 0.416628 loss)
I0918 21:11:56.082449 24660 sgd_solver.cpp:106] Iteration 27000, lr = 1e-05
I0918 21:12:36.091156 24660 solver.cpp:228] Iteration 27100, loss = 0.467509
I0918 21:12:36.091435 24660 solver.cpp:244]     Train net output #0: loss = 0.0158392 (* 1 = 0.0158392 loss)
I0918 21:12:36.091462 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.927066 (* 0.4 = 0.370826 loss)
I0918 21:12:36.091490 24660 sgd_solver.cpp:106] Iteration 27100, lr = 1e-05
I0918 21:13:16.074921 24660 solver.cpp:228] Iteration 27200, loss = 0.49377
I0918 21:13:16.075124 24660 solver.cpp:244]     Train net output #0: loss = 0.0191816 (* 1 = 0.0191816 loss)
I0918 21:13:16.075150 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.27171 (* 0.4 = 0.508684 loss)
I0918 21:13:16.075181 24660 sgd_solver.cpp:106] Iteration 27200, lr = 1e-05
I0918 21:13:55.968726 24660 solver.cpp:228] Iteration 27300, loss = 0.444137
I0918 21:13:55.968894 24660 solver.cpp:244]     Train net output #0: loss = 0.080196 (* 1 = 0.080196 loss)
I0918 21:13:55.968921 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.29429 (* 0.4 = 0.517717 loss)
I0918 21:13:55.968943 24660 sgd_solver.cpp:106] Iteration 27300, lr = 1e-05
I0918 21:14:35.743319 24660 solver.cpp:228] Iteration 27400, loss = 0.47388
I0918 21:14:35.743548 24660 solver.cpp:244]     Train net output #0: loss = 0.0142589 (* 1 = 0.0142589 loss)
I0918 21:14:35.743582 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.742373 (* 0.4 = 0.296949 loss)
I0918 21:14:35.743605 24660 sgd_solver.cpp:106] Iteration 27400, lr = 1e-05
I0918 21:15:15.689546 24660 solver.cpp:228] Iteration 27500, loss = 0.453696
I0918 21:15:15.689786 24660 solver.cpp:244]     Train net output #0: loss = 0.0271819 (* 1 = 0.0271819 loss)
I0918 21:15:15.689821 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.07978 (* 0.4 = 0.431912 loss)
I0918 21:15:15.689847 24660 sgd_solver.cpp:106] Iteration 27500, lr = 1e-05
I0918 21:15:55.481974 24660 solver.cpp:228] Iteration 27600, loss = 0.450493
I0918 21:15:55.482187 24660 solver.cpp:244]     Train net output #0: loss = 0.0422915 (* 1 = 0.0422915 loss)
I0918 21:15:55.482221 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.2211 (* 0.4 = 0.48844 loss)
I0918 21:15:55.482244 24660 sgd_solver.cpp:106] Iteration 27600, lr = 1e-05
I0918 21:16:35.423009 24660 solver.cpp:228] Iteration 27700, loss = 0.45252
I0918 21:16:35.423197 24660 solver.cpp:244]     Train net output #0: loss = 0.0167348 (* 1 = 0.0167348 loss)
I0918 21:16:35.423223 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.993075 (* 0.4 = 0.39723 loss)
I0918 21:16:35.423254 24660 sgd_solver.cpp:106] Iteration 27700, lr = 1e-05
I0918 21:17:15.381285 24660 solver.cpp:228] Iteration 27800, loss = 0.437642
I0918 21:17:15.381494 24660 solver.cpp:244]     Train net output #0: loss = 0.00749435 (* 1 = 0.00749435 loss)
I0918 21:17:15.381521 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.743313 (* 0.4 = 0.297325 loss)
I0918 21:17:15.381541 24660 sgd_solver.cpp:106] Iteration 27800, lr = 1e-05
I0918 21:17:55.302100 24660 solver.cpp:228] Iteration 27900, loss = 0.461047
I0918 21:17:55.302355 24660 solver.cpp:244]     Train net output #0: loss = 0.00771305 (* 1 = 0.00771305 loss)
I0918 21:17:55.302386 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.838707 (* 0.4 = 0.335483 loss)
I0918 21:17:55.302400 24660 sgd_solver.cpp:106] Iteration 27900, lr = 1e-05
I0918 21:18:34.681140 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_28000.caffemodel
I0918 21:18:36.811439 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_28000.solverstate
I0918 21:18:37.301354 24660 solver.cpp:337] Iteration 28000, Testing net (#0)
I0918 21:18:56.131935 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.8365
I0918 21:18:56.132032 24660 solver.cpp:404]     Test net output #1: loss = 0.672058 (* 1 = 0.672058 loss)
I0918 21:18:56.132055 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.64352 (* 0.4 = 1.05741 loss)
I0918 21:18:56.326395 24660 solver.cpp:228] Iteration 28000, loss = 0.48082
I0918 21:18:56.326478 24660 solver.cpp:244]     Train net output #0: loss = 0.0177962 (* 1 = 0.0177962 loss)
I0918 21:18:56.326506 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.36549 (* 0.4 = 0.546196 loss)
I0918 21:18:56.326534 24660 sgd_solver.cpp:106] Iteration 28000, lr = 1e-05
I0918 21:19:36.237303 24660 solver.cpp:228] Iteration 28100, loss = 0.446346
I0918 21:19:36.237488 24660 solver.cpp:244]     Train net output #0: loss = 0.167443 (* 1 = 0.167443 loss)
I0918 21:19:36.237514 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.17593 (* 0.4 = 0.470371 loss)
I0918 21:19:36.237534 24660 sgd_solver.cpp:106] Iteration 28100, lr = 1e-05
I0918 21:20:16.215759 24660 solver.cpp:228] Iteration 28200, loss = 0.44925
I0918 21:20:16.215978 24660 solver.cpp:244]     Train net output #0: loss = 0.0165693 (* 1 = 0.0165693 loss)
I0918 21:20:16.216004 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.692731 (* 0.4 = 0.277093 loss)
I0918 21:20:16.216027 24660 sgd_solver.cpp:106] Iteration 28200, lr = 1e-05
I0918 21:20:56.058261 24660 solver.cpp:228] Iteration 28300, loss = 0.450907
I0918 21:20:56.058394 24660 solver.cpp:244]     Train net output #0: loss = 0.0394836 (* 1 = 0.0394836 loss)
I0918 21:20:56.058418 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.17686 (* 0.4 = 0.470744 loss)
I0918 21:20:56.058439 24660 sgd_solver.cpp:106] Iteration 28300, lr = 1e-05
I0918 21:21:36.072384 24660 solver.cpp:228] Iteration 28400, loss = 0.433465
I0918 21:21:36.072571 24660 solver.cpp:244]     Train net output #0: loss = 0.0128586 (* 1 = 0.0128586 loss)
I0918 21:21:36.072597 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.784143 (* 0.4 = 0.313657 loss)
I0918 21:21:36.072628 24660 sgd_solver.cpp:106] Iteration 28400, lr = 1e-05
I0918 21:22:16.070751 24660 solver.cpp:228] Iteration 28500, loss = 0.446217
I0918 21:22:16.070946 24660 solver.cpp:244]     Train net output #0: loss = 0.0184769 (* 1 = 0.0184769 loss)
I0918 21:22:16.070974 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.972329 (* 0.4 = 0.388932 loss)
I0918 21:22:16.070999 24660 sgd_solver.cpp:106] Iteration 28500, lr = 1e-05
I0918 21:22:56.024720 24660 solver.cpp:228] Iteration 28600, loss = 0.446837
I0918 21:22:56.024927 24660 solver.cpp:244]     Train net output #0: loss = 0.00866548 (* 1 = 0.00866548 loss)
I0918 21:22:56.024955 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.817043 (* 0.4 = 0.326817 loss)
I0918 21:22:56.024984 24660 sgd_solver.cpp:106] Iteration 28600, lr = 1e-05
I0918 21:23:35.900413 24660 solver.cpp:228] Iteration 28700, loss = 0.463674
I0918 21:23:35.900619 24660 solver.cpp:244]     Train net output #0: loss = 0.0166598 (* 1 = 0.0166598 loss)
I0918 21:23:35.900645 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.05604 (* 0.4 = 0.422417 loss)
I0918 21:23:35.900673 24660 sgd_solver.cpp:106] Iteration 28700, lr = 1e-05
I0918 21:24:15.815012 24660 solver.cpp:228] Iteration 28800, loss = 0.493069
I0918 21:24:15.815206 24660 solver.cpp:244]     Train net output #0: loss = 0.0263283 (* 1 = 0.0263283 loss)
I0918 21:24:15.815232 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.40648 (* 0.4 = 0.56259 loss)
I0918 21:24:15.815263 24660 sgd_solver.cpp:106] Iteration 28800, lr = 1e-05
I0918 21:24:55.815433 24660 solver.cpp:228] Iteration 28900, loss = 0.439381
I0918 21:24:55.815672 24660 solver.cpp:244]     Train net output #0: loss = 0.0477661 (* 1 = 0.0477661 loss)
I0918 21:24:55.815701 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.08552 (* 0.4 = 0.43421 loss)
I0918 21:24:55.815734 24660 sgd_solver.cpp:106] Iteration 28900, lr = 1e-05
I0918 21:25:35.238731 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_29000.caffemodel
I0918 21:25:37.583212 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_29000.solverstate
I0918 21:25:38.205742 24660 solver.cpp:337] Iteration 29000, Testing net (#0)
I0918 21:25:57.004096 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.835
I0918 21:25:57.004191 24660 solver.cpp:404]     Test net output #1: loss = 0.674368 (* 1 = 0.674368 loss)
I0918 21:25:57.004215 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.63199 (* 0.4 = 1.0528 loss)
I0918 21:25:57.174024 24660 solver.cpp:228] Iteration 29000, loss = 0.469863
I0918 21:25:57.174110 24660 solver.cpp:244]     Train net output #0: loss = 0.0773892 (* 1 = 0.0773892 loss)
I0918 21:25:57.174136 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.16609 (* 0.4 = 0.466436 loss)
I0918 21:25:57.174161 24660 sgd_solver.cpp:106] Iteration 29000, lr = 1e-05
I0918 21:26:25.484959 24660 solver.cpp:228] Iteration 29100, loss = 0.417673
I0918 21:26:25.485167 24660 solver.cpp:244]     Train net output #0: loss = 0.0267627 (* 1 = 0.0267627 loss)
I0918 21:26:25.485195 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.911883 (* 0.4 = 0.364753 loss)
I0918 21:26:25.485219 24660 sgd_solver.cpp:106] Iteration 29100, lr = 1e-05
I0918 21:26:59.407022 24660 solver.cpp:228] Iteration 29200, loss = 0.440039
I0918 21:26:59.407248 24660 solver.cpp:244]     Train net output #0: loss = 0.0138219 (* 1 = 0.0138219 loss)
I0918 21:26:59.407275 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.889172 (* 0.4 = 0.355669 loss)
I0918 21:26:59.407305 24660 sgd_solver.cpp:106] Iteration 29200, lr = 1e-05
I0918 21:27:33.368512 24660 solver.cpp:228] Iteration 29300, loss = 0.435865
I0918 21:27:33.368780 24660 solver.cpp:244]     Train net output #0: loss = 0.0194077 (* 1 = 0.0194077 loss)
I0918 21:27:33.368808 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.788937 (* 0.4 = 0.315575 loss)
I0918 21:27:33.368829 24660 sgd_solver.cpp:106] Iteration 29300, lr = 1e-05
I0918 21:28:07.284972 24660 solver.cpp:228] Iteration 29400, loss = 0.434679
I0918 21:28:07.285189 24660 solver.cpp:244]     Train net output #0: loss = 0.00803318 (* 1 = 0.00803318 loss)
I0918 21:28:07.285217 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.792797 (* 0.4 = 0.317119 loss)
I0918 21:28:07.285245 24660 sgd_solver.cpp:106] Iteration 29400, lr = 1e-05
I0918 21:28:41.229917 24660 solver.cpp:228] Iteration 29500, loss = 0.448478
I0918 21:28:41.230125 24660 solver.cpp:244]     Train net output #0: loss = 0.0213054 (* 1 = 0.0213054 loss)
I0918 21:28:41.230151 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.10731 (* 0.4 = 0.442925 loss)
I0918 21:28:41.230172 24660 sgd_solver.cpp:106] Iteration 29500, lr = 1e-05
I0918 21:29:15.187496 24660 solver.cpp:228] Iteration 29600, loss = 0.485285
I0918 21:29:15.187731 24660 solver.cpp:244]     Train net output #0: loss = 0.0416562 (* 1 = 0.0416562 loss)
I0918 21:29:15.187757 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.16295 (* 0.4 = 0.46518 loss)
I0918 21:29:15.187780 24660 sgd_solver.cpp:106] Iteration 29600, lr = 1e-05
I0918 21:29:52.857592 24660 solver.cpp:228] Iteration 29700, loss = 0.440428
I0918 21:29:52.857851 24660 solver.cpp:244]     Train net output #0: loss = 0.0676309 (* 1 = 0.0676309 loss)
I0918 21:29:52.857882 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.02905 (* 0.4 = 0.41162 loss)
I0918 21:29:52.857903 24660 sgd_solver.cpp:106] Iteration 29700, lr = 1e-05
I0918 21:30:32.722825 24660 solver.cpp:228] Iteration 29800, loss = 0.468633
I0918 21:30:32.723081 24660 solver.cpp:244]     Train net output #0: loss = 0.00794045 (* 1 = 0.00794045 loss)
I0918 21:30:32.723109 24660 solver.cpp:244]     Train net output #1: loss_hashing = 0.781652 (* 0.4 = 0.312661 loss)
I0918 21:30:32.723139 24660 sgd_solver.cpp:106] Iteration 29800, lr = 1e-05
I0918 21:31:12.657667 24660 solver.cpp:228] Iteration 29900, loss = 0.441247
I0918 21:31:12.657876 24660 solver.cpp:244]     Train net output #0: loss = 0.0578434 (* 1 = 0.0578434 loss)
I0918 21:31:12.657902 24660 solver.cpp:244]     Train net output #1: loss_hashing = 1.09093 (* 0.4 = 0.436371 loss)
I0918 21:31:12.657932 24660 sgd_solver.cpp:106] Iteration 29900, lr = 1e-05
I0918 21:31:52.216205 24660 solver.cpp:454] Snapshotting to binary proto file COLOR/color_alexnet_f24_iter_30000.caffemodel
I0918 21:31:54.259673 24660 sgd_solver.cpp:273] Snapshotting solver state to binary proto file COLOR/color_alexnet_f24_iter_30000.solverstate
I0918 21:31:54.874766 24660 solver.cpp:317] Iteration 30000, loss = 0.426619
I0918 21:31:54.874842 24660 solver.cpp:337] Iteration 30000, Testing net (#0)
I0918 21:32:13.651774 24660 solver.cpp:404]     Test net output #0: accuracy_at_1_Color = 0.837
I0918 21:32:13.651861 24660 solver.cpp:404]     Test net output #1: loss = 0.678488 (* 1 = 0.678488 loss)
I0918 21:32:13.651888 24660 solver.cpp:404]     Test net output #2: loss_hashing = 2.60649 (* 0.4 = 1.0426 loss)
I0918 21:32:13.651906 24660 solver.cpp:322] Optimization Done.
I0918 21:32:13.651919 24660 caffe.cpp:222] Optimization Done.
