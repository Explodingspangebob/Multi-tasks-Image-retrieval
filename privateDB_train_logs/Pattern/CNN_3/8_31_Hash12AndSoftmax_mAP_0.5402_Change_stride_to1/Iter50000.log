Log file created at: 2017/08/31 13:17:57
Running on machine: img08
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0831 13:17:57.888386 12026 caffe.cpp:185] Using GPUs 1
I0831 13:17:59.053531 12026 caffe.cpp:190] GPU 1: GeForce GTX TITAN Black
I0831 13:17:59.447397 12026 solver.cpp:48] Initializing solver from parameters: 
test_iter: 70
test_interval: 1000
base_lr: 0.0001
display: 100
max_iter: 50000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0004
snapshot: 1000
snapshot_prefix: "PATTERN/pattern_cnn"
solver_mode: GPU
device_id: 1
net: "PATTERN/train_cnn_model.prototxt"
test_initialization: true
average_loss: 100
stepvalue: 30000
stepvalue: 40000
stepvalue: 45000
I0831 13:17:59.447851 12026 solver.cpp:91] Creating training net from net file: PATTERN/train_cnn_model.prototxt
I0831 13:17:59.449195 12026 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer pattern
I0831 13:17:59.449280 12026 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_at_1
I0831 13:17:59.449312 12026 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_at_5
I0831 13:17:59.449668 12026 net.cpp:49] Initializing net from parameters: 
name: "docomo_pattern_CNN"
state {
  phase: TRAIN
}
layer {
  name: "pattern"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
  }
  data_param {
    source: "PATTERN/pattern_train_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "dropout_conv3"
  type: "Dropout"
  bottom: "pool3"
  top: "dropout_conv3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip500"
  type: "InnerProduct"
  bottom: "dropout_conv3"
  top: "ip500"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu_ip500"
  type: "ReLU"
  bottom: "ip500"
  top: "ip500"
}
layer {
  name: "dropout_ip500"
  type: "Dropout"
  bottom: "ip500"
  top: "ip500"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip_hash"
  type: "InnerProduct"
  bottom: "ip500"
  top: "ip_hash"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 12
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ip_classification"
  type: "InnerProduct"
  bottom: "ip500"
  top: "ip_classification"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "loss_hash"
  type: "HashingLoss"
  bottom: "ip_hash"
  bottom: "label"
  top: "loss_hash"
  loss_weight: 0.1
  hashing_loss_param {
    bi_margin: 24
    tradeoff: 0.01
  }
}
layer {
  name: "loss_classification"
  type: "SoftmaxWithLoss"
  bottom: "ip_classification"
  bottom: "label"
  top: "loss_classification"
}
I0831 13:17:59.451855 12026 layer_factory.hpp:77] Creating layer pattern
I0831 13:17:59.452941 12026 net.cpp:91] Creating Layer pattern
I0831 13:17:59.453023 12026 net.cpp:399] pattern -> data
I0831 13:17:59.453109 12026 net.cpp:399] pattern -> label
I0831 13:17:59.454581 12032 db_lmdb.cpp:38] Opened lmdb PATTERN/pattern_train_lmdb
I0831 13:17:59.480590 12026 data_layer.cpp:41] output data size: 50,3,224,224
I0831 13:17:59.568032 12026 net.cpp:141] Setting up pattern
I0831 13:17:59.568130 12026 net.cpp:148] Top shape: 50 3 224 224 (7526400)
I0831 13:17:59.568159 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:17:59.568179 12026 net.cpp:156] Memory required for data: 30105800
I0831 13:17:59.568210 12026 layer_factory.hpp:77] Creating layer label_pattern_1_split
I0831 13:17:59.568248 12026 net.cpp:91] Creating Layer label_pattern_1_split
I0831 13:17:59.568274 12026 net.cpp:425] label_pattern_1_split <- label
I0831 13:17:59.568312 12026 net.cpp:399] label_pattern_1_split -> label_pattern_1_split_0
I0831 13:17:59.568351 12026 net.cpp:399] label_pattern_1_split -> label_pattern_1_split_1
I0831 13:17:59.568441 12026 net.cpp:141] Setting up label_pattern_1_split
I0831 13:17:59.568475 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:17:59.568496 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:17:59.568517 12026 net.cpp:156] Memory required for data: 30106200
I0831 13:17:59.568536 12026 layer_factory.hpp:77] Creating layer conv1
I0831 13:17:59.568593 12026 net.cpp:91] Creating Layer conv1
I0831 13:17:59.568617 12026 net.cpp:425] conv1 <- data
I0831 13:17:59.568646 12026 net.cpp:399] conv1 -> conv1
I0831 13:17:59.571121 12026 net.cpp:141] Setting up conv1
I0831 13:17:59.571188 12026 net.cpp:148] Top shape: 50 32 224 224 (80281600)
I0831 13:17:59.571218 12026 net.cpp:156] Memory required for data: 351232600
I0831 13:17:59.571275 12026 layer_factory.hpp:77] Creating layer pool1
I0831 13:17:59.571318 12026 net.cpp:91] Creating Layer pool1
I0831 13:17:59.571352 12026 net.cpp:425] pool1 <- conv1
I0831 13:17:59.571382 12026 net.cpp:399] pool1 -> pool1
I0831 13:17:59.573590 12026 net.cpp:141] Setting up pool1
I0831 13:17:59.573624 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:17:59.573644 12026 net.cpp:156] Memory required for data: 431514200
I0831 13:17:59.573664 12026 layer_factory.hpp:77] Creating layer relu1
I0831 13:17:59.573689 12026 net.cpp:91] Creating Layer relu1
I0831 13:17:59.573709 12026 net.cpp:425] relu1 <- pool1
I0831 13:17:59.573734 12026 net.cpp:386] relu1 -> pool1 (in-place)
I0831 13:17:59.573763 12026 net.cpp:141] Setting up relu1
I0831 13:17:59.573786 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:17:59.573807 12026 net.cpp:156] Memory required for data: 511795800
I0831 13:17:59.573825 12026 layer_factory.hpp:77] Creating layer norm1
I0831 13:17:59.573854 12026 net.cpp:91] Creating Layer norm1
I0831 13:17:59.573925 12026 net.cpp:425] norm1 <- pool1
I0831 13:17:59.573951 12026 net.cpp:399] norm1 -> norm1
I0831 13:17:59.574144 12026 net.cpp:141] Setting up norm1
I0831 13:17:59.574177 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:17:59.574196 12026 net.cpp:156] Memory required for data: 592077400
I0831 13:17:59.574215 12026 layer_factory.hpp:77] Creating layer conv2
I0831 13:17:59.574247 12026 net.cpp:91] Creating Layer conv2
I0831 13:17:59.574271 12026 net.cpp:425] conv2 <- norm1
I0831 13:17:59.574296 12026 net.cpp:399] conv2 -> conv2
I0831 13:17:59.575883 12026 net.cpp:141] Setting up conv2
I0831 13:17:59.575934 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:17:59.575960 12026 net.cpp:156] Memory required for data: 672359000
I0831 13:17:59.575999 12026 layer_factory.hpp:77] Creating layer pool2
I0831 13:17:59.576036 12026 net.cpp:91] Creating Layer pool2
I0831 13:17:59.576067 12026 net.cpp:425] pool2 <- conv2
I0831 13:17:59.576097 12026 net.cpp:399] pool2 -> pool2
I0831 13:17:59.576172 12026 net.cpp:141] Setting up pool2
I0831 13:17:59.576215 12026 net.cpp:148] Top shape: 50 32 56 56 (5017600)
I0831 13:17:59.576239 12026 net.cpp:156] Memory required for data: 692429400
I0831 13:17:59.576264 12026 layer_factory.hpp:77] Creating layer relu2
I0831 13:17:59.576297 12026 net.cpp:91] Creating Layer relu2
I0831 13:17:59.576321 12026 net.cpp:425] relu2 <- pool2
I0831 13:17:59.576354 12026 net.cpp:386] relu2 -> pool2 (in-place)
I0831 13:17:59.576386 12026 net.cpp:141] Setting up relu2
I0831 13:17:59.576416 12026 net.cpp:148] Top shape: 50 32 56 56 (5017600)
I0831 13:17:59.576442 12026 net.cpp:156] Memory required for data: 712499800
I0831 13:17:59.576467 12026 layer_factory.hpp:77] Creating layer norm2
I0831 13:17:59.576495 12026 net.cpp:91] Creating Layer norm2
I0831 13:17:59.576519 12026 net.cpp:425] norm2 <- pool2
I0831 13:17:59.576558 12026 net.cpp:399] norm2 -> norm2
I0831 13:17:59.576761 12026 net.cpp:141] Setting up norm2
I0831 13:17:59.576802 12026 net.cpp:148] Top shape: 50 32 56 56 (5017600)
I0831 13:17:59.576828 12026 net.cpp:156] Memory required for data: 732570200
I0831 13:17:59.576851 12026 layer_factory.hpp:77] Creating layer conv3
I0831 13:17:59.576896 12026 net.cpp:91] Creating Layer conv3
I0831 13:17:59.576927 12026 net.cpp:425] conv3 <- norm2
I0831 13:17:59.576959 12026 net.cpp:399] conv3 -> conv3
I0831 13:17:59.578104 12026 net.cpp:141] Setting up conv3
I0831 13:17:59.578147 12026 net.cpp:148] Top shape: 50 64 56 56 (10035200)
I0831 13:17:59.578173 12026 net.cpp:156] Memory required for data: 772711000
I0831 13:17:59.578305 12026 layer_factory.hpp:77] Creating layer relu3
I0831 13:17:59.578327 12026 net.cpp:91] Creating Layer relu3
I0831 13:17:59.578343 12026 net.cpp:425] relu3 <- conv3
I0831 13:17:59.578359 12026 net.cpp:386] relu3 -> conv3 (in-place)
I0831 13:17:59.578385 12026 net.cpp:141] Setting up relu3
I0831 13:17:59.578403 12026 net.cpp:148] Top shape: 50 64 56 56 (10035200)
I0831 13:17:59.578418 12026 net.cpp:156] Memory required for data: 812851800
I0831 13:17:59.578433 12026 layer_factory.hpp:77] Creating layer pool3
I0831 13:17:59.578450 12026 net.cpp:91] Creating Layer pool3
I0831 13:17:59.578464 12026 net.cpp:425] pool3 <- conv3
I0831 13:17:59.578485 12026 net.cpp:399] pool3 -> pool3
I0831 13:17:59.578526 12026 net.cpp:141] Setting up pool3
I0831 13:17:59.578557 12026 net.cpp:148] Top shape: 50 64 28 28 (2508800)
I0831 13:17:59.578577 12026 net.cpp:156] Memory required for data: 822887000
I0831 13:17:59.578591 12026 layer_factory.hpp:77] Creating layer dropout_conv3
I0831 13:17:59.578613 12026 net.cpp:91] Creating Layer dropout_conv3
I0831 13:17:59.578629 12026 net.cpp:425] dropout_conv3 <- pool3
I0831 13:17:59.578644 12026 net.cpp:399] dropout_conv3 -> dropout_conv3
I0831 13:17:59.578707 12026 net.cpp:141] Setting up dropout_conv3
I0831 13:17:59.578730 12026 net.cpp:148] Top shape: 50 64 28 28 (2508800)
I0831 13:17:59.578744 12026 net.cpp:156] Memory required for data: 832922200
I0831 13:17:59.578758 12026 layer_factory.hpp:77] Creating layer ip500
I0831 13:17:59.578805 12026 net.cpp:91] Creating Layer ip500
I0831 13:17:59.578824 12026 net.cpp:425] ip500 <- dropout_conv3
I0831 13:17:59.578842 12026 net.cpp:399] ip500 -> ip500
I0831 13:18:00.517841 12026 net.cpp:141] Setting up ip500
I0831 13:18:00.517917 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:00.517935 12026 net.cpp:156] Memory required for data: 833022200
I0831 13:18:00.517958 12026 layer_factory.hpp:77] Creating layer relu_ip500
I0831 13:18:00.517982 12026 net.cpp:91] Creating Layer relu_ip500
I0831 13:18:00.517997 12026 net.cpp:425] relu_ip500 <- ip500
I0831 13:18:00.518020 12026 net.cpp:386] relu_ip500 -> ip500 (in-place)
I0831 13:18:00.518043 12026 net.cpp:141] Setting up relu_ip500
I0831 13:18:00.518074 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:00.518087 12026 net.cpp:156] Memory required for data: 833122200
I0831 13:18:00.518102 12026 layer_factory.hpp:77] Creating layer dropout_ip500
I0831 13:18:00.518126 12026 net.cpp:91] Creating Layer dropout_ip500
I0831 13:18:00.518141 12026 net.cpp:425] dropout_ip500 <- ip500
I0831 13:18:00.518157 12026 net.cpp:386] dropout_ip500 -> ip500 (in-place)
I0831 13:18:00.518199 12026 net.cpp:141] Setting up dropout_ip500
I0831 13:18:00.518221 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:00.518235 12026 net.cpp:156] Memory required for data: 833222200
I0831 13:18:00.518249 12026 layer_factory.hpp:77] Creating layer ip500_dropout_ip500_0_split
I0831 13:18:00.518267 12026 net.cpp:91] Creating Layer ip500_dropout_ip500_0_split
I0831 13:18:00.518281 12026 net.cpp:425] ip500_dropout_ip500_0_split <- ip500
I0831 13:18:00.518308 12026 net.cpp:399] ip500_dropout_ip500_0_split -> ip500_dropout_ip500_0_split_0
I0831 13:18:00.518329 12026 net.cpp:399] ip500_dropout_ip500_0_split -> ip500_dropout_ip500_0_split_1
I0831 13:18:00.518398 12026 net.cpp:141] Setting up ip500_dropout_ip500_0_split
I0831 13:18:00.518422 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:00.518441 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:00.518455 12026 net.cpp:156] Memory required for data: 833422200
I0831 13:18:00.518473 12026 layer_factory.hpp:77] Creating layer ip_hash
I0831 13:18:00.518494 12026 net.cpp:91] Creating Layer ip_hash
I0831 13:18:00.518508 12026 net.cpp:425] ip_hash <- ip500_dropout_ip500_0_split_0
I0831 13:18:00.518527 12026 net.cpp:399] ip_hash -> ip_hash
I0831 13:18:00.518889 12026 net.cpp:141] Setting up ip_hash
I0831 13:18:00.518913 12026 net.cpp:148] Top shape: 50 12 (600)
I0831 13:18:00.518926 12026 net.cpp:156] Memory required for data: 833424600
I0831 13:18:00.518949 12026 layer_factory.hpp:77] Creating layer ip_classification
I0831 13:18:00.518971 12026 net.cpp:91] Creating Layer ip_classification
I0831 13:18:00.518990 12026 net.cpp:425] ip_classification <- ip500_dropout_ip500_0_split_1
I0831 13:18:00.519006 12026 net.cpp:399] ip_classification -> ip_classification
I0831 13:18:00.519248 12026 net.cpp:141] Setting up ip_classification
I0831 13:18:00.519270 12026 net.cpp:148] Top shape: 50 7 (350)
I0831 13:18:00.519284 12026 net.cpp:156] Memory required for data: 833426000
I0831 13:18:00.519301 12026 layer_factory.hpp:77] Creating layer loss_hash
I0831 13:18:00.519326 12026 net.cpp:91] Creating Layer loss_hash
I0831 13:18:00.519347 12026 net.cpp:425] loss_hash <- ip_hash
I0831 13:18:00.519362 12026 net.cpp:425] loss_hash <- label_pattern_1_split_0
I0831 13:18:00.519379 12026 net.cpp:399] loss_hash -> loss_hash
I0831 13:18:00.519474 12026 net.cpp:141] Setting up loss_hash
I0831 13:18:00.519497 12026 net.cpp:148] Top shape: (1)
I0831 13:18:00.519511 12026 net.cpp:151]     with loss weight 0.1
I0831 13:18:00.519551 12026 net.cpp:156] Memory required for data: 833426004
I0831 13:18:00.519565 12026 layer_factory.hpp:77] Creating layer loss_classification
I0831 13:18:00.519585 12026 net.cpp:91] Creating Layer loss_classification
I0831 13:18:00.519599 12026 net.cpp:425] loss_classification <- ip_classification
I0831 13:18:00.519614 12026 net.cpp:425] loss_classification <- label_pattern_1_split_1
I0831 13:18:00.519668 12026 net.cpp:399] loss_classification -> loss_classification
I0831 13:18:00.519693 12026 layer_factory.hpp:77] Creating layer loss_classification
I0831 13:18:00.519814 12026 net.cpp:141] Setting up loss_classification
I0831 13:18:00.519836 12026 net.cpp:148] Top shape: (1)
I0831 13:18:00.519850 12026 net.cpp:151]     with loss weight 1
I0831 13:18:00.519867 12026 net.cpp:156] Memory required for data: 833426008
I0831 13:18:00.519881 12026 net.cpp:217] loss_classification needs backward computation.
I0831 13:18:00.519896 12026 net.cpp:217] loss_hash needs backward computation.
I0831 13:18:00.519909 12026 net.cpp:217] ip_classification needs backward computation.
I0831 13:18:00.519922 12026 net.cpp:217] ip_hash needs backward computation.
I0831 13:18:00.519939 12026 net.cpp:217] ip500_dropout_ip500_0_split needs backward computation.
I0831 13:18:00.519955 12026 net.cpp:217] dropout_ip500 needs backward computation.
I0831 13:18:00.519969 12026 net.cpp:217] relu_ip500 needs backward computation.
I0831 13:18:00.519981 12026 net.cpp:217] ip500 needs backward computation.
I0831 13:18:00.519999 12026 net.cpp:217] dropout_conv3 needs backward computation.
I0831 13:18:00.520012 12026 net.cpp:217] pool3 needs backward computation.
I0831 13:18:00.520030 12026 net.cpp:217] relu3 needs backward computation.
I0831 13:18:00.520042 12026 net.cpp:217] conv3 needs backward computation.
I0831 13:18:00.520061 12026 net.cpp:217] norm2 needs backward computation.
I0831 13:18:00.520073 12026 net.cpp:217] relu2 needs backward computation.
I0831 13:18:00.520087 12026 net.cpp:217] pool2 needs backward computation.
I0831 13:18:00.520100 12026 net.cpp:217] conv2 needs backward computation.
I0831 13:18:00.520114 12026 net.cpp:217] norm1 needs backward computation.
I0831 13:18:00.520131 12026 net.cpp:217] relu1 needs backward computation.
I0831 13:18:00.520144 12026 net.cpp:217] pool1 needs backward computation.
I0831 13:18:00.520157 12026 net.cpp:217] conv1 needs backward computation.
I0831 13:18:00.520174 12026 net.cpp:219] label_pattern_1_split does not need backward computation.
I0831 13:18:00.520190 12026 net.cpp:219] pattern does not need backward computation.
I0831 13:18:00.520203 12026 net.cpp:261] This network produces output loss_classification
I0831 13:18:00.520217 12026 net.cpp:261] This network produces output loss_hash
I0831 13:18:00.520248 12026 net.cpp:274] Network initialization done.
I0831 13:18:00.520910 12026 solver.cpp:181] Creating test net (#0) specified by net file: PATTERN/train_cnn_model.prototxt
I0831 13:18:00.520979 12026 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer pattern
I0831 13:18:00.521206 12026 net.cpp:49] Initializing net from parameters: 
name: "docomo_pattern_CNN"
state {
  phase: TEST
}
layer {
  name: "pattern"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
  }
  data_param {
    source: "PATTERN/pattern_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "dropout_conv3"
  type: "Dropout"
  bottom: "pool3"
  top: "dropout_conv3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip500"
  type: "InnerProduct"
  bottom: "dropout_conv3"
  top: "ip500"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu_ip500"
  type: "ReLU"
  bottom: "ip500"
  top: "ip500"
}
layer {
  name: "dropout_ip500"
  type: "Dropout"
  bottom: "ip500"
  top: "ip500"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip_hash"
  type: "InnerProduct"
  bottom: "ip500"
  top: "ip_hash"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 12
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "ip_classification"
  type: "InnerProduct"
  bottom: "ip500"
  top: "ip_classification"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "loss_hash"
  type: "HashingLoss"
  bottom: "ip_hash"
  bottom: "label"
  top: "loss_hash"
  loss_weight: 0.1
  hashing_loss_param {
    bi_margin: 24
    tradeoff: 0.01
  }
}
layer {
  name: "loss_classification"
  type: "SoftmaxWithLoss"
  bottom: "ip_classification"
  bottom: "label"
  top: "loss_classification"
}
layer {
  name: "accuracy_at_1"
  type: "Accuracy"
  bottom: "ip_classification"
  bottom: "label"
  top: "accuracy_at_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_at_5"
  type: "Accuracy"
  bottom: "ip_classification"
  bottom: "label"
  top: "accuracy_at_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0831 13:18:00.522480 12026 layer_factory.hpp:77] Creating layer pattern
I0831 13:18:00.522614 12026 net.cpp:91] Creating Layer pattern
I0831 13:18:00.522655 12026 net.cpp:399] pattern -> data
I0831 13:18:00.522677 12026 net.cpp:399] pattern -> label
I0831 13:18:00.523813 12034 db_lmdb.cpp:38] Opened lmdb PATTERN/pattern_val_lmdb
I0831 13:18:00.524224 12026 data_layer.cpp:41] output data size: 50,3,224,224
I0831 13:18:00.582200 12026 net.cpp:141] Setting up pattern
I0831 13:18:00.582279 12026 net.cpp:148] Top shape: 50 3 224 224 (7526400)
I0831 13:18:00.582300 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:18:00.582316 12026 net.cpp:156] Memory required for data: 30105800
I0831 13:18:00.582335 12026 layer_factory.hpp:77] Creating layer label_pattern_1_split
I0831 13:18:00.582363 12026 net.cpp:91] Creating Layer label_pattern_1_split
I0831 13:18:00.582438 12026 net.cpp:425] label_pattern_1_split <- label
I0831 13:18:00.582463 12026 net.cpp:399] label_pattern_1_split -> label_pattern_1_split_0
I0831 13:18:00.582491 12026 net.cpp:399] label_pattern_1_split -> label_pattern_1_split_1
I0831 13:18:00.582516 12026 net.cpp:399] label_pattern_1_split -> label_pattern_1_split_2
I0831 13:18:00.582537 12026 net.cpp:399] label_pattern_1_split -> label_pattern_1_split_3
I0831 13:18:00.582638 12026 net.cpp:141] Setting up label_pattern_1_split
I0831 13:18:00.582662 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:18:00.582679 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:18:00.582696 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:18:00.582712 12026 net.cpp:148] Top shape: 50 1 1 1 (50)
I0831 13:18:00.582727 12026 net.cpp:156] Memory required for data: 30106600
I0831 13:18:00.582743 12026 layer_factory.hpp:77] Creating layer conv1
I0831 13:18:00.582777 12026 net.cpp:91] Creating Layer conv1
I0831 13:18:00.582795 12026 net.cpp:425] conv1 <- data
I0831 13:18:00.582818 12026 net.cpp:399] conv1 -> conv1
I0831 13:18:00.583178 12026 net.cpp:141] Setting up conv1
I0831 13:18:00.583210 12026 net.cpp:148] Top shape: 50 32 224 224 (80281600)
I0831 13:18:00.583225 12026 net.cpp:156] Memory required for data: 351233000
I0831 13:18:00.583261 12026 layer_factory.hpp:77] Creating layer pool1
I0831 13:18:00.583286 12026 net.cpp:91] Creating Layer pool1
I0831 13:18:00.583302 12026 net.cpp:425] pool1 <- conv1
I0831 13:18:00.583328 12026 net.cpp:399] pool1 -> pool1
I0831 13:18:00.585762 12026 net.cpp:141] Setting up pool1
I0831 13:18:00.585810 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:18:00.585827 12026 net.cpp:156] Memory required for data: 431514600
I0831 13:18:00.585844 12026 layer_factory.hpp:77] Creating layer relu1
I0831 13:18:00.585865 12026 net.cpp:91] Creating Layer relu1
I0831 13:18:00.585881 12026 net.cpp:425] relu1 <- pool1
I0831 13:18:00.585899 12026 net.cpp:386] relu1 -> pool1 (in-place)
I0831 13:18:00.585921 12026 net.cpp:141] Setting up relu1
I0831 13:18:00.585938 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:18:00.585963 12026 net.cpp:156] Memory required for data: 511796200
I0831 13:18:00.585978 12026 layer_factory.hpp:77] Creating layer norm1
I0831 13:18:00.586002 12026 net.cpp:91] Creating Layer norm1
I0831 13:18:00.586030 12026 net.cpp:425] norm1 <- pool1
I0831 13:18:00.586050 12026 net.cpp:399] norm1 -> norm1
I0831 13:18:00.586182 12026 net.cpp:141] Setting up norm1
I0831 13:18:00.586213 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:18:00.586230 12026 net.cpp:156] Memory required for data: 592077800
I0831 13:18:00.586243 12026 layer_factory.hpp:77] Creating layer conv2
I0831 13:18:00.586269 12026 net.cpp:91] Creating Layer conv2
I0831 13:18:00.586290 12026 net.cpp:425] conv2 <- norm1
I0831 13:18:00.586308 12026 net.cpp:399] conv2 -> conv2
I0831 13:18:00.586818 12026 net.cpp:141] Setting up conv2
I0831 13:18:00.586846 12026 net.cpp:148] Top shape: 50 32 112 112 (20070400)
I0831 13:18:00.586865 12026 net.cpp:156] Memory required for data: 672359400
I0831 13:18:00.586887 12026 layer_factory.hpp:77] Creating layer pool2
I0831 13:18:00.586910 12026 net.cpp:91] Creating Layer pool2
I0831 13:18:00.586926 12026 net.cpp:425] pool2 <- conv2
I0831 13:18:00.586943 12026 net.cpp:399] pool2 -> pool2
I0831 13:18:00.586992 12026 net.cpp:141] Setting up pool2
I0831 13:18:00.587018 12026 net.cpp:148] Top shape: 50 32 56 56 (5017600)
I0831 13:18:00.587034 12026 net.cpp:156] Memory required for data: 692429800
I0831 13:18:00.587049 12026 layer_factory.hpp:77] Creating layer relu2
I0831 13:18:00.587067 12026 net.cpp:91] Creating Layer relu2
I0831 13:18:00.587086 12026 net.cpp:425] relu2 <- pool2
I0831 13:18:00.587106 12026 net.cpp:386] relu2 -> pool2 (in-place)
I0831 13:18:00.587131 12026 net.cpp:141] Setting up relu2
I0831 13:18:00.587147 12026 net.cpp:148] Top shape: 50 32 56 56 (5017600)
I0831 13:18:00.587163 12026 net.cpp:156] Memory required for data: 712500200
I0831 13:18:00.587178 12026 layer_factory.hpp:77] Creating layer norm2
I0831 13:18:00.587224 12026 net.cpp:91] Creating Layer norm2
I0831 13:18:00.587241 12026 net.cpp:425] norm2 <- pool2
I0831 13:18:00.587266 12026 net.cpp:399] norm2 -> norm2
I0831 13:18:00.587393 12026 net.cpp:141] Setting up norm2
I0831 13:18:00.587419 12026 net.cpp:148] Top shape: 50 32 56 56 (5017600)
I0831 13:18:00.587435 12026 net.cpp:156] Memory required for data: 732570600
I0831 13:18:00.587448 12026 layer_factory.hpp:77] Creating layer conv3
I0831 13:18:00.587473 12026 net.cpp:91] Creating Layer conv3
I0831 13:18:00.587494 12026 net.cpp:425] conv3 <- norm2
I0831 13:18:00.587512 12026 net.cpp:399] conv3 -> conv3
I0831 13:18:00.588224 12026 net.cpp:141] Setting up conv3
I0831 13:18:00.588251 12026 net.cpp:148] Top shape: 50 64 56 56 (10035200)
I0831 13:18:00.588274 12026 net.cpp:156] Memory required for data: 772711400
I0831 13:18:00.588295 12026 layer_factory.hpp:77] Creating layer relu3
I0831 13:18:00.588317 12026 net.cpp:91] Creating Layer relu3
I0831 13:18:00.588332 12026 net.cpp:425] relu3 <- conv3
I0831 13:18:00.588349 12026 net.cpp:386] relu3 -> conv3 (in-place)
I0831 13:18:00.588372 12026 net.cpp:141] Setting up relu3
I0831 13:18:00.588390 12026 net.cpp:148] Top shape: 50 64 56 56 (10035200)
I0831 13:18:00.588407 12026 net.cpp:156] Memory required for data: 812852200
I0831 13:18:00.588428 12026 layer_factory.hpp:77] Creating layer pool3
I0831 13:18:00.588446 12026 net.cpp:91] Creating Layer pool3
I0831 13:18:00.588461 12026 net.cpp:425] pool3 <- conv3
I0831 13:18:00.588480 12026 net.cpp:399] pool3 -> pool3
I0831 13:18:00.588521 12026 net.cpp:141] Setting up pool3
I0831 13:18:00.588541 12026 net.cpp:148] Top shape: 50 64 28 28 (2508800)
I0831 13:18:00.588557 12026 net.cpp:156] Memory required for data: 822887400
I0831 13:18:00.588577 12026 layer_factory.hpp:77] Creating layer dropout_conv3
I0831 13:18:00.588599 12026 net.cpp:91] Creating Layer dropout_conv3
I0831 13:18:00.588618 12026 net.cpp:425] dropout_conv3 <- pool3
I0831 13:18:00.588636 12026 net.cpp:399] dropout_conv3 -> dropout_conv3
I0831 13:18:00.588698 12026 net.cpp:141] Setting up dropout_conv3
I0831 13:18:00.588726 12026 net.cpp:148] Top shape: 50 64 28 28 (2508800)
I0831 13:18:00.588740 12026 net.cpp:156] Memory required for data: 832922600
I0831 13:18:00.588755 12026 layer_factory.hpp:77] Creating layer ip500
I0831 13:18:00.588778 12026 net.cpp:91] Creating Layer ip500
I0831 13:18:00.588793 12026 net.cpp:425] ip500 <- dropout_conv3
I0831 13:18:00.588811 12026 net.cpp:399] ip500 -> ip500
I0831 13:18:01.517550 12026 net.cpp:141] Setting up ip500
I0831 13:18:01.517624 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:01.517639 12026 net.cpp:156] Memory required for data: 833022600
I0831 13:18:01.517663 12026 layer_factory.hpp:77] Creating layer relu_ip500
I0831 13:18:01.517685 12026 net.cpp:91] Creating Layer relu_ip500
I0831 13:18:01.517701 12026 net.cpp:425] relu_ip500 <- ip500
I0831 13:18:01.517722 12026 net.cpp:386] relu_ip500 -> ip500 (in-place)
I0831 13:18:01.517745 12026 net.cpp:141] Setting up relu_ip500
I0831 13:18:01.517760 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:01.517774 12026 net.cpp:156] Memory required for data: 833122600
I0831 13:18:01.517792 12026 layer_factory.hpp:77] Creating layer dropout_ip500
I0831 13:18:01.517813 12026 net.cpp:91] Creating Layer dropout_ip500
I0831 13:18:01.517828 12026 net.cpp:425] dropout_ip500 <- ip500
I0831 13:18:01.517844 12026 net.cpp:386] dropout_ip500 -> ip500 (in-place)
I0831 13:18:01.517887 12026 net.cpp:141] Setting up dropout_ip500
I0831 13:18:01.517916 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:01.517931 12026 net.cpp:156] Memory required for data: 833222600
I0831 13:18:01.517944 12026 layer_factory.hpp:77] Creating layer ip500_dropout_ip500_0_split
I0831 13:18:01.517964 12026 net.cpp:91] Creating Layer ip500_dropout_ip500_0_split
I0831 13:18:01.517979 12026 net.cpp:425] ip500_dropout_ip500_0_split <- ip500
I0831 13:18:01.517995 12026 net.cpp:399] ip500_dropout_ip500_0_split -> ip500_dropout_ip500_0_split_0
I0831 13:18:01.518054 12026 net.cpp:399] ip500_dropout_ip500_0_split -> ip500_dropout_ip500_0_split_1
I0831 13:18:01.518108 12026 net.cpp:141] Setting up ip500_dropout_ip500_0_split
I0831 13:18:01.518131 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:01.518146 12026 net.cpp:148] Top shape: 50 500 (25000)
I0831 13:18:01.518159 12026 net.cpp:156] Memory required for data: 833422600
I0831 13:18:01.518173 12026 layer_factory.hpp:77] Creating layer ip_hash
I0831 13:18:01.518193 12026 net.cpp:91] Creating Layer ip_hash
I0831 13:18:01.518208 12026 net.cpp:425] ip_hash <- ip500_dropout_ip500_0_split_0
I0831 13:18:01.518226 12026 net.cpp:399] ip_hash -> ip_hash
I0831 13:18:01.518569 12026 net.cpp:141] Setting up ip_hash
I0831 13:18:01.518592 12026 net.cpp:148] Top shape: 50 12 (600)
I0831 13:18:01.518606 12026 net.cpp:156] Memory required for data: 833425000
I0831 13:18:01.518632 12026 layer_factory.hpp:77] Creating layer ip_classification
I0831 13:18:01.518653 12026 net.cpp:91] Creating Layer ip_classification
I0831 13:18:01.518668 12026 net.cpp:425] ip_classification <- ip500_dropout_ip500_0_split_1
I0831 13:18:01.518684 12026 net.cpp:399] ip_classification -> ip_classification
I0831 13:18:01.518923 12026 net.cpp:141] Setting up ip_classification
I0831 13:18:01.518945 12026 net.cpp:148] Top shape: 50 7 (350)
I0831 13:18:01.518959 12026 net.cpp:156] Memory required for data: 833426400
I0831 13:18:01.518976 12026 layer_factory.hpp:77] Creating layer ip_classification_ip_classification_0_split
I0831 13:18:01.518995 12026 net.cpp:91] Creating Layer ip_classification_ip_classification_0_split
I0831 13:18:01.519008 12026 net.cpp:425] ip_classification_ip_classification_0_split <- ip_classification
I0831 13:18:01.519024 12026 net.cpp:399] ip_classification_ip_classification_0_split -> ip_classification_ip_classification_0_split_0
I0831 13:18:01.519043 12026 net.cpp:399] ip_classification_ip_classification_0_split -> ip_classification_ip_classification_0_split_1
I0831 13:18:01.519062 12026 net.cpp:399] ip_classification_ip_classification_0_split -> ip_classification_ip_classification_0_split_2
I0831 13:18:01.519127 12026 net.cpp:141] Setting up ip_classification_ip_classification_0_split
I0831 13:18:01.519151 12026 net.cpp:148] Top shape: 50 7 (350)
I0831 13:18:01.519166 12026 net.cpp:148] Top shape: 50 7 (350)
I0831 13:18:01.519181 12026 net.cpp:148] Top shape: 50 7 (350)
I0831 13:18:01.519194 12026 net.cpp:156] Memory required for data: 833430600
I0831 13:18:01.519207 12026 layer_factory.hpp:77] Creating layer loss_hash
I0831 13:18:01.519229 12026 net.cpp:91] Creating Layer loss_hash
I0831 13:18:01.519249 12026 net.cpp:425] loss_hash <- ip_hash
I0831 13:18:01.519264 12026 net.cpp:425] loss_hash <- label_pattern_1_split_0
I0831 13:18:01.519281 12026 net.cpp:399] loss_hash -> loss_hash
I0831 13:18:01.519358 12026 net.cpp:141] Setting up loss_hash
I0831 13:18:01.519381 12026 net.cpp:148] Top shape: (1)
I0831 13:18:01.519395 12026 net.cpp:151]     with loss weight 0.1
I0831 13:18:01.519425 12026 net.cpp:156] Memory required for data: 833430604
I0831 13:18:01.519440 12026 layer_factory.hpp:77] Creating layer loss_classification
I0831 13:18:01.519457 12026 net.cpp:91] Creating Layer loss_classification
I0831 13:18:01.519472 12026 net.cpp:425] loss_classification <- ip_classification_ip_classification_0_split_0
I0831 13:18:01.519487 12026 net.cpp:425] loss_classification <- label_pattern_1_split_1
I0831 13:18:01.519502 12026 net.cpp:399] loss_classification -> loss_classification
I0831 13:18:01.519525 12026 layer_factory.hpp:77] Creating layer loss_classification
I0831 13:18:01.519631 12026 net.cpp:141] Setting up loss_classification
I0831 13:18:01.519654 12026 net.cpp:148] Top shape: (1)
I0831 13:18:01.519670 12026 net.cpp:151]     with loss weight 1
I0831 13:18:01.519687 12026 net.cpp:156] Memory required for data: 833430608
I0831 13:18:01.519701 12026 layer_factory.hpp:77] Creating layer accuracy_at_1
I0831 13:18:01.519731 12026 net.cpp:91] Creating Layer accuracy_at_1
I0831 13:18:01.519749 12026 net.cpp:425] accuracy_at_1 <- ip_classification_ip_classification_0_split_1
I0831 13:18:01.519783 12026 net.cpp:425] accuracy_at_1 <- label_pattern_1_split_2
I0831 13:18:01.519804 12026 net.cpp:399] accuracy_at_1 -> accuracy_at_1
I0831 13:18:01.519831 12026 net.cpp:141] Setting up accuracy_at_1
I0831 13:18:01.519848 12026 net.cpp:148] Top shape: (1)
I0831 13:18:01.519861 12026 net.cpp:156] Memory required for data: 833430612
I0831 13:18:01.519876 12026 layer_factory.hpp:77] Creating layer accuracy_at_5
I0831 13:18:01.519896 12026 net.cpp:91] Creating Layer accuracy_at_5
I0831 13:18:01.519911 12026 net.cpp:425] accuracy_at_5 <- ip_classification_ip_classification_0_split_2
I0831 13:18:01.519930 12026 net.cpp:425] accuracy_at_5 <- label_pattern_1_split_3
I0831 13:18:01.519949 12026 net.cpp:399] accuracy_at_5 -> accuracy_at_5
I0831 13:18:01.519973 12026 net.cpp:141] Setting up accuracy_at_5
I0831 13:18:01.519990 12026 net.cpp:148] Top shape: (1)
I0831 13:18:01.520004 12026 net.cpp:156] Memory required for data: 833430616
I0831 13:18:01.520018 12026 net.cpp:219] accuracy_at_5 does not need backward computation.
I0831 13:18:01.520033 12026 net.cpp:219] accuracy_at_1 does not need backward computation.
I0831 13:18:01.520048 12026 net.cpp:217] loss_classification needs backward computation.
I0831 13:18:01.520062 12026 net.cpp:217] loss_hash needs backward computation.
I0831 13:18:01.520087 12026 net.cpp:217] ip_classification_ip_classification_0_split needs backward computation.
I0831 13:18:01.520099 12026 net.cpp:217] ip_classification needs backward computation.
I0831 13:18:01.520113 12026 net.cpp:217] ip_hash needs backward computation.
I0831 13:18:01.520128 12026 net.cpp:217] ip500_dropout_ip500_0_split needs backward computation.
I0831 13:18:01.520140 12026 net.cpp:217] dropout_ip500 needs backward computation.
I0831 13:18:01.520154 12026 net.cpp:217] relu_ip500 needs backward computation.
I0831 13:18:01.520171 12026 net.cpp:217] ip500 needs backward computation.
I0831 13:18:01.520184 12026 net.cpp:217] dropout_conv3 needs backward computation.
I0831 13:18:01.520198 12026 net.cpp:217] pool3 needs backward computation.
I0831 13:18:01.520215 12026 net.cpp:217] relu3 needs backward computation.
I0831 13:18:01.520231 12026 net.cpp:217] conv3 needs backward computation.
I0831 13:18:01.520243 12026 net.cpp:217] norm2 needs backward computation.
I0831 13:18:01.520257 12026 net.cpp:217] relu2 needs backward computation.
I0831 13:18:01.520272 12026 net.cpp:217] pool2 needs backward computation.
I0831 13:18:01.520284 12026 net.cpp:217] conv2 needs backward computation.
I0831 13:18:01.520298 12026 net.cpp:217] norm1 needs backward computation.
I0831 13:18:01.520313 12026 net.cpp:217] relu1 needs backward computation.
I0831 13:18:01.520325 12026 net.cpp:217] pool1 needs backward computation.
I0831 13:18:01.520339 12026 net.cpp:217] conv1 needs backward computation.
I0831 13:18:01.520355 12026 net.cpp:219] label_pattern_1_split does not need backward computation.
I0831 13:18:01.520370 12026 net.cpp:219] pattern does not need backward computation.
I0831 13:18:01.520383 12026 net.cpp:261] This network produces output accuracy_at_1
I0831 13:18:01.520396 12026 net.cpp:261] This network produces output accuracy_at_5
I0831 13:18:01.520411 12026 net.cpp:261] This network produces output loss_classification
I0831 13:18:01.520424 12026 net.cpp:261] This network produces output loss_hash
I0831 13:18:01.520458 12026 net.cpp:274] Network initialization done.
I0831 13:18:01.520576 12026 solver.cpp:60] Solver scaffolding done.
I0831 13:18:01.520982 12026 caffe.cpp:219] Starting Optimization
I0831 13:18:01.521008 12026 solver.cpp:279] Solving docomo_pattern_CNN
I0831 13:18:01.521020 12026 solver.cpp:280] Learning Rate Policy: multistep
I0831 13:18:01.522157 12026 solver.cpp:337] Iteration 0, Testing net (#0)
I0831 13:18:08.284610 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.137143
I0831 13:18:08.284682 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.712
I0831 13:18:08.284715 12026 solver.cpp:404]     Test net output #2: loss_classification = 2.86536 (* 1 = 2.86536 loss)
I0831 13:18:08.284783 12026 solver.cpp:404]     Test net output #3: loss_hash = 7.57573 (* 0.1 = 0.757573 loss)
I0831 13:18:08.405185 12026 solver.cpp:228] Iteration 0, loss = 4.91884
I0831 13:18:08.405257 12026 solver.cpp:244]     Train net output #0: loss_classification = 3.94858 (* 1 = 3.94858 loss)
I0831 13:18:08.405280 12026 solver.cpp:244]     Train net output #1: loss_hash = 9.70261 (* 0.1 = 0.970261 loss)
I0831 13:18:08.405318 12026 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0831 13:18:45.468245 12026 solver.cpp:228] Iteration 100, loss = 2.67864
I0831 13:18:45.468516 12026 solver.cpp:244]     Train net output #0: loss_classification = 2.06746 (* 1 = 2.06746 loss)
I0831 13:18:45.468549 12026 solver.cpp:244]     Train net output #1: loss_hash = 4.12501 (* 0.1 = 0.412501 loss)
I0831 13:18:45.468564 12026 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0831 13:19:25.766646 12026 solver.cpp:228] Iteration 200, loss = 2.23342
I0831 13:19:25.766844 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.95918 (* 1 = 1.95918 loss)
I0831 13:19:25.766868 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.73263 (* 0.1 = 0.373263 loss)
I0831 13:19:25.766880 12026 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0831 13:20:06.053210 12026 solver.cpp:228] Iteration 300, loss = 2.12147
I0831 13:20:06.053447 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.82709 (* 1 = 1.82709 loss)
I0831 13:20:06.053480 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.45686 (* 0.1 = 0.345686 loss)
I0831 13:20:06.053496 12026 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0831 13:20:46.333662 12026 solver.cpp:228] Iteration 400, loss = 1.98052
I0831 13:20:46.333927 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.59303 (* 1 = 1.59303 loss)
I0831 13:20:46.333962 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.53146 (* 0.1 = 0.353146 loss)
I0831 13:20:46.333978 12026 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0831 13:21:26.612625 12026 solver.cpp:228] Iteration 500, loss = 1.90381
I0831 13:21:26.612874 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.53293 (* 1 = 1.53293 loss)
I0831 13:21:26.612905 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.36685 (* 0.1 = 0.336685 loss)
I0831 13:21:26.612920 12026 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0831 13:22:06.896980 12026 solver.cpp:228] Iteration 600, loss = 1.81005
I0831 13:22:06.897164 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.35244 (* 1 = 1.35244 loss)
I0831 13:22:06.897197 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.31587 (* 0.1 = 0.331587 loss)
I0831 13:22:06.897222 12026 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0831 13:22:47.183334 12026 solver.cpp:228] Iteration 700, loss = 1.8003
I0831 13:22:47.183573 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.65284 (* 1 = 1.65284 loss)
I0831 13:22:47.183604 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.38472 (* 0.1 = 0.338472 loss)
I0831 13:22:47.183619 12026 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0831 13:23:27.467432 12026 solver.cpp:228] Iteration 800, loss = 1.78824
I0831 13:23:27.467666 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.58601 (* 1 = 1.58601 loss)
I0831 13:23:27.467702 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.92792 (* 0.1 = 0.292792 loss)
I0831 13:23:27.467730 12026 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0831 13:24:07.749649 12026 solver.cpp:228] Iteration 900, loss = 1.74924
I0831 13:24:07.749891 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.48056 (* 1 = 1.48056 loss)
I0831 13:24:07.749927 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.52802 (* 0.1 = 0.352802 loss)
I0831 13:24:07.749943 12026 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0831 13:24:47.626929 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_1000.caffemodel
I0831 13:24:48.387519 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_1000.solverstate
I0831 13:24:48.575852 12026 solver.cpp:337] Iteration 1000, Testing net (#0)
I0831 13:24:56.065855 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.522857
I0831 13:24:56.065927 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.951428
I0831 13:24:56.065959 12026 solver.cpp:404]     Test net output #2: loss_classification = 1.28884 (* 1 = 1.28884 loss)
I0831 13:24:56.065980 12026 solver.cpp:404]     Test net output #3: loss_hash = 6.60158 (* 0.1 = 0.660158 loss)
I0831 13:24:56.182363 12026 solver.cpp:228] Iteration 1000, loss = 1.71538
I0831 13:24:56.182433 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.17373 (* 1 = 1.17373 loss)
I0831 13:24:56.182456 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.97625 (* 0.1 = 0.297625 loss)
I0831 13:24:56.182487 12026 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0831 13:25:36.457077 12026 solver.cpp:228] Iteration 1100, loss = 1.67095
I0831 13:25:36.457264 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.26174 (* 1 = 1.26174 loss)
I0831 13:25:36.457291 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.07583 (* 0.1 = 0.307583 loss)
I0831 13:25:36.457315 12026 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0831 13:26:16.723263 12026 solver.cpp:228] Iteration 1200, loss = 1.66236
I0831 13:26:16.723430 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.09669 (* 1 = 1.09669 loss)
I0831 13:26:16.723457 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.02058 (* 0.1 = 0.302058 loss)
I0831 13:26:16.723479 12026 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0831 13:26:56.994133 12026 solver.cpp:228] Iteration 1300, loss = 1.64391
I0831 13:26:56.994321 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.26032 (* 1 = 1.26032 loss)
I0831 13:26:56.994349 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.14643 (* 0.1 = 0.314643 loss)
I0831 13:26:56.994376 12026 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0831 13:27:37.266364 12026 solver.cpp:228] Iteration 1400, loss = 1.6448
I0831 13:27:37.266608 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.21523 (* 1 = 1.21523 loss)
I0831 13:27:37.266640 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.12687 (* 0.1 = 0.312687 loss)
I0831 13:27:37.266656 12026 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0831 13:28:17.543965 12026 solver.cpp:228] Iteration 1500, loss = 1.63883
I0831 13:28:17.544247 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.32206 (* 1 = 1.32206 loss)
I0831 13:28:17.544277 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.46665 (* 0.1 = 0.346665 loss)
I0831 13:28:17.544292 12026 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0831 13:28:57.822571 12026 solver.cpp:228] Iteration 1600, loss = 1.61126
I0831 13:28:57.822840 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.30461 (* 1 = 1.30461 loss)
I0831 13:28:57.822867 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.37916 (* 0.1 = 0.337916 loss)
I0831 13:28:57.822881 12026 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0831 13:29:38.099234 12026 solver.cpp:228] Iteration 1700, loss = 1.59311
I0831 13:29:38.099444 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.26238 (* 1 = 1.26238 loss)
I0831 13:29:38.099472 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.25113 (* 0.1 = 0.325113 loss)
I0831 13:29:38.099486 12026 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0831 13:30:18.367043 12026 solver.cpp:228] Iteration 1800, loss = 1.57746
I0831 13:30:18.367326 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.73861 (* 1 = 1.73861 loss)
I0831 13:30:18.367348 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.29883 (* 0.1 = 0.329883 loss)
I0831 13:30:18.367369 12026 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0831 13:30:58.636570 12026 solver.cpp:228] Iteration 1900, loss = 1.55588
I0831 13:30:58.636832 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.976263 (* 1 = 0.976263 loss)
I0831 13:30:58.636863 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.69464 (* 0.1 = 0.269464 loss)
I0831 13:30:58.636879 12026 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0831 13:31:38.499235 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_2000.caffemodel
I0831 13:31:39.213310 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_2000.solverstate
I0831 13:31:39.399875 12026 solver.cpp:337] Iteration 2000, Testing net (#0)
I0831 13:31:46.864758 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.565143
I0831 13:31:46.864830 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.964
I0831 13:31:46.864862 12026 solver.cpp:404]     Test net output #2: loss_classification = 1.18028 (* 1 = 1.18028 loss)
I0831 13:31:46.864883 12026 solver.cpp:404]     Test net output #3: loss_hash = 5.74076 (* 0.1 = 0.574076 loss)
I0831 13:31:46.981437 12026 solver.cpp:228] Iteration 2000, loss = 1.55157
I0831 13:31:46.981509 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.41056 (* 1 = 1.41056 loss)
I0831 13:31:46.981533 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.10822 (* 0.1 = 0.310822 loss)
I0831 13:31:46.981557 12026 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0831 13:32:27.259829 12026 solver.cpp:228] Iteration 2100, loss = 1.55267
I0831 13:32:27.260004 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.50501 (* 1 = 1.50501 loss)
I0831 13:32:27.260038 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.81801 (* 0.1 = 0.281801 loss)
I0831 13:32:27.260064 12026 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0831 13:33:07.531780 12026 solver.cpp:228] Iteration 2200, loss = 1.53109
I0831 13:33:07.532052 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.25671 (* 1 = 1.25671 loss)
I0831 13:33:07.532081 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.71412 (* 0.1 = 0.271412 loss)
I0831 13:33:07.532094 12026 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0831 13:33:47.811883 12026 solver.cpp:228] Iteration 2300, loss = 1.50171
I0831 13:33:47.812074 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.19213 (* 1 = 1.19213 loss)
I0831 13:33:47.812103 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.8572 (* 0.1 = 0.28572 loss)
I0831 13:33:47.812125 12026 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0831 13:34:28.091444 12026 solver.cpp:228] Iteration 2400, loss = 1.49408
I0831 13:34:28.091680 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.16368 (* 1 = 1.16368 loss)
I0831 13:34:28.091706 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.35784 (* 0.1 = 0.335784 loss)
I0831 13:34:28.091727 12026 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0831 13:35:08.360745 12026 solver.cpp:228] Iteration 2500, loss = 1.49458
I0831 13:35:08.360939 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.36758 (* 1 = 1.36758 loss)
I0831 13:35:08.360967 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.88574 (* 0.1 = 0.288574 loss)
I0831 13:35:08.360993 12026 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0831 13:35:48.631947 12026 solver.cpp:228] Iteration 2600, loss = 1.46347
I0831 13:35:48.632225 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.45733 (* 1 = 1.45733 loss)
I0831 13:35:48.632256 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.778 (* 0.1 = 0.2778 loss)
I0831 13:35:48.632280 12026 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0831 13:36:28.901046 12026 solver.cpp:228] Iteration 2700, loss = 1.47848
I0831 13:36:28.901219 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.18764 (* 1 = 1.18764 loss)
I0831 13:36:28.901245 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.69802 (* 0.1 = 0.269802 loss)
I0831 13:36:28.901275 12026 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0831 13:37:09.175195 12026 solver.cpp:228] Iteration 2800, loss = 1.48373
I0831 13:37:09.175489 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.28712 (* 1 = 1.28712 loss)
I0831 13:37:09.175520 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.88474 (* 0.1 = 0.288474 loss)
I0831 13:37:09.175544 12026 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0831 13:37:49.453521 12026 solver.cpp:228] Iteration 2900, loss = 1.41962
I0831 13:37:49.453707 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.30047 (* 1 = 1.30047 loss)
I0831 13:37:49.453735 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.69678 (* 0.1 = 0.269678 loss)
I0831 13:37:49.453759 12026 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0831 13:38:29.326124 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_3000.caffemodel
I0831 13:38:30.042768 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_3000.solverstate
I0831 13:38:30.229737 12026 solver.cpp:337] Iteration 3000, Testing net (#0)
I0831 13:38:37.699276 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.594286
I0831 13:38:37.699347 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.958571
I0831 13:38:37.699373 12026 solver.cpp:404]     Test net output #2: loss_classification = 1.10555 (* 1 = 1.10555 loss)
I0831 13:38:37.699398 12026 solver.cpp:404]     Test net output #3: loss_hash = 5.3345 (* 0.1 = 0.53345 loss)
I0831 13:38:37.816023 12026 solver.cpp:228] Iteration 3000, loss = 1.44885
I0831 13:38:37.816095 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.21516 (* 1 = 1.21516 loss)
I0831 13:38:37.816120 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.74909 (* 0.1 = 0.274909 loss)
I0831 13:38:37.816151 12026 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0831 13:39:18.106112 12026 solver.cpp:228] Iteration 3100, loss = 1.40663
I0831 13:39:18.106359 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.940284 (* 1 = 0.940284 loss)
I0831 13:39:18.106392 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.72784 (* 0.1 = 0.272784 loss)
I0831 13:39:18.106415 12026 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0831 13:39:58.396062 12026 solver.cpp:228] Iteration 3200, loss = 1.41746
I0831 13:39:58.396234 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.10499 (* 1 = 1.10499 loss)
I0831 13:39:58.396260 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.83509 (* 0.1 = 0.283509 loss)
I0831 13:39:58.396281 12026 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0831 13:40:38.682929 12026 solver.cpp:228] Iteration 3300, loss = 1.39975
I0831 13:40:38.683115 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.03925 (* 1 = 1.03925 loss)
I0831 13:40:38.683143 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.73066 (* 0.1 = 0.273066 loss)
I0831 13:40:38.683174 12026 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0831 13:41:18.972919 12026 solver.cpp:228] Iteration 3400, loss = 1.42635
I0831 13:41:18.973091 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.915344 (* 1 = 0.915344 loss)
I0831 13:41:18.973119 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.61389 (* 0.1 = 0.261389 loss)
I0831 13:41:18.973147 12026 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0831 13:41:59.259611 12026 solver.cpp:228] Iteration 3500, loss = 1.38423
I0831 13:41:59.259867 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.34469 (* 1 = 1.34469 loss)
I0831 13:41:59.259894 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.82594 (* 0.1 = 0.282594 loss)
I0831 13:41:59.259925 12026 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0831 13:42:39.548400 12026 solver.cpp:228] Iteration 3600, loss = 1.39231
I0831 13:42:39.548692 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.42761 (* 1 = 1.42761 loss)
I0831 13:42:39.548722 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.90379 (* 0.1 = 0.290379 loss)
I0831 13:42:39.548746 12026 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0831 13:43:19.832787 12026 solver.cpp:228] Iteration 3700, loss = 1.38072
I0831 13:43:19.832976 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.712404 (* 1 = 0.712404 loss)
I0831 13:43:19.833008 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42072 (* 0.1 = 0.242072 loss)
I0831 13:43:19.833027 12026 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0831 13:44:00.120375 12026 solver.cpp:228] Iteration 3800, loss = 1.35492
I0831 13:44:00.120546 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.943144 (* 1 = 0.943144 loss)
I0831 13:44:00.120573 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3847 (* 0.1 = 0.23847 loss)
I0831 13:44:00.120597 12026 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0831 13:44:40.410028 12026 solver.cpp:228] Iteration 3900, loss = 1.33533
I0831 13:44:40.410204 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.893921 (* 1 = 0.893921 loss)
I0831 13:44:40.410228 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.67191 (* 0.1 = 0.267191 loss)
I0831 13:44:40.410248 12026 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0831 13:45:20.295579 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_4000.caffemodel
I0831 13:45:21.014480 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_4000.solverstate
I0831 13:45:21.203008 12026 solver.cpp:337] Iteration 4000, Testing net (#0)
I0831 13:45:28.685185 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.635714
I0831 13:45:28.685255 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.966
I0831 13:45:28.685279 12026 solver.cpp:404]     Test net output #2: loss_classification = 1.02659 (* 1 = 1.02659 loss)
I0831 13:45:28.685298 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.78397 (* 0.1 = 0.478397 loss)
I0831 13:45:28.801712 12026 solver.cpp:228] Iteration 4000, loss = 1.37455
I0831 13:45:28.801777 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.15833 (* 1 = 1.15833 loss)
I0831 13:45:28.801800 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.78155 (* 0.1 = 0.278155 loss)
I0831 13:45:28.801825 12026 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0831 13:46:09.075925 12026 solver.cpp:228] Iteration 4100, loss = 1.3805
I0831 13:46:09.076098 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.15227 (* 1 = 1.15227 loss)
I0831 13:46:09.076126 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.061 (* 0.1 = 0.3061 loss)
I0831 13:46:09.076148 12026 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0831 13:46:49.350981 12026 solver.cpp:228] Iteration 4200, loss = 1.34086
I0831 13:46:49.351130 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.868344 (* 1 = 0.868344 loss)
I0831 13:46:49.351155 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.00842 (* 0.1 = 0.300842 loss)
I0831 13:46:49.351174 12026 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0831 13:47:29.630708 12026 solver.cpp:228] Iteration 4300, loss = 1.34796
I0831 13:47:29.630888 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.01578 (* 1 = 1.01578 loss)
I0831 13:47:29.630915 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.67137 (* 0.1 = 0.267137 loss)
I0831 13:47:29.630941 12026 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0831 13:48:09.910913 12026 solver.cpp:228] Iteration 4400, loss = 1.31861
I0831 13:48:09.911125 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.904931 (* 1 = 0.904931 loss)
I0831 13:48:09.911154 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.73079 (* 0.1 = 0.273079 loss)
I0831 13:48:09.911175 12026 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0831 13:48:50.187129 12026 solver.cpp:228] Iteration 4500, loss = 1.31569
I0831 13:48:50.187407 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.00889 (* 1 = 1.00889 loss)
I0831 13:48:50.187438 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.7729 (* 0.1 = 0.27729 loss)
I0831 13:48:50.187454 12026 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0831 13:49:30.465076 12026 solver.cpp:228] Iteration 4600, loss = 1.30899
I0831 13:49:30.465243 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.92549 (* 1 = 0.92549 loss)
I0831 13:49:30.465268 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.55883 (* 0.1 = 0.255883 loss)
I0831 13:49:30.465288 12026 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0831 13:50:10.741370 12026 solver.cpp:228] Iteration 4700, loss = 1.34196
I0831 13:50:10.741559 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.023 (* 1 = 1.023 loss)
I0831 13:50:10.741587 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.85508 (* 0.1 = 0.285508 loss)
I0831 13:50:10.741608 12026 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0831 13:50:51.022878 12026 solver.cpp:228] Iteration 4800, loss = 1.31331
I0831 13:50:51.023063 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.25826 (* 1 = 1.25826 loss)
I0831 13:50:51.023090 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.86605 (* 0.1 = 0.286605 loss)
I0831 13:50:51.023113 12026 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0831 13:51:31.298143 12026 solver.cpp:228] Iteration 4900, loss = 1.28811
I0831 13:51:31.298319 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.817679 (* 1 = 0.817679 loss)
I0831 13:51:31.298344 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3279 (* 0.1 = 0.23279 loss)
I0831 13:51:31.298363 12026 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0831 13:52:11.177733 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_5000.caffemodel
I0831 13:52:11.933573 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_5000.solverstate
I0831 13:52:12.135329 12026 solver.cpp:337] Iteration 5000, Testing net (#0)
I0831 13:52:19.625267 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.627429
I0831 13:52:19.625336 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.968571
I0831 13:52:19.625361 12026 solver.cpp:404]     Test net output #2: loss_classification = 1.00409 (* 1 = 1.00409 loss)
I0831 13:52:19.625383 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.9443 (* 0.1 = 0.49443 loss)
I0831 13:52:19.742406 12026 solver.cpp:228] Iteration 5000, loss = 1.30848
I0831 13:52:19.742473 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.11671 (* 1 = 1.11671 loss)
I0831 13:52:19.742496 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.64631 (* 0.1 = 0.264631 loss)
I0831 13:52:19.742521 12026 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0831 13:53:00.022747 12026 solver.cpp:228] Iteration 5100, loss = 1.29829
I0831 13:53:00.022913 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.26034 (* 1 = 1.26034 loss)
I0831 13:53:00.022943 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36289 (* 0.1 = 0.236289 loss)
I0831 13:53:00.022961 12026 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0831 13:53:40.300873 12026 solver.cpp:228] Iteration 5200, loss = 1.30024
I0831 13:53:40.301064 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.19111 (* 1 = 1.19111 loss)
I0831 13:53:40.301090 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.83072 (* 0.1 = 0.283072 loss)
I0831 13:53:40.301111 12026 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0831 13:54:20.577621 12026 solver.cpp:228] Iteration 5300, loss = 1.29253
I0831 13:54:20.577870 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.05924 (* 1 = 1.05924 loss)
I0831 13:54:20.577900 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.54478 (* 0.1 = 0.254478 loss)
I0831 13:54:20.577925 12026 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0831 13:55:01.640166 12026 solver.cpp:228] Iteration 5400, loss = 1.30473
I0831 13:55:01.640440 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.22466 (* 1 = 1.22466 loss)
I0831 13:55:01.640468 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.59608 (* 0.1 = 0.259608 loss)
I0831 13:55:01.640491 12026 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0831 13:55:45.763260 12026 solver.cpp:228] Iteration 5500, loss = 1.27568
I0831 13:55:45.763447 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.886094 (* 1 = 0.886094 loss)
I0831 13:55:45.763473 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21155 (* 0.1 = 0.221155 loss)
I0831 13:55:45.763495 12026 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0831 13:56:26.038125 12026 solver.cpp:228] Iteration 5600, loss = 1.25753
I0831 13:56:26.038296 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.933455 (* 1 = 0.933455 loss)
I0831 13:56:26.038322 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.4591 (* 0.1 = 0.24591 loss)
I0831 13:56:26.038342 12026 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0831 13:57:06.321375 12026 solver.cpp:228] Iteration 5700, loss = 1.28465
I0831 13:57:06.321552 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.788566 (* 1 = 0.788566 loss)
I0831 13:57:06.321578 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.29647 (* 0.1 = 0.229647 loss)
I0831 13:57:06.321599 12026 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0831 13:57:51.235481 12026 solver.cpp:228] Iteration 5800, loss = 1.24044
I0831 13:57:51.235671 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.28632 (* 1 = 1.28632 loss)
I0831 13:57:51.235698 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.43883 (* 0.1 = 0.243883 loss)
I0831 13:57:51.235719 12026 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0831 13:58:36.144145 12026 solver.cpp:228] Iteration 5900, loss = 1.24989
I0831 13:58:36.144268 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.05051 (* 1 = 1.05051 loss)
I0831 13:58:36.144294 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.55209 (* 0.1 = 0.255209 loss)
I0831 13:58:36.144316 12026 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0831 13:59:20.661178 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_6000.caffemodel
I0831 13:59:21.395349 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_6000.solverstate
I0831 13:59:21.589498 12026 solver.cpp:337] Iteration 6000, Testing net (#0)
I0831 13:59:29.083861 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.646571
I0831 13:59:29.083931 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.971428
I0831 13:59:29.083963 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.97505 (* 1 = 0.97505 loss)
I0831 13:59:29.083988 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.59847 (* 0.1 = 0.459847 loss)
I0831 13:59:29.200028 12026 solver.cpp:228] Iteration 6000, loss = 1.26937
I0831 13:59:29.200103 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.32791 (* 1 = 1.32791 loss)
I0831 13:59:29.200129 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.46721 (* 0.1 = 0.246721 loss)
I0831 13:59:29.200153 12026 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0831 14:00:09.489433 12026 solver.cpp:228] Iteration 6100, loss = 1.26322
I0831 14:00:09.489634 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.985712 (* 1 = 0.985712 loss)
I0831 14:00:09.489660 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.34059 (* 0.1 = 0.234059 loss)
I0831 14:00:09.489681 12026 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0831 14:00:49.781812 12026 solver.cpp:228] Iteration 6200, loss = 1.26069
I0831 14:00:49.782070 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.06861 (* 1 = 1.06861 loss)
I0831 14:00:49.782099 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.84225 (* 0.1 = 0.284225 loss)
I0831 14:00:49.782119 12026 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0831 14:01:30.069947 12026 solver.cpp:228] Iteration 6300, loss = 1.25056
I0831 14:01:30.070117 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.00064 (* 1 = 1.00064 loss)
I0831 14:01:30.070144 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.4657 (* 0.1 = 0.24657 loss)
I0831 14:01:30.070165 12026 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0831 14:02:10.357764 12026 solver.cpp:228] Iteration 6400, loss = 1.24537
I0831 14:02:10.357944 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.863342 (* 1 = 0.863342 loss)
I0831 14:02:10.357970 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.29027 (* 0.1 = 0.229027 loss)
I0831 14:02:10.358011 12026 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0831 14:02:50.646489 12026 solver.cpp:228] Iteration 6500, loss = 1.21516
I0831 14:02:50.646679 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.07303 (* 1 = 1.07303 loss)
I0831 14:02:50.646706 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.66799 (* 0.1 = 0.266799 loss)
I0831 14:02:50.646726 12026 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0831 14:03:30.930394 12026 solver.cpp:228] Iteration 6600, loss = 1.22025
I0831 14:03:30.930618 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.08605 (* 1 = 1.08605 loss)
I0831 14:03:30.930647 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.20305 (* 0.1 = 0.220305 loss)
I0831 14:03:30.930666 12026 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0831 14:04:11.218240 12026 solver.cpp:228] Iteration 6700, loss = 1.26106
I0831 14:04:11.218420 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.995309 (* 1 = 0.995309 loss)
I0831 14:04:11.218448 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3012 (* 0.1 = 0.23012 loss)
I0831 14:04:11.218474 12026 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0831 14:04:51.502069 12026 solver.cpp:228] Iteration 6800, loss = 1.26694
I0831 14:04:51.502260 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.12657 (* 1 = 1.12657 loss)
I0831 14:04:51.502288 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.46018 (* 0.1 = 0.246018 loss)
I0831 14:04:51.502310 12026 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0831 14:05:31.783928 12026 solver.cpp:228] Iteration 6900, loss = 1.21747
I0831 14:05:31.784104 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.801285 (* 1 = 0.801285 loss)
I0831 14:05:31.784131 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28947 (* 0.1 = 0.228947 loss)
I0831 14:05:31.784154 12026 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0831 14:06:11.673485 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_7000.caffemodel
I0831 14:06:12.399441 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_7000.solverstate
I0831 14:06:12.586964 12026 solver.cpp:337] Iteration 7000, Testing net (#0)
I0831 14:06:20.070632 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.665714
I0831 14:06:20.070714 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.971143
I0831 14:06:20.070739 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.921676 (* 1 = 0.921676 loss)
I0831 14:06:20.070760 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.18319 (* 0.1 = 0.418319 loss)
I0831 14:06:20.187124 12026 solver.cpp:228] Iteration 7000, loss = 1.20721
I0831 14:06:20.187203 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.917492 (* 1 = 0.917492 loss)
I0831 14:06:20.187225 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3895 (* 0.1 = 0.23895 loss)
I0831 14:06:20.187250 12026 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0831 14:07:00.472609 12026 solver.cpp:228] Iteration 7100, loss = 1.21684
I0831 14:07:00.472851 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.76936 (* 1 = 0.76936 loss)
I0831 14:07:00.472877 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.4438 (* 0.1 = 0.24438 loss)
I0831 14:07:00.472900 12026 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0831 14:07:40.760242 12026 solver.cpp:228] Iteration 7200, loss = 1.20722
I0831 14:07:40.760426 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.18275 (* 1 = 1.18275 loss)
I0831 14:07:40.760452 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.97959 (* 0.1 = 0.297959 loss)
I0831 14:07:40.760474 12026 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0831 14:08:21.049671 12026 solver.cpp:228] Iteration 7300, loss = 1.20467
I0831 14:08:21.049870 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.06605 (* 1 = 1.06605 loss)
I0831 14:08:21.049896 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.68815 (* 0.1 = 0.268815 loss)
I0831 14:08:21.049919 12026 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0831 14:09:01.339908 12026 solver.cpp:228] Iteration 7400, loss = 1.23098
I0831 14:09:01.340088 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.895796 (* 1 = 0.895796 loss)
I0831 14:09:01.340113 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30244 (* 0.1 = 0.230244 loss)
I0831 14:09:01.340135 12026 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0831 14:09:41.633942 12026 solver.cpp:228] Iteration 7500, loss = 1.23068
I0831 14:09:41.634107 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.970528 (* 1 = 0.970528 loss)
I0831 14:09:41.634135 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.27807 (* 0.1 = 0.227807 loss)
I0831 14:09:41.634156 12026 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0831 14:10:21.923101 12026 solver.cpp:228] Iteration 7600, loss = 1.17843
I0831 14:10:21.923355 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.633295 (* 1 = 0.633295 loss)
I0831 14:10:21.923384 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11674 (* 0.1 = 0.211674 loss)
I0831 14:10:21.923400 12026 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0831 14:11:02.209097 12026 solver.cpp:228] Iteration 7700, loss = 1.19448
I0831 14:11:02.209287 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.81072 (* 1 = 0.81072 loss)
I0831 14:11:02.209314 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.16396 (* 0.1 = 0.216396 loss)
I0831 14:11:02.209336 12026 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0831 14:11:42.498271 12026 solver.cpp:228] Iteration 7800, loss = 1.1747
I0831 14:11:42.498469 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.813732 (* 1 = 0.813732 loss)
I0831 14:11:42.498497 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.26861 (* 0.1 = 0.226861 loss)
I0831 14:11:42.498518 12026 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0831 14:12:22.788103 12026 solver.cpp:228] Iteration 7900, loss = 1.18452
I0831 14:12:22.788292 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.900546 (* 1 = 0.900546 loss)
I0831 14:12:22.788318 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3839 (* 0.1 = 0.23839 loss)
I0831 14:12:22.788339 12026 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0831 14:13:02.670279 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_8000.caffemodel
I0831 14:13:03.403712 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_8000.solverstate
I0831 14:13:03.598433 12026 solver.cpp:337] Iteration 8000, Testing net (#0)
I0831 14:13:11.087946 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.666571
I0831 14:13:11.088019 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.976857
I0831 14:13:11.088052 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.916005 (* 1 = 0.916005 loss)
I0831 14:13:11.088074 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.3172 (* 0.1 = 0.43172 loss)
I0831 14:13:11.204668 12026 solver.cpp:228] Iteration 8000, loss = 1.20255
I0831 14:13:11.204741 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.833417 (* 1 = 0.833417 loss)
I0831 14:13:11.204764 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.34585 (* 0.1 = 0.234585 loss)
I0831 14:13:11.204789 12026 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0831 14:13:51.488215 12026 solver.cpp:228] Iteration 8100, loss = 1.21388
I0831 14:13:51.488464 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.821337 (* 1 = 0.821337 loss)
I0831 14:13:51.488502 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.60601 (* 0.1 = 0.260601 loss)
I0831 14:13:51.488523 12026 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0831 14:14:31.772446 12026 solver.cpp:228] Iteration 8200, loss = 1.1677
I0831 14:14:31.772595 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.820868 (* 1 = 0.820868 loss)
I0831 14:14:31.772621 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.23173 (* 0.1 = 0.223173 loss)
I0831 14:14:31.772644 12026 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0831 14:15:12.055274 12026 solver.cpp:228] Iteration 8300, loss = 1.17107
I0831 14:15:12.055459 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.782389 (* 1 = 0.782389 loss)
I0831 14:15:12.055485 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36379 (* 0.1 = 0.236379 loss)
I0831 14:15:12.055505 12026 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0831 14:15:52.341850 12026 solver.cpp:228] Iteration 8400, loss = 1.19392
I0831 14:15:52.342020 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.22921 (* 1 = 1.22921 loss)
I0831 14:15:52.342046 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.4346 (* 0.1 = 0.24346 loss)
I0831 14:15:52.342072 12026 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0831 14:16:32.631870 12026 solver.cpp:228] Iteration 8500, loss = 1.16488
I0831 14:16:32.632045 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.85184 (* 1 = 0.85184 loss)
I0831 14:16:32.632071 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.26671 (* 0.1 = 0.226671 loss)
I0831 14:16:32.632091 12026 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0831 14:17:12.920979 12026 solver.cpp:228] Iteration 8600, loss = 1.14646
I0831 14:17:12.921165 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.14633 (* 1 = 1.14633 loss)
I0831 14:17:12.921191 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3515 (* 0.1 = 0.23515 loss)
I0831 14:17:12.921219 12026 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0831 14:17:53.211112 12026 solver.cpp:228] Iteration 8700, loss = 1.18609
I0831 14:17:53.211292 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.969282 (* 1 = 0.969282 loss)
I0831 14:17:53.211318 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36743 (* 0.1 = 0.236743 loss)
I0831 14:17:53.211336 12026 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0831 14:18:33.504215 12026 solver.cpp:228] Iteration 8800, loss = 1.1872
I0831 14:18:33.504451 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.10784 (* 1 = 1.10784 loss)
I0831 14:18:33.504478 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.61696 (* 0.1 = 0.261696 loss)
I0831 14:18:33.504511 12026 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0831 14:19:13.789940 12026 solver.cpp:228] Iteration 8900, loss = 1.16758
I0831 14:19:13.790115 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.965962 (* 1 = 0.965962 loss)
I0831 14:19:13.790140 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.77849 (* 0.1 = 0.277849 loss)
I0831 14:19:13.790161 12026 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0831 14:19:53.679165 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_9000.caffemodel
I0831 14:19:54.413949 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_9000.solverstate
I0831 14:19:54.612607 12026 solver.cpp:337] Iteration 9000, Testing net (#0)
I0831 14:20:02.103453 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.667143
I0831 14:20:02.103543 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.975714
I0831 14:20:02.103570 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.918543 (* 1 = 0.918543 loss)
I0831 14:20:02.103592 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.23689 (* 0.1 = 0.423689 loss)
I0831 14:20:02.219967 12026 solver.cpp:228] Iteration 9000, loss = 1.16022
I0831 14:20:02.220036 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.791981 (* 1 = 0.791981 loss)
I0831 14:20:02.220058 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.50184 (* 0.1 = 0.250184 loss)
I0831 14:20:02.220082 12026 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0831 14:20:42.518878 12026 solver.cpp:228] Iteration 9100, loss = 1.17976
I0831 14:20:42.519070 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.839761 (* 1 = 0.839761 loss)
I0831 14:20:42.519098 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30753 (* 0.1 = 0.230753 loss)
I0831 14:20:42.519119 12026 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0831 14:21:22.811390 12026 solver.cpp:228] Iteration 9200, loss = 1.1447
I0831 14:21:22.811573 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.24629 (* 1 = 1.24629 loss)
I0831 14:21:22.811600 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.61448 (* 0.1 = 0.261448 loss)
I0831 14:21:22.811620 12026 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0831 14:22:03.118978 12026 solver.cpp:228] Iteration 9300, loss = 1.14748
I0831 14:22:03.119197 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.10501 (* 1 = 1.10501 loss)
I0831 14:22:03.119225 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.35365 (* 0.1 = 0.235365 loss)
I0831 14:22:03.119246 12026 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0831 14:22:43.416574 12026 solver.cpp:228] Iteration 9400, loss = 1.181
I0831 14:22:43.416823 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.700425 (* 1 = 0.700425 loss)
I0831 14:22:43.416851 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.29044 (* 0.1 = 0.229044 loss)
I0831 14:22:43.416872 12026 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0831 14:23:23.726058 12026 solver.cpp:228] Iteration 9500, loss = 1.16596
I0831 14:23:23.726251 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.808897 (* 1 = 0.808897 loss)
I0831 14:23:23.726279 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.26137 (* 0.1 = 0.226137 loss)
I0831 14:23:23.726300 12026 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0831 14:24:04.016527 12026 solver.cpp:228] Iteration 9600, loss = 1.13824
I0831 14:24:04.016741 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.640754 (* 1 = 0.640754 loss)
I0831 14:24:04.016765 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98172 (* 0.1 = 0.198172 loss)
I0831 14:24:04.016786 12026 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0831 14:24:44.309710 12026 solver.cpp:228] Iteration 9700, loss = 1.14529
I0831 14:24:44.309880 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.05224 (* 1 = 1.05224 loss)
I0831 14:24:44.309904 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30337 (* 0.1 = 0.230337 loss)
I0831 14:24:44.309929 12026 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0831 14:25:24.608006 12026 solver.cpp:228] Iteration 9800, loss = 1.14764
I0831 14:25:24.608181 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.979245 (* 1 = 0.979245 loss)
I0831 14:25:24.608208 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.76438 (* 0.1 = 0.276438 loss)
I0831 14:25:24.608229 12026 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0831 14:26:04.908077 12026 solver.cpp:228] Iteration 9900, loss = 1.12625
I0831 14:26:04.908329 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.16029 (* 1 = 1.16029 loss)
I0831 14:26:04.908356 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.89307 (* 0.1 = 0.289307 loss)
I0831 14:26:04.908380 12026 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0831 14:26:44.800102 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_10000.caffemodel
I0831 14:26:45.534349 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_10000.solverstate
I0831 14:26:45.734302 12026 solver.cpp:337] Iteration 10000, Testing net (#0)
I0831 14:26:53.246193 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.702
I0831 14:26:53.246273 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.976571
I0831 14:26:53.246299 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.849219 (* 1 = 0.849219 loss)
I0831 14:26:53.246320 12026 solver.cpp:404]     Test net output #3: loss_hash = 4.1123 (* 0.1 = 0.41123 loss)
I0831 14:26:53.362627 12026 solver.cpp:228] Iteration 10000, loss = 1.14214
I0831 14:26:53.362697 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.814915 (* 1 = 0.814915 loss)
I0831 14:26:53.362728 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.18867 (* 0.1 = 0.218867 loss)
I0831 14:26:53.362753 12026 sgd_solver.cpp:106] Iteration 10000, lr = 0.0001
I0831 14:27:33.651731 12026 solver.cpp:228] Iteration 10100, loss = 1.14789
I0831 14:27:33.651911 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.23124 (* 1 = 1.23124 loss)
I0831 14:27:33.651937 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.93455 (* 0.1 = 0.293455 loss)
I0831 14:27:33.651957 12026 sgd_solver.cpp:106] Iteration 10100, lr = 0.0001
I0831 14:28:13.938071 12026 solver.cpp:228] Iteration 10200, loss = 1.15874
I0831 14:28:13.938258 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.841232 (* 1 = 0.841232 loss)
I0831 14:28:13.938287 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.23922 (* 0.1 = 0.223922 loss)
I0831 14:28:13.938307 12026 sgd_solver.cpp:106] Iteration 10200, lr = 0.0001
I0831 14:28:54.229560 12026 solver.cpp:228] Iteration 10300, loss = 1.10206
I0831 14:28:54.229733 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.09617 (* 1 = 1.09617 loss)
I0831 14:28:54.229760 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.89914 (* 0.1 = 0.289914 loss)
I0831 14:28:54.229780 12026 sgd_solver.cpp:106] Iteration 10300, lr = 0.0001
I0831 14:29:34.539330 12026 solver.cpp:228] Iteration 10400, loss = 1.13923
I0831 14:29:34.539530 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.18442 (* 1 = 1.18442 loss)
I0831 14:29:34.539556 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.74132 (* 0.1 = 0.274132 loss)
I0831 14:29:34.539577 12026 sgd_solver.cpp:106] Iteration 10400, lr = 0.0001
I0831 14:30:14.827334 12026 solver.cpp:228] Iteration 10500, loss = 1.10095
I0831 14:30:14.827580 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.900838 (* 1 = 0.900838 loss)
I0831 14:30:14.827606 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.70606 (* 0.1 = 0.270606 loss)
I0831 14:30:14.827632 12026 sgd_solver.cpp:106] Iteration 10500, lr = 0.0001
I0831 14:30:55.122745 12026 solver.cpp:228] Iteration 10600, loss = 1.12677
I0831 14:30:55.122928 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.769166 (* 1 = 0.769166 loss)
I0831 14:30:55.122956 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.34807 (* 0.1 = 0.234807 loss)
I0831 14:30:55.122975 12026 sgd_solver.cpp:106] Iteration 10600, lr = 0.0001
I0831 14:31:35.411001 12026 solver.cpp:228] Iteration 10700, loss = 1.12542
I0831 14:31:35.411133 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.978465 (* 1 = 0.978465 loss)
I0831 14:31:35.411157 12026 solver.cpp:244]     Train net output #1: loss_hash = 3.30419 (* 0.1 = 0.330419 loss)
I0831 14:31:35.411178 12026 sgd_solver.cpp:106] Iteration 10700, lr = 0.0001
I0831 14:32:15.701180 12026 solver.cpp:228] Iteration 10800, loss = 1.12788
I0831 14:32:15.701426 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.599455 (* 1 = 0.599455 loss)
I0831 14:32:15.701457 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.32773 (* 0.1 = 0.232773 loss)
I0831 14:32:15.701477 12026 sgd_solver.cpp:106] Iteration 10800, lr = 0.0001
I0831 14:32:55.999013 12026 solver.cpp:228] Iteration 10900, loss = 1.13457
I0831 14:32:55.999193 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.741103 (* 1 = 0.741103 loss)
I0831 14:32:55.999219 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28204 (* 0.1 = 0.228204 loss)
I0831 14:32:55.999239 12026 sgd_solver.cpp:106] Iteration 10900, lr = 0.0001
I0831 14:33:35.891669 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_11000.caffemodel
I0831 14:33:36.623502 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_11000.solverstate
I0831 14:33:36.823650 12026 solver.cpp:337] Iteration 11000, Testing net (#0)
I0831 14:33:44.309619 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.696286
I0831 14:33:44.309697 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.977143
I0831 14:33:44.309731 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.861979 (* 1 = 0.861979 loss)
I0831 14:33:44.309757 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.69072 (* 0.1 = 0.369072 loss)
I0831 14:33:44.426147 12026 solver.cpp:228] Iteration 11000, loss = 1.09984
I0831 14:33:44.426225 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.818825 (* 1 = 0.818825 loss)
I0831 14:33:44.426249 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42054 (* 0.1 = 0.242054 loss)
I0831 14:33:44.426271 12026 sgd_solver.cpp:106] Iteration 11000, lr = 0.0001
I0831 14:34:24.733815 12026 solver.cpp:228] Iteration 11100, loss = 1.1137
I0831 14:34:24.734033 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.965135 (* 1 = 0.965135 loss)
I0831 14:34:24.734061 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.32176 (* 0.1 = 0.232176 loss)
I0831 14:34:24.734082 12026 sgd_solver.cpp:106] Iteration 11100, lr = 0.0001
I0831 14:35:05.033113 12026 solver.cpp:228] Iteration 11200, loss = 1.05993
I0831 14:35:05.033380 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.702049 (* 1 = 0.702049 loss)
I0831 14:35:05.033407 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.82823 (* 0.1 = 0.182823 loss)
I0831 14:35:05.033428 12026 sgd_solver.cpp:106] Iteration 11200, lr = 0.0001
I0831 14:35:45.330849 12026 solver.cpp:228] Iteration 11300, loss = 1.08686
I0831 14:35:45.331051 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.784046 (* 1 = 0.784046 loss)
I0831 14:35:45.331090 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30616 (* 0.1 = 0.230616 loss)
I0831 14:35:45.331122 12026 sgd_solver.cpp:106] Iteration 11300, lr = 0.0001
I0831 14:36:25.647192 12026 solver.cpp:228] Iteration 11400, loss = 1.11387
I0831 14:36:25.647354 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.852218 (* 1 = 0.852218 loss)
I0831 14:36:25.647379 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.20536 (* 0.1 = 0.220536 loss)
I0831 14:36:25.647404 12026 sgd_solver.cpp:106] Iteration 11400, lr = 0.0001
I0831 14:37:05.942920 12026 solver.cpp:228] Iteration 11500, loss = 1.13126
I0831 14:37:05.943183 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.995783 (* 1 = 0.995783 loss)
I0831 14:37:05.943213 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.47719 (* 0.1 = 0.247719 loss)
I0831 14:37:05.943228 12026 sgd_solver.cpp:106] Iteration 11500, lr = 0.0001
I0831 14:37:46.248980 12026 solver.cpp:228] Iteration 11600, loss = 1.09691
I0831 14:37:46.249238 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.742807 (* 1 = 0.742807 loss)
I0831 14:37:46.249266 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.97299 (* 0.1 = 0.197299 loss)
I0831 14:37:46.249289 12026 sgd_solver.cpp:106] Iteration 11600, lr = 0.0001
I0831 14:38:26.545186 12026 solver.cpp:228] Iteration 11700, loss = 1.09778
I0831 14:38:26.545405 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.632497 (* 1 = 0.632497 loss)
I0831 14:38:26.545433 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.1336 (* 0.1 = 0.21336 loss)
I0831 14:38:26.545455 12026 sgd_solver.cpp:106] Iteration 11700, lr = 0.0001
I0831 14:39:06.839287 12026 solver.cpp:228] Iteration 11800, loss = 1.10111
I0831 14:39:06.839486 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.805897 (* 1 = 0.805897 loss)
I0831 14:39:06.839514 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36875 (* 0.1 = 0.236875 loss)
I0831 14:39:06.839535 12026 sgd_solver.cpp:106] Iteration 11800, lr = 0.0001
I0831 14:39:47.129158 12026 solver.cpp:228] Iteration 11900, loss = 1.07587
I0831 14:39:47.129339 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.843339 (* 1 = 0.843339 loss)
I0831 14:39:47.129365 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.16869 (* 0.1 = 0.216869 loss)
I0831 14:39:47.129386 12026 sgd_solver.cpp:106] Iteration 11900, lr = 0.0001
I0831 14:40:27.023290 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_12000.caffemodel
I0831 14:40:27.753815 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_12000.solverstate
I0831 14:40:27.948773 12026 solver.cpp:337] Iteration 12000, Testing net (#0)
I0831 14:40:35.421716 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.709714
I0831 14:40:35.421790 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.979143
I0831 14:40:35.421825 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.830506 (* 1 = 0.830506 loss)
I0831 14:40:35.421846 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.62631 (* 0.1 = 0.362631 loss)
I0831 14:40:35.538520 12026 solver.cpp:228] Iteration 12000, loss = 1.0776
I0831 14:40:35.538599 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.958238 (* 1 = 0.958238 loss)
I0831 14:40:35.538622 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.22222 (* 0.1 = 0.222222 loss)
I0831 14:40:35.538660 12026 sgd_solver.cpp:106] Iteration 12000, lr = 0.0001
I0831 14:41:15.834617 12026 solver.cpp:228] Iteration 12100, loss = 1.12
I0831 14:41:15.834841 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.860671 (* 1 = 0.860671 loss)
I0831 14:41:15.834867 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28095 (* 0.1 = 0.228095 loss)
I0831 14:41:15.834887 12026 sgd_solver.cpp:106] Iteration 12100, lr = 0.0001
I0831 14:41:56.137058 12026 solver.cpp:228] Iteration 12200, loss = 1.11038
I0831 14:41:56.137186 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.877553 (* 1 = 0.877553 loss)
I0831 14:41:56.137212 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.78975 (* 0.1 = 0.278975 loss)
I0831 14:41:56.137235 12026 sgd_solver.cpp:106] Iteration 12200, lr = 0.0001
I0831 14:42:36.435546 12026 solver.cpp:228] Iteration 12300, loss = 1.06373
I0831 14:42:36.435731 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.796642 (* 1 = 0.796642 loss)
I0831 14:42:36.435757 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.8309 (* 0.1 = 0.28309 loss)
I0831 14:42:36.435782 12026 sgd_solver.cpp:106] Iteration 12300, lr = 0.0001
I0831 14:43:16.737211 12026 solver.cpp:228] Iteration 12400, loss = 1.09222
I0831 14:43:16.737390 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.97514 (* 1 = 0.97514 loss)
I0831 14:43:16.737416 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.58738 (* 0.1 = 0.258738 loss)
I0831 14:43:16.737437 12026 sgd_solver.cpp:106] Iteration 12400, lr = 0.0001
I0831 14:43:57.038043 12026 solver.cpp:228] Iteration 12500, loss = 1.07458
I0831 14:43:57.038280 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.989576 (* 1 = 0.989576 loss)
I0831 14:43:57.038306 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.52545 (* 0.1 = 0.252545 loss)
I0831 14:43:57.038331 12026 sgd_solver.cpp:106] Iteration 12500, lr = 0.0001
I0831 14:44:37.327149 12026 solver.cpp:228] Iteration 12600, loss = 1.07573
I0831 14:44:37.327365 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.722335 (* 1 = 0.722335 loss)
I0831 14:44:37.327391 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00218 (* 0.1 = 0.200218 loss)
I0831 14:44:37.327412 12026 sgd_solver.cpp:106] Iteration 12600, lr = 0.0001
I0831 14:45:17.619294 12026 solver.cpp:228] Iteration 12700, loss = 1.06859
I0831 14:45:17.619474 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.761512 (* 1 = 0.761512 loss)
I0831 14:45:17.619500 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21842 (* 0.1 = 0.221842 loss)
I0831 14:45:17.619524 12026 sgd_solver.cpp:106] Iteration 12700, lr = 0.0001
I0831 14:45:57.916038 12026 solver.cpp:228] Iteration 12800, loss = 1.11189
I0831 14:45:57.916221 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.891033 (* 1 = 0.891033 loss)
I0831 14:45:57.916257 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.97582 (* 0.1 = 0.197582 loss)
I0831 14:45:57.916281 12026 sgd_solver.cpp:106] Iteration 12800, lr = 0.0001
I0831 14:46:38.210100 12026 solver.cpp:228] Iteration 12900, loss = 1.06112
I0831 14:46:38.210273 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.848073 (* 1 = 0.848073 loss)
I0831 14:46:38.210299 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.57546 (* 0.1 = 0.257546 loss)
I0831 14:46:38.210320 12026 sgd_solver.cpp:106] Iteration 12900, lr = 0.0001
I0831 14:47:18.102833 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_13000.caffemodel
I0831 14:47:18.838692 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_13000.solverstate
I0831 14:47:19.033424 12026 solver.cpp:337] Iteration 13000, Testing net (#0)
I0831 14:47:26.523934 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.692572
I0831 14:47:26.524009 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.981428
I0831 14:47:26.524044 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.873565 (* 1 = 0.873565 loss)
I0831 14:47:26.524067 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.99166 (* 0.1 = 0.399166 loss)
I0831 14:47:26.640653 12026 solver.cpp:228] Iteration 13000, loss = 1.05646
I0831 14:47:26.640733 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.652343 (* 1 = 0.652343 loss)
I0831 14:47:26.640758 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02772 (* 0.1 = 0.202772 loss)
I0831 14:47:26.640784 12026 sgd_solver.cpp:106] Iteration 13000, lr = 0.0001
I0831 14:48:06.951669 12026 solver.cpp:228] Iteration 13100, loss = 1.07072
I0831 14:48:06.951853 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.04062 (* 1 = 1.04062 loss)
I0831 14:48:06.951879 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.61917 (* 0.1 = 0.261917 loss)
I0831 14:48:06.951915 12026 sgd_solver.cpp:106] Iteration 13100, lr = 0.0001
I0831 14:48:47.247867 12026 solver.cpp:228] Iteration 13200, loss = 1.03781
I0831 14:48:47.248039 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.799523 (* 1 = 0.799523 loss)
I0831 14:48:47.248064 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.27859 (* 0.1 = 0.227859 loss)
I0831 14:48:47.248091 12026 sgd_solver.cpp:106] Iteration 13200, lr = 0.0001
I0831 14:49:27.542021 12026 solver.cpp:228] Iteration 13300, loss = 1.04097
I0831 14:49:27.542196 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.00432 (* 1 = 1.00432 loss)
I0831 14:49:27.542222 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.64162 (* 0.1 = 0.264162 loss)
I0831 14:49:27.542253 12026 sgd_solver.cpp:106] Iteration 13300, lr = 0.0001
I0831 14:50:07.839996 12026 solver.cpp:228] Iteration 13400, loss = 1.06678
I0831 14:50:07.840270 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.716835 (* 1 = 0.716835 loss)
I0831 14:50:07.840298 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.13102 (* 0.1 = 0.213102 loss)
I0831 14:50:07.840337 12026 sgd_solver.cpp:106] Iteration 13400, lr = 0.0001
I0831 14:50:48.158330 12026 solver.cpp:228] Iteration 13500, loss = 1.09353
I0831 14:50:48.158555 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.991509 (* 1 = 0.991509 loss)
I0831 14:50:48.158584 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.27931 (* 0.1 = 0.227931 loss)
I0831 14:50:48.158599 12026 sgd_solver.cpp:106] Iteration 13500, lr = 0.0001
I0831 14:51:28.451359 12026 solver.cpp:228] Iteration 13600, loss = 1.0563
I0831 14:51:28.451501 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.720228 (* 1 = 0.720228 loss)
I0831 14:51:28.451527 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.09374 (* 0.1 = 0.209374 loss)
I0831 14:51:28.451547 12026 sgd_solver.cpp:106] Iteration 13600, lr = 0.0001
I0831 14:52:08.744943 12026 solver.cpp:228] Iteration 13700, loss = 1.05689
I0831 14:52:08.745122 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.875912 (* 1 = 0.875912 loss)
I0831 14:52:08.745148 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.64429 (* 0.1 = 0.264429 loss)
I0831 14:52:08.745169 12026 sgd_solver.cpp:106] Iteration 13700, lr = 0.0001
I0831 14:52:49.045966 12026 solver.cpp:228] Iteration 13800, loss = 1.04132
I0831 14:52:49.046152 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.580391 (* 1 = 0.580391 loss)
I0831 14:52:49.046178 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.78274 (* 0.1 = 0.178274 loss)
I0831 14:52:49.046202 12026 sgd_solver.cpp:106] Iteration 13800, lr = 0.0001
I0831 14:53:29.344759 12026 solver.cpp:228] Iteration 13900, loss = 1.01102
I0831 14:53:29.344939 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.654834 (* 1 = 0.654834 loss)
I0831 14:53:29.344965 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.81901 (* 0.1 = 0.181901 loss)
I0831 14:53:29.344997 12026 sgd_solver.cpp:106] Iteration 13900, lr = 0.0001
I0831 14:54:09.241645 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_14000.caffemodel
I0831 14:54:09.973053 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_14000.solverstate
I0831 14:54:10.174844 12026 solver.cpp:337] Iteration 14000, Testing net (#0)
I0831 14:54:17.661645 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.706286
I0831 14:54:17.661738 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.982571
I0831 14:54:17.661767 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.81371 (* 1 = 0.81371 loss)
I0831 14:54:17.661788 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.60629 (* 0.1 = 0.360629 loss)
I0831 14:54:17.778553 12026 solver.cpp:228] Iteration 14000, loss = 1.04669
I0831 14:54:17.778607 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.930191 (* 1 = 0.930191 loss)
I0831 14:54:17.778631 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11402 (* 0.1 = 0.211402 loss)
I0831 14:54:17.778656 12026 sgd_solver.cpp:106] Iteration 14000, lr = 0.0001
I0831 14:54:58.078140 12026 solver.cpp:228] Iteration 14100, loss = 1.06725
I0831 14:54:58.078325 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.08942 (* 1 = 1.08942 loss)
I0831 14:54:58.078361 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.56846 (* 0.1 = 0.256846 loss)
I0831 14:54:58.078392 12026 sgd_solver.cpp:106] Iteration 14100, lr = 0.0001
I0831 14:55:38.369415 12026 solver.cpp:228] Iteration 14200, loss = 1.0666
I0831 14:55:38.369668 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.859319 (* 1 = 0.859319 loss)
I0831 14:55:38.369710 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.35383 (* 0.1 = 0.235383 loss)
I0831 14:55:38.369734 12026 sgd_solver.cpp:106] Iteration 14200, lr = 0.0001
I0831 14:56:18.663161 12026 solver.cpp:228] Iteration 14300, loss = 1.02567
I0831 14:56:18.663386 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.973499 (* 1 = 0.973499 loss)
I0831 14:56:18.663415 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.47275 (* 0.1 = 0.247275 loss)
I0831 14:56:18.663429 12026 sgd_solver.cpp:106] Iteration 14300, lr = 0.0001
I0831 14:56:58.959347 12026 solver.cpp:228] Iteration 14400, loss = 1.04101
I0831 14:56:58.959533 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.741264 (* 1 = 0.741264 loss)
I0831 14:56:58.959558 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05228 (* 0.1 = 0.205228 loss)
I0831 14:56:58.959580 12026 sgd_solver.cpp:106] Iteration 14400, lr = 0.0001
I0831 14:57:39.253862 12026 solver.cpp:228] Iteration 14500, loss = 1.03839
I0831 14:57:39.254110 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.835611 (* 1 = 0.835611 loss)
I0831 14:57:39.254142 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.46676 (* 0.1 = 0.246676 loss)
I0831 14:57:39.254165 12026 sgd_solver.cpp:106] Iteration 14500, lr = 0.0001
I0831 14:58:19.548976 12026 solver.cpp:228] Iteration 14600, loss = 1.01515
I0831 14:58:19.549163 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.717477 (* 1 = 0.717477 loss)
I0831 14:58:19.549190 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.91747 (* 0.1 = 0.191747 loss)
I0831 14:58:19.549216 12026 sgd_solver.cpp:106] Iteration 14600, lr = 0.0001
I0831 14:58:59.844507 12026 solver.cpp:228] Iteration 14700, loss = 1.04375
I0831 14:58:59.844691 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.787731 (* 1 = 0.787731 loss)
I0831 14:58:59.844717 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.59014 (* 0.1 = 0.259014 loss)
I0831 14:58:59.844743 12026 sgd_solver.cpp:106] Iteration 14700, lr = 0.0001
I0831 14:59:40.139354 12026 solver.cpp:228] Iteration 14800, loss = 1.05686
I0831 14:59:40.139482 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.962451 (* 1 = 0.962451 loss)
I0831 14:59:40.139508 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.29789 (* 0.1 = 0.229789 loss)
I0831 14:59:40.139528 12026 sgd_solver.cpp:106] Iteration 14800, lr = 0.0001
I0831 15:00:20.450297 12026 solver.cpp:228] Iteration 14900, loss = 1.06168
I0831 15:00:20.450500 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.976714 (* 1 = 0.976714 loss)
I0831 15:00:20.450527 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30137 (* 0.1 = 0.230137 loss)
I0831 15:00:20.450551 12026 sgd_solver.cpp:106] Iteration 14900, lr = 0.0001
I0831 15:01:00.340402 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_15000.caffemodel
I0831 15:01:01.072988 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_15000.solverstate
I0831 15:01:01.268717 12026 solver.cpp:337] Iteration 15000, Testing net (#0)
I0831 15:01:08.747536 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.726286
I0831 15:01:08.747608 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.979428
I0831 15:01:08.747642 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.796962 (* 1 = 0.796962 loss)
I0831 15:01:08.747668 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.76406 (* 0.1 = 0.376406 loss)
I0831 15:01:08.863858 12026 solver.cpp:228] Iteration 15000, loss = 1.01463
I0831 15:01:08.863937 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.848036 (* 1 = 0.848036 loss)
I0831 15:01:08.863960 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.57051 (* 0.1 = 0.257051 loss)
I0831 15:01:08.863983 12026 sgd_solver.cpp:106] Iteration 15000, lr = 0.0001
I0831 15:01:49.178306 12026 solver.cpp:228] Iteration 15100, loss = 1.04169
I0831 15:01:49.178627 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.715808 (* 1 = 0.715808 loss)
I0831 15:01:49.178655 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.96687 (* 0.1 = 0.196687 loss)
I0831 15:01:49.178675 12026 sgd_solver.cpp:106] Iteration 15100, lr = 0.0001
I0831 15:02:29.487895 12026 solver.cpp:228] Iteration 15200, loss = 0.979644
I0831 15:02:29.488075 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.807107 (* 1 = 0.807107 loss)
I0831 15:02:29.488101 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.33363 (* 0.1 = 0.233363 loss)
I0831 15:02:29.488123 12026 sgd_solver.cpp:106] Iteration 15200, lr = 0.0001
I0831 15:03:09.794550 12026 solver.cpp:228] Iteration 15300, loss = 1.02519
I0831 15:03:09.794772 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.559529 (* 1 = 0.559529 loss)
I0831 15:03:09.794801 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.49183 (* 0.1 = 0.249183 loss)
I0831 15:03:09.794818 12026 sgd_solver.cpp:106] Iteration 15300, lr = 0.0001
I0831 15:03:50.095417 12026 solver.cpp:228] Iteration 15400, loss = 1.02146
I0831 15:03:50.095597 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.90802 (* 1 = 0.90802 loss)
I0831 15:03:50.095623 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.60773 (* 0.1 = 0.260773 loss)
I0831 15:03:50.095643 12026 sgd_solver.cpp:106] Iteration 15400, lr = 0.0001
I0831 15:04:30.395304 12026 solver.cpp:228] Iteration 15500, loss = 1.04959
I0831 15:04:30.395481 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.721774 (* 1 = 0.721774 loss)
I0831 15:04:30.395509 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.44627 (* 0.1 = 0.244627 loss)
I0831 15:04:30.395530 12026 sgd_solver.cpp:106] Iteration 15500, lr = 0.0001
I0831 15:05:10.699429 12026 solver.cpp:228] Iteration 15600, loss = 1.03062
I0831 15:05:10.699616 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.509639 (* 1 = 0.509639 loss)
I0831 15:05:10.699643 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.78005 (* 0.1 = 0.178005 loss)
I0831 15:05:10.699662 12026 sgd_solver.cpp:106] Iteration 15600, lr = 0.0001
I0831 15:05:51.004674 12026 solver.cpp:228] Iteration 15700, loss = 1.01029
I0831 15:05:51.004801 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.927427 (* 1 = 0.927427 loss)
I0831 15:05:51.004827 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3656 (* 0.1 = 0.23656 loss)
I0831 15:05:51.004859 12026 sgd_solver.cpp:106] Iteration 15700, lr = 0.0001
I0831 15:06:31.311115 12026 solver.cpp:228] Iteration 15800, loss = 1.01327
I0831 15:06:31.311336 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.720625 (* 1 = 0.720625 loss)
I0831 15:06:31.311367 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.26212 (* 0.1 = 0.226212 loss)
I0831 15:06:31.311383 12026 sgd_solver.cpp:106] Iteration 15800, lr = 0.0001
I0831 15:07:11.620862 12026 solver.cpp:228] Iteration 15900, loss = 0.969773
I0831 15:07:11.621043 12026 solver.cpp:244]     Train net output #0: loss_classification = 1.0235 (* 1 = 1.0235 loss)
I0831 15:07:11.621071 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.48655 (* 0.1 = 0.248655 loss)
I0831 15:07:11.621096 12026 sgd_solver.cpp:106] Iteration 15900, lr = 0.0001
I0831 15:07:51.516788 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_16000.caffemodel
I0831 15:07:52.249825 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_16000.solverstate
I0831 15:07:52.444952 12026 solver.cpp:337] Iteration 16000, Testing net (#0)
I0831 15:07:59.919942 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.713714
I0831 15:07:59.920017 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.980286
I0831 15:07:59.920051 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.801562 (* 1 = 0.801562 loss)
I0831 15:07:59.920073 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.64342 (* 0.1 = 0.364342 loss)
I0831 15:08:00.037397 12026 solver.cpp:228] Iteration 16000, loss = 0.993845
I0831 15:08:00.037489 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.677807 (* 1 = 0.677807 loss)
I0831 15:08:00.037514 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.25401 (* 0.1 = 0.225401 loss)
I0831 15:08:00.037539 12026 sgd_solver.cpp:106] Iteration 16000, lr = 0.0001
I0831 15:08:40.331997 12026 solver.cpp:228] Iteration 16100, loss = 1.03551
I0831 15:08:40.332252 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.757981 (* 1 = 0.757981 loss)
I0831 15:08:40.332280 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02155 (* 0.1 = 0.202155 loss)
I0831 15:08:40.332301 12026 sgd_solver.cpp:106] Iteration 16100, lr = 0.0001
I0831 15:09:20.625521 12026 solver.cpp:228] Iteration 16200, loss = 1.02569
I0831 15:09:20.625704 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.809838 (* 1 = 0.809838 loss)
I0831 15:09:20.625730 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.35372 (* 0.1 = 0.235372 loss)
I0831 15:09:20.625751 12026 sgd_solver.cpp:106] Iteration 16200, lr = 0.0001
I0831 15:10:00.928494 12026 solver.cpp:228] Iteration 16300, loss = 0.980673
I0831 15:10:00.928694 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.59619 (* 1 = 0.59619 loss)
I0831 15:10:00.928722 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.2093 (* 0.1 = 0.22093 loss)
I0831 15:10:00.928745 12026 sgd_solver.cpp:106] Iteration 16300, lr = 0.0001
I0831 15:10:41.227391 12026 solver.cpp:228] Iteration 16400, loss = 0.995207
I0831 15:10:41.227591 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.676998 (* 1 = 0.676998 loss)
I0831 15:10:41.227617 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.40791 (* 0.1 = 0.240791 loss)
I0831 15:10:41.227638 12026 sgd_solver.cpp:106] Iteration 16400, lr = 0.0001
I0831 15:11:21.525823 12026 solver.cpp:228] Iteration 16500, loss = 0.985221
I0831 15:11:21.526005 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.858148 (* 1 = 0.858148 loss)
I0831 15:11:21.526031 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.46932 (* 0.1 = 0.246932 loss)
I0831 15:11:21.526052 12026 sgd_solver.cpp:106] Iteration 16500, lr = 0.0001
I0831 15:12:01.829836 12026 solver.cpp:228] Iteration 16600, loss = 0.977927
I0831 15:12:01.830008 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.629589 (* 1 = 0.629589 loss)
I0831 15:12:01.830032 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02548 (* 0.1 = 0.202548 loss)
I0831 15:12:01.830052 12026 sgd_solver.cpp:106] Iteration 16600, lr = 0.0001
I0831 15:12:42.131328 12026 solver.cpp:228] Iteration 16700, loss = 1.01675
I0831 15:12:42.131505 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.604077 (* 1 = 0.604077 loss)
I0831 15:12:42.131531 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.48053 (* 0.1 = 0.248053 loss)
I0831 15:12:42.131552 12026 sgd_solver.cpp:106] Iteration 16700, lr = 0.0001
I0831 15:13:22.437788 12026 solver.cpp:228] Iteration 16800, loss = 1.02859
I0831 15:13:22.437965 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.630169 (* 1 = 0.630169 loss)
I0831 15:13:22.437990 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.13594 (* 0.1 = 0.213594 loss)
I0831 15:13:22.438010 12026 sgd_solver.cpp:106] Iteration 16800, lr = 0.0001
I0831 15:14:02.737488 12026 solver.cpp:228] Iteration 16900, loss = 1.01538
I0831 15:14:02.737675 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.719411 (* 1 = 0.719411 loss)
I0831 15:14:02.737700 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.44784 (* 0.1 = 0.244784 loss)
I0831 15:14:02.737722 12026 sgd_solver.cpp:106] Iteration 16900, lr = 0.0001
I0831 15:14:42.637717 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_17000.caffemodel
I0831 15:14:43.368893 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_17000.solverstate
I0831 15:14:43.562582 12026 solver.cpp:337] Iteration 17000, Testing net (#0)
I0831 15:14:51.042011 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.729429
I0831 15:14:51.042085 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.983428
I0831 15:14:51.042120 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.777725 (* 1 = 0.777725 loss)
I0831 15:14:51.042142 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.32906 (* 0.1 = 0.332906 loss)
I0831 15:14:51.158273 12026 solver.cpp:228] Iteration 17000, loss = 0.969214
I0831 15:14:51.158350 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.944101 (* 1 = 0.944101 loss)
I0831 15:14:51.158378 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.50404 (* 0.1 = 0.250404 loss)
I0831 15:14:51.158409 12026 sgd_solver.cpp:106] Iteration 17000, lr = 0.0001
I0831 15:15:31.460950 12026 solver.cpp:228] Iteration 17100, loss = 0.990008
I0831 15:15:31.461161 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.689662 (* 1 = 0.689662 loss)
I0831 15:15:31.461189 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21478 (* 0.1 = 0.221478 loss)
I0831 15:15:31.461215 12026 sgd_solver.cpp:106] Iteration 17100, lr = 0.0001
I0831 15:16:11.784263 12026 solver.cpp:228] Iteration 17200, loss = 0.978589
I0831 15:16:11.784502 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.59228 (* 1 = 0.59228 loss)
I0831 15:16:11.784529 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.03927 (* 0.1 = 0.203927 loss)
I0831 15:16:11.784551 12026 sgd_solver.cpp:106] Iteration 17200, lr = 0.0001
I0831 15:16:52.093241 12026 solver.cpp:228] Iteration 17300, loss = 0.977646
I0831 15:16:52.093456 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.74611 (* 1 = 0.74611 loss)
I0831 15:16:52.093482 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92515 (* 0.1 = 0.192515 loss)
I0831 15:16:52.093506 12026 sgd_solver.cpp:106] Iteration 17300, lr = 0.0001
I0831 15:17:32.390290 12026 solver.cpp:228] Iteration 17400, loss = 0.973829
I0831 15:17:32.390509 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.655874 (* 1 = 0.655874 loss)
I0831 15:17:32.390535 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.41364 (* 0.1 = 0.241364 loss)
I0831 15:17:32.390558 12026 sgd_solver.cpp:106] Iteration 17400, lr = 0.0001
I0831 15:18:12.691120 12026 solver.cpp:228] Iteration 17500, loss = 1.01311
I0831 15:18:12.691315 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.855196 (* 1 = 0.855196 loss)
I0831 15:18:12.691342 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.45648 (* 0.1 = 0.245648 loss)
I0831 15:18:12.691366 12026 sgd_solver.cpp:106] Iteration 17500, lr = 0.0001
I0831 15:18:53.039728 12026 solver.cpp:228] Iteration 17600, loss = 0.977593
I0831 15:18:53.039925 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.788043 (* 1 = 0.788043 loss)
I0831 15:18:53.039952 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.38841 (* 0.1 = 0.238841 loss)
I0831 15:18:53.039978 12026 sgd_solver.cpp:106] Iteration 17600, lr = 0.0001
I0831 15:19:33.357787 12026 solver.cpp:228] Iteration 17700, loss = 0.979727
I0831 15:19:33.358057 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.781979 (* 1 = 0.781979 loss)
I0831 15:19:33.358083 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.18751 (* 0.1 = 0.218751 loss)
I0831 15:19:33.358105 12026 sgd_solver.cpp:106] Iteration 17700, lr = 0.0001
I0831 15:20:13.690244 12026 solver.cpp:228] Iteration 17800, loss = 0.995014
I0831 15:20:13.690513 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.614277 (* 1 = 0.614277 loss)
I0831 15:20:13.690541 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05438 (* 0.1 = 0.205438 loss)
I0831 15:20:13.690567 12026 sgd_solver.cpp:106] Iteration 17800, lr = 0.0001
I0831 15:20:54.013973 12026 solver.cpp:228] Iteration 17900, loss = 0.945648
I0831 15:20:54.014230 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.481041 (* 1 = 0.481041 loss)
I0831 15:20:54.014257 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.0965 (* 0.1 = 0.20965 loss)
I0831 15:20:54.014279 12026 sgd_solver.cpp:106] Iteration 17900, lr = 0.0001
I0831 15:21:33.925691 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_18000.caffemodel
I0831 15:21:34.659440 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_18000.solverstate
I0831 15:21:34.854002 12026 solver.cpp:337] Iteration 18000, Testing net (#0)
I0831 15:21:42.317569 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.743429
I0831 15:21:42.317651 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984857
I0831 15:21:42.317679 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.743501 (* 1 = 0.743501 loss)
I0831 15:21:42.317700 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.29025 (* 0.1 = 0.329025 loss)
I0831 15:21:42.434849 12026 solver.cpp:228] Iteration 18000, loss = 0.962234
I0831 15:21:42.434942 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.597275 (* 1 = 0.597275 loss)
I0831 15:21:42.434967 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02755 (* 0.1 = 0.202755 loss)
I0831 15:21:42.434991 12026 sgd_solver.cpp:106] Iteration 18000, lr = 0.0001
I0831 15:22:22.752605 12026 solver.cpp:228] Iteration 18100, loss = 0.984074
I0831 15:22:22.752786 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.686812 (* 1 = 0.686812 loss)
I0831 15:22:22.752813 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.16416 (* 0.1 = 0.216416 loss)
I0831 15:22:22.752835 12026 sgd_solver.cpp:106] Iteration 18100, lr = 0.0001
I0831 15:23:03.064786 12026 solver.cpp:228] Iteration 18200, loss = 1.00026
I0831 15:23:03.064996 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.776786 (* 1 = 0.776786 loss)
I0831 15:23:03.065021 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.51751 (* 0.1 = 0.251751 loss)
I0831 15:23:03.065040 12026 sgd_solver.cpp:106] Iteration 18200, lr = 0.0001
I0831 15:23:43.368785 12026 solver.cpp:228] Iteration 18300, loss = 0.960073
I0831 15:23:43.368970 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.888088 (* 1 = 0.888088 loss)
I0831 15:23:43.368996 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.58856 (* 0.1 = 0.258856 loss)
I0831 15:23:43.369019 12026 sgd_solver.cpp:106] Iteration 18300, lr = 0.0001
I0831 15:24:23.668238 12026 solver.cpp:228] Iteration 18400, loss = 0.976387
I0831 15:24:23.668417 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.721599 (* 1 = 0.721599 loss)
I0831 15:24:23.668443 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.52339 (* 0.1 = 0.252339 loss)
I0831 15:24:23.668465 12026 sgd_solver.cpp:106] Iteration 18400, lr = 0.0001
I0831 15:25:03.973619 12026 solver.cpp:228] Iteration 18500, loss = 0.948288
I0831 15:25:03.973846 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.758119 (* 1 = 0.758119 loss)
I0831 15:25:03.973873 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.41997 (* 0.1 = 0.241997 loss)
I0831 15:25:03.973896 12026 sgd_solver.cpp:106] Iteration 18500, lr = 0.0001
I0831 15:25:44.280385 12026 solver.cpp:228] Iteration 18600, loss = 0.93177
I0831 15:25:44.280575 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.846637 (* 1 = 0.846637 loss)
I0831 15:25:44.280601 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.60288 (* 0.1 = 0.260288 loss)
I0831 15:25:44.280622 12026 sgd_solver.cpp:106] Iteration 18600, lr = 0.0001
I0831 15:26:24.592077 12026 solver.cpp:228] Iteration 18700, loss = 0.949761
I0831 15:26:24.592332 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.462402 (* 1 = 0.462402 loss)
I0831 15:26:24.592360 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.65517 (* 0.1 = 0.165517 loss)
I0831 15:26:24.592380 12026 sgd_solver.cpp:106] Iteration 18700, lr = 0.0001
I0831 15:27:04.894095 12026 solver.cpp:228] Iteration 18800, loss = 0.974872
I0831 15:27:04.894279 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.99262 (* 1 = 0.99262 loss)
I0831 15:27:04.894305 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.55002 (* 0.1 = 0.255002 loss)
I0831 15:27:04.894326 12026 sgd_solver.cpp:106] Iteration 18800, lr = 0.0001
I0831 15:27:45.195637 12026 solver.cpp:228] Iteration 18900, loss = 0.993501
I0831 15:27:45.195858 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.620318 (* 1 = 0.620318 loss)
I0831 15:27:45.195885 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.06836 (* 0.1 = 0.206836 loss)
I0831 15:27:45.195910 12026 sgd_solver.cpp:106] Iteration 18900, lr = 0.0001
I0831 15:28:25.100208 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_19000.caffemodel
I0831 15:28:25.834928 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_19000.solverstate
I0831 15:28:26.029842 12026 solver.cpp:337] Iteration 19000, Testing net (#0)
I0831 15:28:33.498952 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.727429
I0831 15:28:33.499025 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984286
I0831 15:28:33.499055 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.772716 (* 1 = 0.772716 loss)
I0831 15:28:33.499080 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.45969 (* 0.1 = 0.345969 loss)
I0831 15:28:33.615723 12026 solver.cpp:228] Iteration 19000, loss = 0.93557
I0831 15:28:33.615799 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.82599 (* 1 = 0.82599 loss)
I0831 15:28:33.615823 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36906 (* 0.1 = 0.236906 loss)
I0831 15:28:33.615847 12026 sgd_solver.cpp:106] Iteration 19000, lr = 0.0001
I0831 15:29:13.909027 12026 solver.cpp:228] Iteration 19100, loss = 0.962957
I0831 15:29:13.909211 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.844859 (* 1 = 0.844859 loss)
I0831 15:29:13.909237 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.34273 (* 0.1 = 0.234273 loss)
I0831 15:29:13.909260 12026 sgd_solver.cpp:106] Iteration 19100, lr = 0.0001
I0831 15:29:54.205631 12026 solver.cpp:228] Iteration 19200, loss = 0.957032
I0831 15:29:54.205807 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.817362 (* 1 = 0.817362 loss)
I0831 15:29:54.205832 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.39855 (* 0.1 = 0.239855 loss)
I0831 15:29:54.205852 12026 sgd_solver.cpp:106] Iteration 19200, lr = 0.0001
I0831 15:30:34.501643 12026 solver.cpp:228] Iteration 19300, loss = 0.933027
I0831 15:30:34.501773 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.775995 (* 1 = 0.775995 loss)
I0831 15:30:34.501798 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36066 (* 0.1 = 0.236066 loss)
I0831 15:30:34.501818 12026 sgd_solver.cpp:106] Iteration 19300, lr = 0.0001
I0831 15:31:14.797340 12026 solver.cpp:228] Iteration 19400, loss = 0.952121
I0831 15:31:14.797523 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.92106 (* 1 = 0.92106 loss)
I0831 15:31:14.797549 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36024 (* 0.1 = 0.236024 loss)
I0831 15:31:14.797570 12026 sgd_solver.cpp:106] Iteration 19400, lr = 0.0001
I0831 15:31:55.093394 12026 solver.cpp:228] Iteration 19500, loss = 0.955453
I0831 15:31:55.093582 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.760532 (* 1 = 0.760532 loss)
I0831 15:31:55.093610 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.2924 (* 0.1 = 0.22924 loss)
I0831 15:31:55.093632 12026 sgd_solver.cpp:106] Iteration 19500, lr = 0.0001
I0831 15:32:35.422046 12026 solver.cpp:228] Iteration 19600, loss = 0.982543
I0831 15:32:35.422329 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.784174 (* 1 = 0.784174 loss)
I0831 15:32:35.422358 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.50243 (* 0.1 = 0.250243 loss)
I0831 15:32:35.422387 12026 sgd_solver.cpp:106] Iteration 19600, lr = 0.0001
I0831 15:33:15.717867 12026 solver.cpp:228] Iteration 19700, loss = 0.915867
I0831 15:33:15.718055 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.726303 (* 1 = 0.726303 loss)
I0831 15:33:15.718081 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.12899 (* 0.1 = 0.212899 loss)
I0831 15:33:15.718102 12026 sgd_solver.cpp:106] Iteration 19700, lr = 0.0001
I0831 15:33:56.042901 12026 solver.cpp:228] Iteration 19800, loss = 0.953901
I0831 15:33:56.043083 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.911106 (* 1 = 0.911106 loss)
I0831 15:33:56.043110 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.77445 (* 0.1 = 0.277445 loss)
I0831 15:33:56.043131 12026 sgd_solver.cpp:106] Iteration 19800, lr = 0.0001
I0831 15:34:36.345942 12026 solver.cpp:228] Iteration 19900, loss = 0.92903
I0831 15:34:36.346122 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.540582 (* 1 = 0.540582 loss)
I0831 15:34:36.346148 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92048 (* 0.1 = 0.192048 loss)
I0831 15:34:36.346169 12026 sgd_solver.cpp:106] Iteration 19900, lr = 0.0001
I0831 15:35:16.238584 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_20000.caffemodel
I0831 15:35:16.971153 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_20000.solverstate
I0831 15:35:17.165638 12026 solver.cpp:337] Iteration 20000, Testing net (#0)
I0831 15:35:24.649616 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.748857
I0831 15:35:24.649690 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984286
I0831 15:35:24.649724 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.71704 (* 1 = 0.71704 loss)
I0831 15:35:24.649749 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.19738 (* 0.1 = 0.319738 loss)
I0831 15:35:24.766031 12026 solver.cpp:228] Iteration 20000, loss = 0.953131
I0831 15:35:24.766109 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.741332 (* 1 = 0.741332 loss)
I0831 15:35:24.766132 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.38688 (* 0.1 = 0.238688 loss)
I0831 15:35:24.766157 12026 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0831 15:36:05.066804 12026 solver.cpp:228] Iteration 20100, loss = 0.942107
I0831 15:36:05.066957 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.669613 (* 1 = 0.669613 loss)
I0831 15:36:05.066982 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21608 (* 0.1 = 0.221608 loss)
I0831 15:36:05.067008 12026 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0831 15:36:45.366286 12026 solver.cpp:228] Iteration 20200, loss = 0.962945
I0831 15:36:45.366467 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.632092 (* 1 = 0.632092 loss)
I0831 15:36:45.366495 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00712 (* 0.1 = 0.200712 loss)
I0831 15:36:45.366518 12026 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0831 15:37:25.667362 12026 solver.cpp:228] Iteration 20300, loss = 0.913107
I0831 15:37:25.667745 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.584352 (* 1 = 0.584352 loss)
I0831 15:37:25.667791 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.32924 (* 0.1 = 0.232924 loss)
I0831 15:37:25.667831 12026 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0831 15:38:05.967818 12026 solver.cpp:228] Iteration 20400, loss = 0.930544
I0831 15:38:05.968035 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.877383 (* 1 = 0.877383 loss)
I0831 15:38:05.968062 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42178 (* 0.1 = 0.242178 loss)
I0831 15:38:05.968085 12026 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0831 15:38:46.268100 12026 solver.cpp:228] Iteration 20500, loss = 0.937436
I0831 15:38:46.268299 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.488069 (* 1 = 0.488069 loss)
I0831 15:38:46.268324 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89391 (* 0.1 = 0.189391 loss)
I0831 15:38:46.268362 12026 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0831 15:39:26.588603 12026 solver.cpp:228] Iteration 20600, loss = 0.909838
I0831 15:39:26.588840 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.576883 (* 1 = 0.576883 loss)
I0831 15:39:26.588868 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89675 (* 0.1 = 0.189675 loss)
I0831 15:39:26.588889 12026 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0831 15:40:06.905652 12026 solver.cpp:228] Iteration 20700, loss = 0.92283
I0831 15:40:06.905861 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.504212 (* 1 = 0.504212 loss)
I0831 15:40:06.905890 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89015 (* 0.1 = 0.189015 loss)
I0831 15:40:06.905910 12026 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0831 15:40:47.215505 12026 solver.cpp:228] Iteration 20800, loss = 0.956015
I0831 15:40:47.215715 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.698837 (* 1 = 0.698837 loss)
I0831 15:40:47.215742 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.09166 (* 0.1 = 0.209166 loss)
I0831 15:40:47.215764 12026 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0831 15:41:27.529206 12026 solver.cpp:228] Iteration 20900, loss = 0.956552
I0831 15:41:27.529407 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.652554 (* 1 = 0.652554 loss)
I0831 15:41:27.529433 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.17663 (* 0.1 = 0.217663 loss)
I0831 15:41:27.529455 12026 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0831 15:42:07.431982 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_21000.caffemodel
I0831 15:42:08.166446 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_21000.solverstate
I0831 15:42:08.361351 12026 solver.cpp:337] Iteration 21000, Testing net (#0)
I0831 15:42:15.838479 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.742286
I0831 15:42:15.838555 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.983143
I0831 15:42:15.838582 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.754945 (* 1 = 0.754945 loss)
I0831 15:42:15.838604 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.42594 (* 0.1 = 0.342594 loss)
I0831 15:42:15.956183 12026 solver.cpp:228] Iteration 21000, loss = 0.90309
I0831 15:42:15.956255 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.690801 (* 1 = 0.690801 loss)
I0831 15:42:15.956279 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.67415 (* 0.1 = 0.267415 loss)
I0831 15:42:15.956305 12026 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0831 15:42:56.262485 12026 solver.cpp:228] Iteration 21100, loss = 0.924168
I0831 15:42:56.262666 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.838924 (* 1 = 0.838924 loss)
I0831 15:42:56.262693 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.43984 (* 0.1 = 0.243984 loss)
I0831 15:42:56.262725 12026 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0831 15:43:36.573901 12026 solver.cpp:228] Iteration 21200, loss = 0.91474
I0831 15:43:36.574102 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.514783 (* 1 = 0.514783 loss)
I0831 15:43:36.574128 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.14162 (* 0.1 = 0.214162 loss)
I0831 15:43:36.574149 12026 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0831 15:44:16.898701 12026 solver.cpp:228] Iteration 21300, loss = 0.909418
I0831 15:44:16.898959 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.717144 (* 1 = 0.717144 loss)
I0831 15:44:16.898986 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.9616 (* 0.1 = 0.19616 loss)
I0831 15:44:16.899008 12026 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0831 15:44:57.206200 12026 solver.cpp:228] Iteration 21400, loss = 0.897996
I0831 15:44:57.206406 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.515664 (* 1 = 0.515664 loss)
I0831 15:44:57.206434 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98379 (* 0.1 = 0.198379 loss)
I0831 15:44:57.206456 12026 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0831 15:45:37.514111 12026 solver.cpp:228] Iteration 21500, loss = 0.93091
I0831 15:45:37.514312 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.837018 (* 1 = 0.837018 loss)
I0831 15:45:37.514338 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.57147 (* 0.1 = 0.257147 loss)
I0831 15:45:37.514359 12026 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0831 15:46:17.825532 12026 solver.cpp:228] Iteration 21600, loss = 0.920505
I0831 15:46:17.825733 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.70857 (* 1 = 0.70857 loss)
I0831 15:46:17.825760 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.32353 (* 0.1 = 0.232353 loss)
I0831 15:46:17.825781 12026 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0831 15:46:58.154093 12026 solver.cpp:228] Iteration 21700, loss = 0.886706
I0831 15:46:58.154346 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.503524 (* 1 = 0.503524 loss)
I0831 15:46:58.154379 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.96727 (* 0.1 = 0.196727 loss)
I0831 15:46:58.154404 12026 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0831 15:47:38.460304 12026 solver.cpp:228] Iteration 21800, loss = 0.924683
I0831 15:47:38.460530 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.774522 (* 1 = 0.774522 loss)
I0831 15:47:38.460556 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.19434 (* 0.1 = 0.219434 loss)
I0831 15:47:38.460577 12026 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0831 15:48:18.800340 12026 solver.cpp:228] Iteration 21900, loss = 0.915561
I0831 15:48:18.800550 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.795917 (* 1 = 0.795917 loss)
I0831 15:48:18.800577 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21381 (* 0.1 = 0.221381 loss)
I0831 15:48:18.800602 12026 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0831 15:48:58.698648 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_22000.caffemodel
I0831 15:48:59.432382 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_22000.solverstate
I0831 15:48:59.627365 12026 solver.cpp:337] Iteration 22000, Testing net (#0)
I0831 15:49:07.106964 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.748286
I0831 15:49:07.107046 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.986
I0831 15:49:07.107110 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.721353 (* 1 = 0.721353 loss)
I0831 15:49:07.107136 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.49476 (* 0.1 = 0.349476 loss)
I0831 15:49:07.224395 12026 solver.cpp:228] Iteration 22000, loss = 0.884528
I0831 15:49:07.224483 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.51982 (* 1 = 0.51982 loss)
I0831 15:49:07.224508 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.94685 (* 0.1 = 0.194685 loss)
I0831 15:49:07.224534 12026 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0831 15:49:47.555094 12026 solver.cpp:228] Iteration 22100, loss = 0.914543
I0831 15:49:47.555269 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.782582 (* 1 = 0.782582 loss)
I0831 15:49:47.555295 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.14024 (* 0.1 = 0.214024 loss)
I0831 15:49:47.555316 12026 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0831 15:50:27.877737 12026 solver.cpp:228] Iteration 22200, loss = 0.914429
I0831 15:50:27.877948 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.99896 (* 1 = 0.99896 loss)
I0831 15:50:27.877974 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.49671 (* 0.1 = 0.249671 loss)
I0831 15:50:27.878007 12026 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0831 15:51:08.200295 12026 solver.cpp:228] Iteration 22300, loss = 0.905895
I0831 15:51:08.200489 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.520902 (* 1 = 0.520902 loss)
I0831 15:51:08.200515 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.03429 (* 0.1 = 0.203429 loss)
I0831 15:51:08.200533 12026 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0831 15:51:48.517405 12026 solver.cpp:228] Iteration 22400, loss = 0.900364
I0831 15:51:48.517627 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.681535 (* 1 = 0.681535 loss)
I0831 15:51:48.517653 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11966 (* 0.1 = 0.211966 loss)
I0831 15:51:48.517675 12026 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0831 15:52:28.849710 12026 solver.cpp:228] Iteration 22500, loss = 0.898822
I0831 15:52:28.849911 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.575956 (* 1 = 0.575956 loss)
I0831 15:52:28.849938 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.06303 (* 0.1 = 0.206303 loss)
I0831 15:52:28.849961 12026 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0831 15:53:09.161962 12026 solver.cpp:228] Iteration 22600, loss = 0.861
I0831 15:53:09.162148 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.762178 (* 1 = 0.762178 loss)
I0831 15:53:09.162173 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08569 (* 0.1 = 0.208569 loss)
I0831 15:53:09.162194 12026 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0831 15:53:49.476662 12026 solver.cpp:228] Iteration 22700, loss = 0.90078
I0831 15:53:49.476845 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.800332 (* 1 = 0.800332 loss)
I0831 15:53:49.476868 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.44485 (* 0.1 = 0.244485 loss)
I0831 15:53:49.476889 12026 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0831 15:54:29.791115 12026 solver.cpp:228] Iteration 22800, loss = 0.905183
I0831 15:54:29.791296 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.836936 (* 1 = 0.836936 loss)
I0831 15:54:29.791321 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04185 (* 0.1 = 0.204185 loss)
I0831 15:54:29.791342 12026 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0831 15:55:10.109268 12026 solver.cpp:228] Iteration 22900, loss = 0.916823
I0831 15:55:10.109463 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.75097 (* 1 = 0.75097 loss)
I0831 15:55:10.109489 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04364 (* 0.1 = 0.204364 loss)
I0831 15:55:10.109513 12026 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0831 15:55:50.037644 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_23000.caffemodel
I0831 15:55:50.773293 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_23000.solverstate
I0831 15:55:50.974243 12026 solver.cpp:337] Iteration 23000, Testing net (#0)
I0831 15:55:58.457078 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.741714
I0831 15:55:58.457175 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984286
I0831 15:55:58.457201 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.763472 (* 1 = 0.763472 loss)
I0831 15:55:58.457223 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.38921 (* 0.1 = 0.338921 loss)
I0831 15:55:58.573720 12026 solver.cpp:228] Iteration 23000, loss = 0.891227
I0831 15:55:58.573801 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.765158 (* 1 = 0.765158 loss)
I0831 15:55:58.573824 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.39762 (* 0.1 = 0.239762 loss)
I0831 15:55:58.573849 12026 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0831 15:56:38.878584 12026 solver.cpp:228] Iteration 23100, loss = 0.907803
I0831 15:56:38.878901 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.578614 (* 1 = 0.578614 loss)
I0831 15:56:38.878932 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.18666 (* 0.1 = 0.218666 loss)
I0831 15:56:38.878947 12026 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0831 15:57:19.184767 12026 solver.cpp:228] Iteration 23200, loss = 0.888809
I0831 15:57:19.184919 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.550319 (* 1 = 0.550319 loss)
I0831 15:57:19.184944 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.80994 (* 0.1 = 0.180994 loss)
I0831 15:57:19.184968 12026 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0831 15:57:59.488746 12026 solver.cpp:228] Iteration 23300, loss = 0.86105
I0831 15:57:59.488905 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.567728 (* 1 = 0.567728 loss)
I0831 15:57:59.488931 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.2937 (* 0.1 = 0.22937 loss)
I0831 15:57:59.488953 12026 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0831 15:58:39.786679 12026 solver.cpp:228] Iteration 23400, loss = 0.874739
I0831 15:58:39.786931 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.739476 (* 1 = 0.739476 loss)
I0831 15:58:39.786959 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98557 (* 0.1 = 0.198557 loss)
I0831 15:58:39.786974 12026 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0831 15:59:20.082458 12026 solver.cpp:228] Iteration 23500, loss = 0.910833
I0831 15:59:20.082674 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.687255 (* 1 = 0.687255 loss)
I0831 15:59:20.082703 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08372 (* 0.1 = 0.208372 loss)
I0831 15:59:20.082718 12026 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0831 16:00:00.375936 12026 solver.cpp:228] Iteration 23600, loss = 0.928674
I0831 16:00:00.376123 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.852109 (* 1 = 0.852109 loss)
I0831 16:00:00.376150 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.13876 (* 0.1 = 0.213876 loss)
I0831 16:00:00.376173 12026 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0831 16:00:40.679603 12026 solver.cpp:228] Iteration 23700, loss = 0.861031
I0831 16:00:40.679790 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.478123 (* 1 = 0.478123 loss)
I0831 16:00:40.679814 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.7565 (* 0.1 = 0.17565 loss)
I0831 16:00:40.679837 12026 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0831 16:01:20.975812 12026 solver.cpp:228] Iteration 23800, loss = 0.899508
I0831 16:01:20.975987 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.661667 (* 1 = 0.661667 loss)
I0831 16:01:20.976013 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11351 (* 0.1 = 0.211351 loss)
I0831 16:01:20.976034 12026 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0831 16:02:01.275496 12026 solver.cpp:228] Iteration 23900, loss = 0.888295
I0831 16:02:01.275674 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.510336 (* 1 = 0.510336 loss)
I0831 16:02:01.275701 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.32441 (* 0.1 = 0.232441 loss)
I0831 16:02:01.275722 12026 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0831 16:02:41.175901 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_24000.caffemodel
I0831 16:02:41.911676 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_24000.solverstate
I0831 16:02:42.105589 12026 solver.cpp:337] Iteration 24000, Testing net (#0)
I0831 16:02:49.601810 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.736571
I0831 16:02:49.601919 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984571
I0831 16:02:49.601966 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.743213 (* 1 = 0.743213 loss)
I0831 16:02:49.602006 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.62605 (* 0.1 = 0.362605 loss)
I0831 16:02:49.725006 12026 solver.cpp:228] Iteration 24000, loss = 0.875436
I0831 16:02:49.725131 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.734065 (* 1 = 0.734065 loss)
I0831 16:02:49.725219 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.63933 (* 0.1 = 0.263933 loss)
I0831 16:02:49.725280 12026 sgd_solver.cpp:106] Iteration 24000, lr = 0.0001
I0831 16:03:30.053302 12026 solver.cpp:228] Iteration 24100, loss = 0.873618
I0831 16:03:30.053539 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.900728 (* 1 = 0.900728 loss)
I0831 16:03:30.053566 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.35694 (* 0.1 = 0.235694 loss)
I0831 16:03:30.053592 12026 sgd_solver.cpp:106] Iteration 24100, lr = 0.0001
I0831 16:04:10.362524 12026 solver.cpp:228] Iteration 24200, loss = 0.88522
I0831 16:04:10.362784 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.629834 (* 1 = 0.629834 loss)
I0831 16:04:10.362812 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.34026 (* 0.1 = 0.234026 loss)
I0831 16:04:10.362833 12026 sgd_solver.cpp:106] Iteration 24200, lr = 0.0001
I0831 16:04:50.682217 12026 solver.cpp:228] Iteration 24300, loss = 0.8976
I0831 16:04:50.682425 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.521653 (* 1 = 0.521653 loss)
I0831 16:04:50.682454 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.87755 (* 0.1 = 0.187755 loss)
I0831 16:04:50.682476 12026 sgd_solver.cpp:106] Iteration 24300, lr = 0.0001
I0831 16:05:30.994987 12026 solver.cpp:228] Iteration 24400, loss = 0.864152
I0831 16:05:30.995205 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.420992 (* 1 = 0.420992 loss)
I0831 16:05:30.995234 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.76799 (* 0.1 = 0.176799 loss)
I0831 16:05:30.995255 12026 sgd_solver.cpp:106] Iteration 24400, lr = 0.0001
I0831 16:06:11.301643 12026 solver.cpp:228] Iteration 24500, loss = 0.878186
I0831 16:06:11.301822 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.548986 (* 1 = 0.548986 loss)
I0831 16:06:11.301847 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.85132 (* 0.1 = 0.185132 loss)
I0831 16:06:11.301868 12026 sgd_solver.cpp:106] Iteration 24500, lr = 0.0001
I0831 16:06:51.613647 12026 solver.cpp:228] Iteration 24600, loss = 0.864993
I0831 16:06:51.613821 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.448536 (* 1 = 0.448536 loss)
I0831 16:06:51.613847 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92505 (* 0.1 = 0.192505 loss)
I0831 16:06:51.613871 12026 sgd_solver.cpp:106] Iteration 24600, lr = 0.0001
I0831 16:07:31.918076 12026 solver.cpp:228] Iteration 24700, loss = 0.858416
I0831 16:07:31.918259 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.572631 (* 1 = 0.572631 loss)
I0831 16:07:31.918285 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89916 (* 0.1 = 0.189916 loss)
I0831 16:07:31.918306 12026 sgd_solver.cpp:106] Iteration 24700, lr = 0.0001
I0831 16:08:12.222815 12026 solver.cpp:228] Iteration 24800, loss = 0.869438
I0831 16:08:12.222950 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.572165 (* 1 = 0.572165 loss)
I0831 16:08:12.222976 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.64396 (* 0.1 = 0.164396 loss)
I0831 16:08:12.222996 12026 sgd_solver.cpp:106] Iteration 24800, lr = 0.0001
I0831 16:08:52.533041 12026 solver.cpp:228] Iteration 24900, loss = 0.900279
I0831 16:08:52.533231 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.473592 (* 1 = 0.473592 loss)
I0831 16:08:52.533259 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.2344 (* 0.1 = 0.22344 loss)
I0831 16:08:52.533280 12026 sgd_solver.cpp:106] Iteration 24900, lr = 0.0001
I0831 16:09:32.442909 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_25000.caffemodel
I0831 16:09:33.182744 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_25000.solverstate
I0831 16:09:33.378867 12026 solver.cpp:337] Iteration 25000, Testing net (#0)
I0831 16:09:40.869609 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.755143
I0831 16:09:40.869752 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.986
I0831 16:09:40.869797 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.717087 (* 1 = 0.717087 loss)
I0831 16:09:40.869853 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.39079 (* 0.1 = 0.339079 loss)
I0831 16:09:40.999608 12026 solver.cpp:228] Iteration 25000, loss = 0.87095
I0831 16:09:40.999739 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.610837 (* 1 = 0.610837 loss)
I0831 16:09:40.999788 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.0277 (* 0.1 = 0.20277 loss)
I0831 16:09:40.999830 12026 sgd_solver.cpp:106] Iteration 25000, lr = 0.0001
I0831 16:10:21.294023 12026 solver.cpp:228] Iteration 25100, loss = 0.858286
I0831 16:10:21.294158 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.89056 (* 1 = 0.89056 loss)
I0831 16:10:21.294183 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08078 (* 0.1 = 0.208078 loss)
I0831 16:10:21.294208 12026 sgd_solver.cpp:106] Iteration 25100, lr = 0.0001
I0831 16:11:01.592521 12026 solver.cpp:228] Iteration 25200, loss = 0.871434
I0831 16:11:01.592705 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.891551 (* 1 = 0.891551 loss)
I0831 16:11:01.592730 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.37511 (* 0.1 = 0.237511 loss)
I0831 16:11:01.592751 12026 sgd_solver.cpp:106] Iteration 25200, lr = 0.0001
I0831 16:11:41.894960 12026 solver.cpp:228] Iteration 25300, loss = 0.842017
I0831 16:11:41.895138 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.553159 (* 1 = 0.553159 loss)
I0831 16:11:41.895164 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00358 (* 0.1 = 0.200358 loss)
I0831 16:11:41.895182 12026 sgd_solver.cpp:106] Iteration 25300, lr = 0.0001
I0831 16:12:22.196637 12026 solver.cpp:228] Iteration 25400, loss = 0.852614
I0831 16:12:22.196820 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.550247 (* 1 = 0.550247 loss)
I0831 16:12:22.196846 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.85091 (* 0.1 = 0.185091 loss)
I0831 16:12:22.196868 12026 sgd_solver.cpp:106] Iteration 25400, lr = 0.0001
I0831 16:13:02.493016 12026 solver.cpp:228] Iteration 25500, loss = 0.873042
I0831 16:13:02.493196 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.843462 (* 1 = 0.843462 loss)
I0831 16:13:02.493223 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04577 (* 0.1 = 0.204577 loss)
I0831 16:13:02.493245 12026 sgd_solver.cpp:106] Iteration 25500, lr = 0.0001
I0831 16:13:42.791172 12026 solver.cpp:228] Iteration 25600, loss = 0.880497
I0831 16:13:42.791303 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.692245 (* 1 = 0.692245 loss)
I0831 16:13:42.791328 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3213 (* 0.1 = 0.23213 loss)
I0831 16:13:42.791349 12026 sgd_solver.cpp:106] Iteration 25600, lr = 0.0001
I0831 16:14:23.085922 12026 solver.cpp:228] Iteration 25700, loss = 0.845645
I0831 16:14:23.086102 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.814295 (* 1 = 0.814295 loss)
I0831 16:14:23.086129 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.41021 (* 0.1 = 0.241021 loss)
I0831 16:14:23.086150 12026 sgd_solver.cpp:106] Iteration 25700, lr = 0.0001
I0831 16:15:03.384124 12026 solver.cpp:228] Iteration 25800, loss = 0.868353
I0831 16:15:03.385520 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.49165 (* 1 = 0.49165 loss)
I0831 16:15:03.385553 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02602 (* 0.1 = 0.202602 loss)
I0831 16:15:03.385570 12026 sgd_solver.cpp:106] Iteration 25800, lr = 0.0001
I0831 16:15:43.685323 12026 solver.cpp:228] Iteration 25900, loss = 0.835806
I0831 16:15:43.685492 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.561439 (* 1 = 0.561439 loss)
I0831 16:15:43.685524 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.93565 (* 0.1 = 0.193565 loss)
I0831 16:15:43.685554 12026 sgd_solver.cpp:106] Iteration 25900, lr = 0.0001
I0831 16:16:23.582785 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_26000.caffemodel
I0831 16:16:24.307327 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_26000.solverstate
I0831 16:16:24.509666 12026 solver.cpp:337] Iteration 26000, Testing net (#0)
I0831 16:16:31.984527 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.75
I0831 16:16:31.984606 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984286
I0831 16:16:31.984629 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.719653 (* 1 = 0.719653 loss)
I0831 16:16:31.984654 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.16757 (* 0.1 = 0.316757 loss)
I0831 16:16:32.101148 12026 solver.cpp:228] Iteration 26000, loss = 0.829305
I0831 16:16:32.101225 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.705479 (* 1 = 0.705479 loss)
I0831 16:16:32.101248 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.22628 (* 0.1 = 0.222628 loss)
I0831 16:16:32.101271 12026 sgd_solver.cpp:106] Iteration 26000, lr = 0.0001
I0831 16:17:12.405927 12026 solver.cpp:228] Iteration 26100, loss = 0.847538
I0831 16:17:12.406096 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.758593 (* 1 = 0.758593 loss)
I0831 16:17:12.406123 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.13493 (* 0.1 = 0.213493 loss)
I0831 16:17:12.406144 12026 sgd_solver.cpp:106] Iteration 26100, lr = 0.0001
I0831 16:17:52.707283 12026 solver.cpp:228] Iteration 26200, loss = 0.879251
I0831 16:17:52.707500 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.496335 (* 1 = 0.496335 loss)
I0831 16:17:52.707527 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.86924 (* 0.1 = 0.186924 loss)
I0831 16:17:52.707548 12026 sgd_solver.cpp:106] Iteration 26200, lr = 0.0001
I0831 16:18:33.008599 12026 solver.cpp:228] Iteration 26300, loss = 0.876453
I0831 16:18:33.008729 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.629282 (* 1 = 0.629282 loss)
I0831 16:18:33.008754 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.85686 (* 0.1 = 0.185686 loss)
I0831 16:18:33.008780 12026 sgd_solver.cpp:106] Iteration 26300, lr = 0.0001
I0831 16:19:13.310997 12026 solver.cpp:228] Iteration 26400, loss = 0.837646
I0831 16:19:13.311215 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.386327 (* 1 = 0.386327 loss)
I0831 16:19:13.311244 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.76426 (* 0.1 = 0.176426 loss)
I0831 16:19:13.311257 12026 sgd_solver.cpp:106] Iteration 26400, lr = 0.0001
I0831 16:19:53.615928 12026 solver.cpp:228] Iteration 26500, loss = 0.854021
I0831 16:19:53.616114 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.624508 (* 1 = 0.624508 loss)
I0831 16:19:53.616142 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05376 (* 0.1 = 0.205376 loss)
I0831 16:19:53.616168 12026 sgd_solver.cpp:106] Iteration 26500, lr = 0.0001
I0831 16:20:33.943783 12026 solver.cpp:228] Iteration 26600, loss = 0.833332
I0831 16:20:33.943995 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.665396 (* 1 = 0.665396 loss)
I0831 16:20:33.944022 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.25608 (* 0.1 = 0.225608 loss)
I0831 16:20:33.944044 12026 sgd_solver.cpp:106] Iteration 26600, lr = 0.0001
I0831 16:21:14.249449 12026 solver.cpp:228] Iteration 26700, loss = 0.828709
I0831 16:21:14.249626 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.663191 (* 1 = 0.663191 loss)
I0831 16:21:14.249652 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.2224 (* 0.1 = 0.22224 loss)
I0831 16:21:14.249672 12026 sgd_solver.cpp:106] Iteration 26700, lr = 0.0001
I0831 16:21:54.551921 12026 solver.cpp:228] Iteration 26800, loss = 0.845683
I0831 16:21:54.552063 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.664086 (* 1 = 0.664086 loss)
I0831 16:21:54.552089 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.10811 (* 0.1 = 0.210811 loss)
I0831 16:21:54.552114 12026 sgd_solver.cpp:106] Iteration 26800, lr = 0.0001
I0831 16:22:34.875464 12026 solver.cpp:228] Iteration 26900, loss = 0.867336
I0831 16:22:34.875658 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.910806 (* 1 = 0.910806 loss)
I0831 16:22:34.875684 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.51124 (* 0.1 = 0.251124 loss)
I0831 16:22:34.875706 12026 sgd_solver.cpp:106] Iteration 26900, lr = 0.0001
I0831 16:23:14.780213 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_27000.caffemodel
I0831 16:23:15.569831 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_27000.solverstate
I0831 16:23:15.783875 12026 solver.cpp:337] Iteration 27000, Testing net (#0)
I0831 16:23:23.265748 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.756857
I0831 16:23:23.265821 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.985143
I0831 16:23:23.265846 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.714061 (* 1 = 0.714061 loss)
I0831 16:23:23.265868 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.40085 (* 0.1 = 0.340085 loss)
I0831 16:23:23.382347 12026 solver.cpp:228] Iteration 27000, loss = 0.845102
I0831 16:23:23.382434 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.484525 (* 1 = 0.484525 loss)
I0831 16:23:23.382467 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89749 (* 0.1 = 0.189749 loss)
I0831 16:23:23.382493 12026 sgd_solver.cpp:106] Iteration 27000, lr = 0.0001
I0831 16:24:03.688053 12026 solver.cpp:228] Iteration 27100, loss = 0.829981
I0831 16:24:03.688226 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.757543 (* 1 = 0.757543 loss)
I0831 16:24:03.688253 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.58835 (* 0.1 = 0.258835 loss)
I0831 16:24:03.688274 12026 sgd_solver.cpp:106] Iteration 27100, lr = 0.0001
I0831 16:24:43.990866 12026 solver.cpp:228] Iteration 27200, loss = 0.851081
I0831 16:24:43.991045 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.592287 (* 1 = 0.592287 loss)
I0831 16:24:43.991071 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.37342 (* 0.1 = 0.237342 loss)
I0831 16:24:43.991092 12026 sgd_solver.cpp:106] Iteration 27200, lr = 0.0001
I0831 16:25:24.315171 12026 solver.cpp:228] Iteration 27300, loss = 0.811958
I0831 16:25:24.315452 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.562669 (* 1 = 0.562669 loss)
I0831 16:25:24.315490 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.23867 (* 0.1 = 0.223867 loss)
I0831 16:25:24.315510 12026 sgd_solver.cpp:106] Iteration 27300, lr = 0.0001
I0831 16:26:04.671947 12026 solver.cpp:228] Iteration 27400, loss = 0.839229
I0831 16:26:04.672246 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.562305 (* 1 = 0.562305 loss)
I0831 16:26:04.672286 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.10901 (* 0.1 = 0.210901 loss)
I0831 16:26:04.672322 12026 sgd_solver.cpp:106] Iteration 27400, lr = 0.0001
I0831 16:26:45.018399 12026 solver.cpp:228] Iteration 27500, loss = 0.839694
I0831 16:26:45.018638 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.601143 (* 1 = 0.601143 loss)
I0831 16:26:45.018666 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.68493 (* 0.1 = 0.268493 loss)
I0831 16:26:45.018687 12026 sgd_solver.cpp:106] Iteration 27500, lr = 0.0001
I0831 16:27:25.336061 12026 solver.cpp:228] Iteration 27600, loss = 0.87112
I0831 16:27:25.336267 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.425735 (* 1 = 0.425735 loss)
I0831 16:27:25.336293 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.81958 (* 0.1 = 0.181958 loss)
I0831 16:27:25.336315 12026 sgd_solver.cpp:106] Iteration 27600, lr = 0.0001
I0831 16:28:05.649265 12026 solver.cpp:228] Iteration 27700, loss = 0.828183
I0831 16:28:05.649479 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.583985 (* 1 = 0.583985 loss)
I0831 16:28:05.649507 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04294 (* 0.1 = 0.204294 loss)
I0831 16:28:05.649528 12026 sgd_solver.cpp:106] Iteration 27700, lr = 0.0001
I0831 16:28:45.962194 12026 solver.cpp:228] Iteration 27800, loss = 0.842808
I0831 16:28:45.962419 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.503897 (* 1 = 0.503897 loss)
I0831 16:28:45.962445 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21116 (* 0.1 = 0.221116 loss)
I0831 16:28:45.962463 12026 sgd_solver.cpp:106] Iteration 27800, lr = 0.0001
I0831 16:29:26.265141 12026 solver.cpp:228] Iteration 27900, loss = 0.847382
I0831 16:29:26.265328 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.883541 (* 1 = 0.883541 loss)
I0831 16:29:26.265353 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.19681 (* 0.1 = 0.219681 loss)
I0831 16:29:26.265374 12026 sgd_solver.cpp:106] Iteration 27900, lr = 0.0001
I0831 16:30:06.171700 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_28000.caffemodel
I0831 16:30:06.985363 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_28000.solverstate
I0831 16:30:07.197808 12026 solver.cpp:337] Iteration 28000, Testing net (#0)
I0831 16:30:14.676614 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.762857
I0831 16:30:14.676689 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.983714
I0831 16:30:14.676724 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.694663 (* 1 = 0.694663 loss)
I0831 16:30:14.676746 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.14619 (* 0.1 = 0.314619 loss)
I0831 16:30:14.793182 12026 solver.cpp:228] Iteration 28000, loss = 0.781246
I0831 16:30:14.793254 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.530459 (* 1 = 0.530459 loss)
I0831 16:30:14.793277 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.57407 (* 0.1 = 0.157408 loss)
I0831 16:30:14.793300 12026 sgd_solver.cpp:106] Iteration 28000, lr = 0.0001
I0831 16:30:55.102704 12026 solver.cpp:228] Iteration 28100, loss = 0.813493
I0831 16:30:55.102936 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.543297 (* 1 = 0.543297 loss)
I0831 16:30:55.102967 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.88301 (* 0.1 = 0.188301 loss)
I0831 16:30:55.102980 12026 sgd_solver.cpp:106] Iteration 28100, lr = 0.0001
I0831 16:31:35.409651 12026 solver.cpp:228] Iteration 28200, loss = 0.850359
I0831 16:31:35.409834 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.821381 (* 1 = 0.821381 loss)
I0831 16:31:35.409860 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.43633 (* 0.1 = 0.243633 loss)
I0831 16:31:35.409881 12026 sgd_solver.cpp:106] Iteration 28200, lr = 0.0001
I0831 16:32:15.716434 12026 solver.cpp:228] Iteration 28300, loss = 0.848839
I0831 16:32:15.716616 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.781904 (* 1 = 0.781904 loss)
I0831 16:32:15.716642 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.24009 (* 0.1 = 0.224009 loss)
I0831 16:32:15.716665 12026 sgd_solver.cpp:106] Iteration 28300, lr = 0.0001
I0831 16:32:56.023583 12026 solver.cpp:228] Iteration 28400, loss = 0.808367
I0831 16:32:56.023773 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.646281 (* 1 = 0.646281 loss)
I0831 16:32:56.023823 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.84402 (* 0.1 = 0.184402 loss)
I0831 16:32:56.023846 12026 sgd_solver.cpp:106] Iteration 28400, lr = 0.0001
I0831 16:33:36.327103 12026 solver.cpp:228] Iteration 28500, loss = 0.845838
I0831 16:33:36.327286 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.39349 (* 1 = 0.39349 loss)
I0831 16:33:36.327312 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.83857 (* 0.1 = 0.183857 loss)
I0831 16:33:36.327334 12026 sgd_solver.cpp:106] Iteration 28500, lr = 0.0001
I0831 16:34:16.633942 12026 solver.cpp:228] Iteration 28600, loss = 0.810607
I0831 16:34:16.634126 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.860339 (* 1 = 0.860339 loss)
I0831 16:34:16.634152 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.47833 (* 0.1 = 0.247833 loss)
I0831 16:34:16.634181 12026 sgd_solver.cpp:106] Iteration 28600, lr = 0.0001
I0831 16:34:56.934901 12026 solver.cpp:228] Iteration 28700, loss = 0.803459
I0831 16:34:56.935127 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.658646 (* 1 = 0.658646 loss)
I0831 16:34:56.935165 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.12828 (* 0.1 = 0.212828 loss)
I0831 16:34:56.935190 12026 sgd_solver.cpp:106] Iteration 28700, lr = 0.0001
I0831 16:35:37.250687 12026 solver.cpp:228] Iteration 28800, loss = 0.795422
I0831 16:35:37.251003 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.727853 (* 1 = 0.727853 loss)
I0831 16:35:37.251058 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.16975 (* 0.1 = 0.216975 loss)
I0831 16:35:37.251085 12026 sgd_solver.cpp:106] Iteration 28800, lr = 0.0001
I0831 16:36:17.551264 12026 solver.cpp:228] Iteration 28900, loss = 0.840924
I0831 16:36:17.551395 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.615689 (* 1 = 0.615689 loss)
I0831 16:36:17.551429 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30502 (* 0.1 = 0.230502 loss)
I0831 16:36:17.551453 12026 sgd_solver.cpp:106] Iteration 28900, lr = 0.0001
I0831 16:36:57.453950 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_29000.caffemodel
I0831 16:36:58.262589 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_29000.solverstate
I0831 16:36:58.476565 12026 solver.cpp:337] Iteration 29000, Testing net (#0)
I0831 16:37:05.943539 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.754572
I0831 16:37:05.943608 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.984
I0831 16:37:05.943641 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.717076 (* 1 = 0.717076 loss)
I0831 16:37:05.943666 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.25833 (* 0.1 = 0.325833 loss)
I0831 16:37:06.060088 12026 solver.cpp:228] Iteration 29000, loss = 0.828798
I0831 16:37:06.060163 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.600031 (* 1 = 0.600031 loss)
I0831 16:37:06.060186 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.5633 (* 0.1 = 0.25633 loss)
I0831 16:37:06.060212 12026 sgd_solver.cpp:106] Iteration 29000, lr = 0.0001
I0831 16:37:46.373174 12026 solver.cpp:228] Iteration 29100, loss = 0.80865
I0831 16:37:46.373354 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.520792 (* 1 = 0.520792 loss)
I0831 16:37:46.373380 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.41431 (* 0.1 = 0.241431 loss)
I0831 16:37:46.373402 12026 sgd_solver.cpp:106] Iteration 29100, lr = 0.0001
I0831 16:38:26.683130 12026 solver.cpp:228] Iteration 29200, loss = 0.840925
I0831 16:38:26.683377 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.659237 (* 1 = 0.659237 loss)
I0831 16:38:26.683403 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.33308 (* 0.1 = 0.233308 loss)
I0831 16:38:26.683431 12026 sgd_solver.cpp:106] Iteration 29200, lr = 0.0001
I0831 16:39:07.006314 12026 solver.cpp:228] Iteration 29300, loss = 0.823497
I0831 16:39:07.006598 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.690407 (* 1 = 0.690407 loss)
I0831 16:39:07.006634 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.2735 (* 0.1 = 0.22735 loss)
I0831 16:39:07.006657 12026 sgd_solver.cpp:106] Iteration 29300, lr = 0.0001
I0831 16:39:47.317733 12026 solver.cpp:228] Iteration 29400, loss = 0.830097
I0831 16:39:47.317970 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.48924 (* 1 = 0.48924 loss)
I0831 16:39:47.317996 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.0154 (* 0.1 = 0.20154 loss)
I0831 16:39:47.318017 12026 sgd_solver.cpp:106] Iteration 29400, lr = 0.0001
I0831 16:40:27.642428 12026 solver.cpp:228] Iteration 29500, loss = 0.799548
I0831 16:40:27.642735 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.487173 (* 1 = 0.487173 loss)
I0831 16:40:27.642766 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.79071 (* 0.1 = 0.179071 loss)
I0831 16:40:27.642787 12026 sgd_solver.cpp:106] Iteration 29500, lr = 0.0001
I0831 16:41:07.958398 12026 solver.cpp:228] Iteration 29600, loss = 0.820742
I0831 16:41:07.958678 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.695407 (* 1 = 0.695407 loss)
I0831 16:41:07.958709 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00221 (* 0.1 = 0.200221 loss)
I0831 16:41:07.958722 12026 sgd_solver.cpp:106] Iteration 29600, lr = 0.0001
I0831 16:41:48.284098 12026 solver.cpp:228] Iteration 29700, loss = 0.804462
I0831 16:41:48.284294 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.729005 (* 1 = 0.729005 loss)
I0831 16:41:48.284328 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.17613 (* 0.1 = 0.217613 loss)
I0831 16:41:48.284353 12026 sgd_solver.cpp:106] Iteration 29700, lr = 0.0001
I0831 16:42:28.591418 12026 solver.cpp:228] Iteration 29800, loss = 0.823636
I0831 16:42:28.591712 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.588026 (* 1 = 0.588026 loss)
I0831 16:42:28.591753 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.09659 (* 0.1 = 0.209659 loss)
I0831 16:42:28.591774 12026 sgd_solver.cpp:106] Iteration 29800, lr = 0.0001
I0831 16:43:08.919656 12026 solver.cpp:228] Iteration 29900, loss = 0.805346
I0831 16:43:08.919889 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.645999 (* 1 = 0.645999 loss)
I0831 16:43:08.919919 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.44452 (* 0.1 = 0.244452 loss)
I0831 16:43:08.919932 12026 sgd_solver.cpp:106] Iteration 29900, lr = 0.0001
I0831 16:43:48.827338 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_30000.caffemodel
I0831 16:43:49.564667 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_30000.solverstate
I0831 16:43:49.760685 12026 solver.cpp:337] Iteration 30000, Testing net (#0)
I0831 16:43:57.246122 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.749429
I0831 16:43:57.246198 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.983428
I0831 16:43:57.246234 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.717483 (* 1 = 0.717483 loss)
I0831 16:43:57.246256 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.22419 (* 0.1 = 0.322419 loss)
I0831 16:43:57.362865 12026 solver.cpp:228] Iteration 30000, loss = 0.775365
I0831 16:43:57.362946 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.544261 (* 1 = 0.544261 loss)
I0831 16:43:57.362967 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04088 (* 0.1 = 0.204088 loss)
I0831 16:43:57.362988 12026 sgd_solver.cpp:46] MultiStep Status: Iteration 30000, step = 1
I0831 16:43:57.363008 12026 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0831 16:44:37.673049 12026 solver.cpp:228] Iteration 30100, loss = 0.797608
I0831 16:44:37.673344 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.84746 (* 1 = 0.84746 loss)
I0831 16:44:37.673382 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.25061 (* 0.1 = 0.225061 loss)
I0831 16:44:37.673403 12026 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0831 16:45:17.986970 12026 solver.cpp:228] Iteration 30200, loss = 0.776579
I0831 16:45:17.987218 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.423354 (* 1 = 0.423354 loss)
I0831 16:45:17.987246 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89487 (* 0.1 = 0.189487 loss)
I0831 16:45:17.987268 12026 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0831 16:45:58.315466 12026 solver.cpp:228] Iteration 30300, loss = 0.780264
I0831 16:45:58.315661 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.797577 (* 1 = 0.797577 loss)
I0831 16:45:58.315688 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.46302 (* 0.1 = 0.246302 loss)
I0831 16:45:58.315718 12026 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0831 16:46:38.627910 12026 solver.cpp:228] Iteration 30400, loss = 0.74782
I0831 16:46:38.628090 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.532338 (* 1 = 0.532338 loss)
I0831 16:46:38.628118 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.95661 (* 0.1 = 0.195661 loss)
I0831 16:46:38.628149 12026 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0831 16:47:18.944183 12026 solver.cpp:228] Iteration 30500, loss = 0.765513
I0831 16:47:18.944321 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.593452 (* 1 = 0.593452 loss)
I0831 16:47:18.944346 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.45814 (* 0.1 = 0.245814 loss)
I0831 16:47:18.944367 12026 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0831 16:47:59.250444 12026 solver.cpp:228] Iteration 30600, loss = 0.740024
I0831 16:47:59.250633 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.551617 (* 1 = 0.551617 loss)
I0831 16:47:59.250663 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.59154 (* 0.1 = 0.159154 loss)
I0831 16:47:59.250681 12026 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0831 16:48:39.559907 12026 solver.cpp:228] Iteration 30700, loss = 0.721984
I0831 16:48:39.560039 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.301765 (* 1 = 0.301765 loss)
I0831 16:48:39.560065 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.83913 (* 0.1 = 0.183913 loss)
I0831 16:48:39.560086 12026 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0831 16:49:19.872920 12026 solver.cpp:228] Iteration 30800, loss = 0.751009
I0831 16:49:19.873105 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.530484 (* 1 = 0.530484 loss)
I0831 16:49:19.873131 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.73725 (* 0.1 = 0.173725 loss)
I0831 16:49:19.873162 12026 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0831 16:50:00.182416 12026 solver.cpp:228] Iteration 30900, loss = 0.759653
I0831 16:50:00.182607 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.636587 (* 1 = 0.636587 loss)
I0831 16:50:00.182636 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.36018 (* 0.1 = 0.236018 loss)
I0831 16:50:00.182651 12026 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0831 16:50:40.098742 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_31000.caffemodel
I0831 16:50:40.833365 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_31000.solverstate
I0831 16:50:41.027623 12026 solver.cpp:337] Iteration 31000, Testing net (#0)
I0831 16:50:48.518894 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.77
I0831 16:50:48.518971 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.987143
I0831 16:50:48.519004 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.664628 (* 1 = 0.664628 loss)
I0831 16:50:48.519029 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.18464 (* 0.1 = 0.318464 loss)
I0831 16:50:48.635807 12026 solver.cpp:228] Iteration 31000, loss = 0.762559
I0831 16:50:48.635886 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.558732 (* 1 = 0.558732 loss)
I0831 16:50:48.635910 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.03644 (* 0.1 = 0.203644 loss)
I0831 16:50:48.635934 12026 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0831 16:51:28.941212 12026 solver.cpp:228] Iteration 31100, loss = 0.723733
I0831 16:51:28.941526 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.735322 (* 1 = 0.735322 loss)
I0831 16:51:28.941556 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.22169 (* 0.1 = 0.222169 loss)
I0831 16:51:28.941583 12026 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0831 16:52:09.249716 12026 solver.cpp:228] Iteration 31200, loss = 0.761716
I0831 16:52:09.249909 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.581611 (* 1 = 0.581611 loss)
I0831 16:52:09.249938 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92314 (* 0.1 = 0.192314 loss)
I0831 16:52:09.249964 12026 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0831 16:52:49.553004 12026 solver.cpp:228] Iteration 31300, loss = 0.749192
I0831 16:52:49.553191 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.563571 (* 1 = 0.563571 loss)
I0831 16:52:49.553217 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21855 (* 0.1 = 0.221855 loss)
I0831 16:52:49.553239 12026 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0831 16:53:29.854987 12026 solver.cpp:228] Iteration 31400, loss = 0.740455
I0831 16:53:29.855166 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.669613 (* 1 = 0.669613 loss)
I0831 16:53:29.855192 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.68604 (* 0.1 = 0.168604 loss)
I0831 16:53:29.855213 12026 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0831 16:54:10.161486 12026 solver.cpp:228] Iteration 31500, loss = 0.756024
I0831 16:54:10.161669 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.43938 (* 1 = 0.43938 loss)
I0831 16:54:10.161695 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28443 (* 0.1 = 0.228443 loss)
I0831 16:54:10.161716 12026 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0831 16:54:50.467813 12026 solver.cpp:228] Iteration 31600, loss = 0.75452
I0831 16:54:50.468013 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.514585 (* 1 = 0.514585 loss)
I0831 16:54:50.468039 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.94898 (* 0.1 = 0.194898 loss)
I0831 16:54:50.468062 12026 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0831 16:55:30.780635 12026 solver.cpp:228] Iteration 31700, loss = 0.770955
I0831 16:55:30.780802 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.877053 (* 1 = 0.877053 loss)
I0831 16:55:30.780827 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21564 (* 0.1 = 0.221564 loss)
I0831 16:55:30.780848 12026 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0831 16:56:11.083575 12026 solver.cpp:228] Iteration 31800, loss = 0.74253
I0831 16:56:11.083755 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.498077 (* 1 = 0.498077 loss)
I0831 16:56:11.083781 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.22183 (* 0.1 = 0.222183 loss)
I0831 16:56:11.083802 12026 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0831 16:56:51.389906 12026 solver.cpp:228] Iteration 31900, loss = 0.759803
I0831 16:56:51.390091 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.439437 (* 1 = 0.439437 loss)
I0831 16:56:51.390116 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05343 (* 0.1 = 0.205343 loss)
I0831 16:56:51.390136 12026 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0831 16:57:31.299207 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_32000.caffemodel
I0831 16:57:32.104914 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_32000.solverstate
I0831 16:57:32.317623 12026 solver.cpp:337] Iteration 32000, Testing net (#0)
I0831 16:57:39.795146 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.768571
I0831 16:57:39.795220 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988285
I0831 16:57:39.795253 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.654439 (* 1 = 0.654439 loss)
I0831 16:57:39.795274 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.1859 (* 0.1 = 0.31859 loss)
I0831 16:57:39.911818 12026 solver.cpp:228] Iteration 32000, loss = 0.710963
I0831 16:57:39.911896 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.494842 (* 1 = 0.494842 loss)
I0831 16:57:39.911918 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.0111 (* 0.1 = 0.20111 loss)
I0831 16:57:39.911942 12026 sgd_solver.cpp:106] Iteration 32000, lr = 1e-05
I0831 16:58:20.232414 12026 solver.cpp:228] Iteration 32100, loss = 0.736181
I0831 16:58:20.232544 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.386911 (* 1 = 0.386911 loss)
I0831 16:58:20.232569 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08339 (* 0.1 = 0.208339 loss)
I0831 16:58:20.232592 12026 sgd_solver.cpp:106] Iteration 32100, lr = 1e-05
I0831 16:59:00.549990 12026 solver.cpp:228] Iteration 32200, loss = 0.738073
I0831 16:59:00.550169 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.502934 (* 1 = 0.502934 loss)
I0831 16:59:00.550194 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.07618 (* 0.1 = 0.207618 loss)
I0831 16:59:00.550217 12026 sgd_solver.cpp:106] Iteration 32200, lr = 1e-05
I0831 16:59:40.869356 12026 solver.cpp:228] Iteration 32300, loss = 0.772868
I0831 16:59:40.869519 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.61419 (* 1 = 0.61419 loss)
I0831 16:59:40.869544 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00173 (* 0.1 = 0.200173 loss)
I0831 16:59:40.869567 12026 sgd_solver.cpp:106] Iteration 32300, lr = 1e-05
I0831 17:00:21.193369 12026 solver.cpp:228] Iteration 32400, loss = 0.734464
I0831 17:00:21.193548 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.318469 (* 1 = 0.318469 loss)
I0831 17:00:21.193574 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.65532 (* 0.1 = 0.165532 loss)
I0831 17:00:21.193594 12026 sgd_solver.cpp:106] Iteration 32400, lr = 1e-05
I0831 17:01:01.517707 12026 solver.cpp:228] Iteration 32500, loss = 0.742664
I0831 17:01:01.517887 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.678147 (* 1 = 0.678147 loss)
I0831 17:01:01.517913 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.22778 (* 0.1 = 0.222778 loss)
I0831 17:01:01.517935 12026 sgd_solver.cpp:106] Iteration 32500, lr = 1e-05
I0831 17:01:41.839825 12026 solver.cpp:228] Iteration 32600, loss = 0.737457
I0831 17:01:41.839956 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.453763 (* 1 = 0.453763 loss)
I0831 17:01:41.839982 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.90001 (* 0.1 = 0.190001 loss)
I0831 17:01:41.840009 12026 sgd_solver.cpp:106] Iteration 32600, lr = 1e-05
I0831 17:02:22.156934 12026 solver.cpp:228] Iteration 32700, loss = 0.713327
I0831 17:02:22.157104 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.650135 (* 1 = 0.650135 loss)
I0831 17:02:22.157133 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.25969 (* 0.1 = 0.225969 loss)
I0831 17:02:22.157155 12026 sgd_solver.cpp:106] Iteration 32700, lr = 1e-05
I0831 17:03:02.479241 12026 solver.cpp:228] Iteration 32800, loss = 0.738792
I0831 17:03:02.479425 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.597845 (* 1 = 0.597845 loss)
I0831 17:03:02.479451 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.15611 (* 0.1 = 0.215611 loss)
I0831 17:03:02.479475 12026 sgd_solver.cpp:106] Iteration 32800, lr = 1e-05
I0831 17:03:42.797127 12026 solver.cpp:228] Iteration 32900, loss = 0.764697
I0831 17:03:42.797302 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.541814 (* 1 = 0.541814 loss)
I0831 17:03:42.797329 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.83015 (* 0.1 = 0.183015 loss)
I0831 17:03:42.797349 12026 sgd_solver.cpp:106] Iteration 32900, lr = 1e-05
I0831 17:04:22.738523 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_33000.caffemodel
I0831 17:04:23.556596 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_33000.solverstate
I0831 17:04:23.769939 12026 solver.cpp:337] Iteration 33000, Testing net (#0)
I0831 17:04:31.244735 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.776286
I0831 17:04:31.244813 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.989143
I0831 17:04:31.244844 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.656806 (* 1 = 0.656806 loss)
I0831 17:04:31.244866 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.20422 (* 0.1 = 0.320422 loss)
I0831 17:04:31.361572 12026 solver.cpp:228] Iteration 33000, loss = 0.773287
I0831 17:04:31.361651 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.558353 (* 1 = 0.558353 loss)
I0831 17:04:31.361675 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.18584 (* 0.1 = 0.218584 loss)
I0831 17:04:31.361701 12026 sgd_solver.cpp:106] Iteration 33000, lr = 1e-05
I0831 17:05:11.681473 12026 solver.cpp:228] Iteration 33100, loss = 0.72411
I0831 17:05:11.681718 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.35758 (* 1 = 0.35758 loss)
I0831 17:05:11.681746 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.0647 (* 0.1 = 0.20647 loss)
I0831 17:05:11.681767 12026 sgd_solver.cpp:106] Iteration 33100, lr = 1e-05
I0831 17:05:52.001299 12026 solver.cpp:228] Iteration 33200, loss = 0.743343
I0831 17:05:52.001473 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.432582 (* 1 = 0.432582 loss)
I0831 17:05:52.001499 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.99332 (* 0.1 = 0.199332 loss)
I0831 17:05:52.001521 12026 sgd_solver.cpp:106] Iteration 33200, lr = 1e-05
I0831 17:06:32.322314 12026 solver.cpp:228] Iteration 33300, loss = 0.729032
I0831 17:06:32.322526 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.543144 (* 1 = 0.543144 loss)
I0831 17:06:32.322553 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.16468 (* 0.1 = 0.216468 loss)
I0831 17:06:32.322574 12026 sgd_solver.cpp:106] Iteration 33300, lr = 1e-05
I0831 17:07:12.641860 12026 solver.cpp:228] Iteration 33400, loss = 0.741746
I0831 17:07:12.642033 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.341269 (* 1 = 0.341269 loss)
I0831 17:07:12.642060 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.75136 (* 0.1 = 0.175136 loss)
I0831 17:07:12.642082 12026 sgd_solver.cpp:106] Iteration 33400, lr = 1e-05
I0831 17:07:52.964678 12026 solver.cpp:228] Iteration 33500, loss = 0.746409
I0831 17:07:52.964805 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.515755 (* 1 = 0.515755 loss)
I0831 17:07:52.964830 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.5455 (* 0.1 = 0.25455 loss)
I0831 17:07:52.964853 12026 sgd_solver.cpp:106] Iteration 33500, lr = 1e-05
I0831 17:08:33.284992 12026 solver.cpp:228] Iteration 33600, loss = 0.763999
I0831 17:08:33.285166 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.410117 (* 1 = 0.410117 loss)
I0831 17:08:33.285192 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.94887 (* 0.1 = 0.194887 loss)
I0831 17:08:33.285212 12026 sgd_solver.cpp:106] Iteration 33600, lr = 1e-05
I0831 17:09:13.607102 12026 solver.cpp:228] Iteration 33700, loss = 0.745493
I0831 17:09:13.607349 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.429001 (* 1 = 0.429001 loss)
I0831 17:09:13.607383 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.39678 (* 0.1 = 0.239678 loss)
I0831 17:09:13.607408 12026 sgd_solver.cpp:106] Iteration 33700, lr = 1e-05
I0831 17:09:53.929296 12026 solver.cpp:228] Iteration 33800, loss = 0.717554
I0831 17:09:53.929493 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.824881 (* 1 = 0.824881 loss)
I0831 17:09:53.929520 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.29091 (* 0.1 = 0.229091 loss)
I0831 17:09:53.929539 12026 sgd_solver.cpp:106] Iteration 33800, lr = 1e-05
I0831 17:10:34.255398 12026 solver.cpp:228] Iteration 33900, loss = 0.750555
I0831 17:10:34.255580 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.576381 (* 1 = 0.576381 loss)
I0831 17:10:34.255605 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.15723 (* 0.1 = 0.215723 loss)
I0831 17:10:34.255627 12026 sgd_solver.cpp:106] Iteration 33900, lr = 1e-05
I0831 17:11:14.172201 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_34000.caffemodel
I0831 17:11:14.995530 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_34000.solverstate
I0831 17:11:15.210108 12026 solver.cpp:337] Iteration 34000, Testing net (#0)
I0831 17:11:22.682575 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.767714
I0831 17:11:22.682656 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988571
I0831 17:11:22.682680 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.652472 (* 1 = 0.652472 loss)
I0831 17:11:22.682703 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.24941 (* 0.1 = 0.324941 loss)
I0831 17:11:22.799062 12026 solver.cpp:228] Iteration 34000, loss = 0.733878
I0831 17:11:22.799136 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.399492 (* 1 = 0.399492 loss)
I0831 17:11:22.799160 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04781 (* 0.1 = 0.204781 loss)
I0831 17:11:22.799183 12026 sgd_solver.cpp:106] Iteration 34000, lr = 1e-05
I0831 17:12:03.119609 12026 solver.cpp:228] Iteration 34100, loss = 0.736046
I0831 17:12:03.119799 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.448469 (* 1 = 0.448469 loss)
I0831 17:12:03.119825 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89641 (* 0.1 = 0.189641 loss)
I0831 17:12:03.119848 12026 sgd_solver.cpp:106] Iteration 34100, lr = 1e-05
I0831 17:12:43.440265 12026 solver.cpp:228] Iteration 34200, loss = 0.743371
I0831 17:12:43.440439 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.502875 (* 1 = 0.502875 loss)
I0831 17:12:43.440465 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.24873 (* 0.1 = 0.224873 loss)
I0831 17:12:43.440485 12026 sgd_solver.cpp:106] Iteration 34200, lr = 1e-05
I0831 17:13:23.758711 12026 solver.cpp:228] Iteration 34300, loss = 0.758967
I0831 17:13:23.758898 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.597556 (* 1 = 0.597556 loss)
I0831 17:13:23.758924 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02413 (* 0.1 = 0.202413 loss)
I0831 17:13:23.758949 12026 sgd_solver.cpp:106] Iteration 34300, lr = 1e-05
I0831 17:14:04.087710 12026 solver.cpp:228] Iteration 34400, loss = 0.734949
I0831 17:14:04.087926 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.603287 (* 1 = 0.603287 loss)
I0831 17:14:04.087954 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30505 (* 0.1 = 0.230505 loss)
I0831 17:14:04.087975 12026 sgd_solver.cpp:106] Iteration 34400, lr = 1e-05
I0831 17:14:44.440609 12026 solver.cpp:228] Iteration 34500, loss = 0.736015
I0831 17:14:44.440840 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.486129 (* 1 = 0.486129 loss)
I0831 17:14:44.440867 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.80966 (* 0.1 = 0.180966 loss)
I0831 17:14:44.440889 12026 sgd_solver.cpp:106] Iteration 34500, lr = 1e-05
I0831 17:15:24.775687 12026 solver.cpp:228] Iteration 34600, loss = 0.730867
I0831 17:15:24.776003 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.400475 (* 1 = 0.400475 loss)
I0831 17:15:24.776031 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.75471 (* 0.1 = 0.175471 loss)
I0831 17:15:24.776055 12026 sgd_solver.cpp:106] Iteration 34600, lr = 1e-05
I0831 17:16:05.110112 12026 solver.cpp:228] Iteration 34700, loss = 0.716859
I0831 17:16:05.110273 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.411642 (* 1 = 0.411642 loss)
I0831 17:16:05.110299 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.78921 (* 0.1 = 0.178921 loss)
I0831 17:16:05.110323 12026 sgd_solver.cpp:106] Iteration 34700, lr = 1e-05
I0831 17:16:45.482669 12026 solver.cpp:228] Iteration 34800, loss = 0.727365
I0831 17:16:45.482978 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.455615 (* 1 = 0.455615 loss)
I0831 17:16:45.483008 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.99617 (* 0.1 = 0.199617 loss)
I0831 17:16:45.483022 12026 sgd_solver.cpp:106] Iteration 34800, lr = 1e-05
I0831 17:17:25.825250 12026 solver.cpp:228] Iteration 34900, loss = 0.752364
I0831 17:17:25.825476 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.406125 (* 1 = 0.406125 loss)
I0831 17:17:25.825512 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.86743 (* 0.1 = 0.186743 loss)
I0831 17:17:25.825542 12026 sgd_solver.cpp:106] Iteration 34900, lr = 1e-05
I0831 17:18:05.772737 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_35000.caffemodel
I0831 17:18:06.585137 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_35000.solverstate
I0831 17:18:06.799391 12026 solver.cpp:337] Iteration 35000, Testing net (#0)
I0831 17:18:14.276296 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.778286
I0831 17:18:14.276373 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.987714
I0831 17:18:14.276399 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.657509 (* 1 = 0.657509 loss)
I0831 17:18:14.276420 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.13052 (* 0.1 = 0.313052 loss)
I0831 17:18:14.392689 12026 solver.cpp:228] Iteration 35000, loss = 0.748897
I0831 17:18:14.392776 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.466675 (* 1 = 0.466675 loss)
I0831 17:18:14.392797 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3614 (* 0.1 = 0.23614 loss)
I0831 17:18:14.392822 12026 sgd_solver.cpp:106] Iteration 35000, lr = 1e-05
I0831 17:18:54.706524 12026 solver.cpp:228] Iteration 35100, loss = 0.728756
I0831 17:18:54.706652 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.528785 (* 1 = 0.528785 loss)
I0831 17:18:54.706678 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.52043 (* 0.1 = 0.252043 loss)
I0831 17:18:54.706701 12026 sgd_solver.cpp:106] Iteration 35100, lr = 1e-05
I0831 17:19:35.021309 12026 solver.cpp:228] Iteration 35200, loss = 0.763539
I0831 17:19:35.021484 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.6768 (* 1 = 0.6768 loss)
I0831 17:19:35.021510 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42406 (* 0.1 = 0.242406 loss)
I0831 17:19:35.021531 12026 sgd_solver.cpp:106] Iteration 35200, lr = 1e-05
I0831 17:20:15.344861 12026 solver.cpp:228] Iteration 35300, loss = 0.723374
I0831 17:20:15.345073 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.507104 (* 1 = 0.507104 loss)
I0831 17:20:15.345100 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.19063 (* 0.1 = 0.219063 loss)
I0831 17:20:15.345122 12026 sgd_solver.cpp:106] Iteration 35300, lr = 1e-05
I0831 17:20:55.664053 12026 solver.cpp:228] Iteration 35400, loss = 0.705167
I0831 17:20:55.664235 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.752368 (* 1 = 0.752368 loss)
I0831 17:20:55.664260 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.53331 (* 0.1 = 0.253331 loss)
I0831 17:20:55.664283 12026 sgd_solver.cpp:106] Iteration 35400, lr = 1e-05
I0831 17:21:35.977417 12026 solver.cpp:228] Iteration 35500, loss = 0.734947
I0831 17:21:35.977607 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.272535 (* 1 = 0.272535 loss)
I0831 17:21:35.977632 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.70579 (* 0.1 = 0.170579 loss)
I0831 17:21:35.977653 12026 sgd_solver.cpp:106] Iteration 35500, lr = 1e-05
I0831 17:22:16.285473 12026 solver.cpp:228] Iteration 35600, loss = 0.75885
I0831 17:22:16.285689 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.867986 (* 1 = 0.867986 loss)
I0831 17:22:16.285717 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.12195 (* 0.1 = 0.212195 loss)
I0831 17:22:16.285737 12026 sgd_solver.cpp:106] Iteration 35600, lr = 1e-05
I0831 17:22:56.603991 12026 solver.cpp:228] Iteration 35700, loss = 0.750639
I0831 17:22:56.604121 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.561204 (* 1 = 0.561204 loss)
I0831 17:22:56.604146 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98869 (* 0.1 = 0.198869 loss)
I0831 17:22:56.604167 12026 sgd_solver.cpp:106] Iteration 35700, lr = 1e-05
I0831 17:23:36.916844 12026 solver.cpp:228] Iteration 35800, loss = 0.717102
I0831 17:23:36.917032 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.53027 (* 1 = 0.53027 loss)
I0831 17:23:36.917059 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.07084 (* 0.1 = 0.207084 loss)
I0831 17:23:36.917080 12026 sgd_solver.cpp:106] Iteration 35800, lr = 1e-05
I0831 17:24:17.236712 12026 solver.cpp:228] Iteration 35900, loss = 0.750878
I0831 17:24:17.236933 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.331123 (* 1 = 0.331123 loss)
I0831 17:24:17.236960 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.02756 (* 0.1 = 0.202756 loss)
I0831 17:24:17.236979 12026 sgd_solver.cpp:106] Iteration 35900, lr = 1e-05
I0831 17:24:57.150079 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_36000.caffemodel
I0831 17:24:57.965890 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_36000.solverstate
I0831 17:24:58.181629 12026 solver.cpp:337] Iteration 36000, Testing net (#0)
I0831 17:25:05.659377 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.769714
I0831 17:25:05.659452 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988857
I0831 17:25:05.659484 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.6459 (* 1 = 0.6459 loss)
I0831 17:25:05.659507 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.17786 (* 0.1 = 0.317786 loss)
I0831 17:25:05.776504 12026 solver.cpp:228] Iteration 36000, loss = 0.719903
I0831 17:25:05.776584 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.629941 (* 1 = 0.629941 loss)
I0831 17:25:05.776608 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.3509 (* 0.1 = 0.23509 loss)
I0831 17:25:05.776634 12026 sgd_solver.cpp:106] Iteration 36000, lr = 1e-05
I0831 17:25:46.093260 12026 solver.cpp:228] Iteration 36100, loss = 0.718119
I0831 17:25:46.093436 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.587519 (* 1 = 0.587519 loss)
I0831 17:25:46.093463 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11644 (* 0.1 = 0.211644 loss)
I0831 17:25:46.093485 12026 sgd_solver.cpp:106] Iteration 36100, lr = 1e-05
I0831 17:26:26.405164 12026 solver.cpp:228] Iteration 36200, loss = 0.736395
I0831 17:26:26.405354 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.802805 (* 1 = 0.802805 loss)
I0831 17:26:26.405380 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.13159 (* 0.1 = 0.213159 loss)
I0831 17:26:26.405398 12026 sgd_solver.cpp:106] Iteration 36200, lr = 1e-05
I0831 17:27:06.723055 12026 solver.cpp:228] Iteration 36300, loss = 0.739401
I0831 17:27:06.723294 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.491769 (* 1 = 0.491769 loss)
I0831 17:27:06.723321 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.07488 (* 0.1 = 0.207488 loss)
I0831 17:27:06.723352 12026 sgd_solver.cpp:106] Iteration 36300, lr = 1e-05
I0831 17:27:47.039933 12026 solver.cpp:228] Iteration 36400, loss = 0.74593
I0831 17:27:47.040084 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.567779 (* 1 = 0.567779 loss)
I0831 17:27:47.040110 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.40752 (* 0.1 = 0.240752 loss)
I0831 17:27:47.040130 12026 sgd_solver.cpp:106] Iteration 36400, lr = 1e-05
I0831 17:28:27.359617 12026 solver.cpp:228] Iteration 36500, loss = 0.716069
I0831 17:28:27.359802 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.43964 (* 1 = 0.43964 loss)
I0831 17:28:27.359828 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.90811 (* 0.1 = 0.190811 loss)
I0831 17:28:27.359853 12026 sgd_solver.cpp:106] Iteration 36500, lr = 1e-05
I0831 17:29:07.672379 12026 solver.cpp:228] Iteration 36600, loss = 0.743518
I0831 17:29:07.672556 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.496478 (* 1 = 0.496478 loss)
I0831 17:29:07.672581 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.37473 (* 0.1 = 0.237473 loss)
I0831 17:29:07.672601 12026 sgd_solver.cpp:106] Iteration 36600, lr = 1e-05
I0831 17:29:47.983220 12026 solver.cpp:228] Iteration 36700, loss = 0.71383
I0831 17:29:47.983404 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.637762 (* 1 = 0.637762 loss)
I0831 17:29:47.983433 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.03003 (* 0.1 = 0.203003 loss)
I0831 17:29:47.983453 12026 sgd_solver.cpp:106] Iteration 36700, lr = 1e-05
I0831 17:30:28.302815 12026 solver.cpp:228] Iteration 36800, loss = 0.728942
I0831 17:30:28.303073 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.746106 (* 1 = 0.746106 loss)
I0831 17:30:28.303099 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21224 (* 0.1 = 0.221224 loss)
I0831 17:30:28.303120 12026 sgd_solver.cpp:106] Iteration 36800, lr = 1e-05
I0831 17:31:08.621225 12026 solver.cpp:228] Iteration 36900, loss = 0.72936
I0831 17:31:08.621417 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.437231 (* 1 = 0.437231 loss)
I0831 17:31:08.621443 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.8659 (* 0.1 = 0.18659 loss)
I0831 17:31:08.621464 12026 sgd_solver.cpp:106] Iteration 36900, lr = 1e-05
I0831 17:31:48.536546 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_37000.caffemodel
I0831 17:31:49.347532 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_37000.solverstate
I0831 17:31:49.561601 12026 solver.cpp:337] Iteration 37000, Testing net (#0)
I0831 17:31:57.038300 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.780286
I0831 17:31:57.038377 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988
I0831 17:31:57.038410 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.65674 (* 1 = 0.65674 loss)
I0831 17:31:57.038432 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.18805 (* 0.1 = 0.318805 loss)
I0831 17:31:57.154685 12026 solver.cpp:228] Iteration 37000, loss = 0.749417
I0831 17:31:57.154759 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.391184 (* 1 = 0.391184 loss)
I0831 17:31:57.154789 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.95535 (* 0.1 = 0.195535 loss)
I0831 17:31:57.154815 12026 sgd_solver.cpp:106] Iteration 37000, lr = 1e-05
I0831 17:32:37.475466 12026 solver.cpp:228] Iteration 37100, loss = 0.715428
I0831 17:32:37.475689 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.427171 (* 1 = 0.427171 loss)
I0831 17:32:37.475716 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.88853 (* 0.1 = 0.188853 loss)
I0831 17:32:37.475739 12026 sgd_solver.cpp:106] Iteration 37100, lr = 1e-05
I0831 17:33:17.792951 12026 solver.cpp:228] Iteration 37200, loss = 0.741159
I0831 17:33:17.793205 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.655059 (* 1 = 0.655059 loss)
I0831 17:33:17.793234 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08372 (* 0.1 = 0.208372 loss)
I0831 17:33:17.793254 12026 sgd_solver.cpp:106] Iteration 37200, lr = 1e-05
I0831 17:33:58.106552 12026 solver.cpp:228] Iteration 37300, loss = 0.726987
I0831 17:33:58.106742 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.285788 (* 1 = 0.285788 loss)
I0831 17:33:58.106770 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.62479 (* 0.1 = 0.162479 loss)
I0831 17:33:58.106797 12026 sgd_solver.cpp:106] Iteration 37300, lr = 1e-05
I0831 17:34:38.454591 12026 solver.cpp:228] Iteration 37400, loss = 0.690497
I0831 17:34:38.454843 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.376427 (* 1 = 0.376427 loss)
I0831 17:34:38.454869 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.84729 (* 0.1 = 0.184729 loss)
I0831 17:34:38.454888 12026 sgd_solver.cpp:106] Iteration 37400, lr = 1e-05
I0831 17:35:18.783375 12026 solver.cpp:228] Iteration 37500, loss = 0.72353
I0831 17:35:18.783618 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.407249 (* 1 = 0.407249 loss)
I0831 17:35:18.783645 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11667 (* 0.1 = 0.211667 loss)
I0831 17:35:18.783670 12026 sgd_solver.cpp:106] Iteration 37500, lr = 1e-05
I0831 17:35:59.113293 12026 solver.cpp:228] Iteration 37600, loss = 0.737205
I0831 17:35:59.113538 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.521211 (* 1 = 0.521211 loss)
I0831 17:35:59.113564 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.33119 (* 0.1 = 0.233119 loss)
I0831 17:35:59.113586 12026 sgd_solver.cpp:106] Iteration 37600, lr = 1e-05
I0831 17:36:39.449918 12026 solver.cpp:228] Iteration 37700, loss = 0.756744
I0831 17:36:39.450129 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.428535 (* 1 = 0.428535 loss)
I0831 17:36:39.450156 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.95433 (* 0.1 = 0.195433 loss)
I0831 17:36:39.450179 12026 sgd_solver.cpp:106] Iteration 37700, lr = 1e-05
I0831 17:37:19.777230 12026 solver.cpp:228] Iteration 37800, loss = 0.711653
I0831 17:37:19.777439 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.488035 (* 1 = 0.488035 loss)
I0831 17:37:19.777467 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.64441 (* 0.1 = 0.264441 loss)
I0831 17:37:19.777487 12026 sgd_solver.cpp:106] Iteration 37800, lr = 1e-05
I0831 17:38:00.096086 12026 solver.cpp:228] Iteration 37900, loss = 0.733473
I0831 17:38:00.096254 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.59797 (* 1 = 0.59797 loss)
I0831 17:38:00.096280 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.46477 (* 0.1 = 0.246477 loss)
I0831 17:38:00.096305 12026 sgd_solver.cpp:106] Iteration 37900, lr = 1e-05
I0831 17:38:40.014266 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_38000.caffemodel
I0831 17:38:40.748533 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_38000.solverstate
I0831 17:38:40.942695 12026 solver.cpp:337] Iteration 38000, Testing net (#0)
I0831 17:38:48.416992 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.768286
I0831 17:38:48.417078 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.989714
I0831 17:38:48.417112 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.645511 (* 1 = 0.645511 loss)
I0831 17:38:48.417138 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.13542 (* 0.1 = 0.313542 loss)
I0831 17:38:48.534065 12026 solver.cpp:228] Iteration 38000, loss = 0.717661
I0831 17:38:48.534152 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.407177 (* 1 = 0.407177 loss)
I0831 17:38:48.534178 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.86924 (* 0.1 = 0.186924 loss)
I0831 17:38:48.534204 12026 sgd_solver.cpp:106] Iteration 38000, lr = 1e-05
I0831 17:39:28.852485 12026 solver.cpp:228] Iteration 38100, loss = 0.698055
I0831 17:39:28.852807 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.546529 (* 1 = 0.546529 loss)
I0831 17:39:28.852834 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.82121 (* 0.1 = 0.182121 loss)
I0831 17:39:28.852855 12026 sgd_solver.cpp:106] Iteration 38100, lr = 1e-05
I0831 17:40:09.160950 12026 solver.cpp:228] Iteration 38200, loss = 0.730531
I0831 17:40:09.161154 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.422649 (* 1 = 0.422649 loss)
I0831 17:40:09.161180 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.81596 (* 0.1 = 0.181596 loss)
I0831 17:40:09.161201 12026 sgd_solver.cpp:106] Iteration 38200, lr = 1e-05
I0831 17:40:49.473091 12026 solver.cpp:228] Iteration 38300, loss = 0.757153
I0831 17:40:49.473295 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.455362 (* 1 = 0.455362 loss)
I0831 17:40:49.473322 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.4909 (* 0.1 = 0.24909 loss)
I0831 17:40:49.473343 12026 sgd_solver.cpp:106] Iteration 38300, lr = 1e-05
I0831 17:41:29.790068 12026 solver.cpp:228] Iteration 38400, loss = 0.743934
I0831 17:41:29.790282 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.606369 (* 1 = 0.606369 loss)
I0831 17:41:29.790308 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.34117 (* 0.1 = 0.234117 loss)
I0831 17:41:29.790329 12026 sgd_solver.cpp:106] Iteration 38400, lr = 1e-05
I0831 17:42:10.106541 12026 solver.cpp:228] Iteration 38500, loss = 0.697111
I0831 17:42:10.106763 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.389676 (* 1 = 0.389676 loss)
I0831 17:42:10.106793 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.95199 (* 0.1 = 0.195199 loss)
I0831 17:42:10.106808 12026 sgd_solver.cpp:106] Iteration 38500, lr = 1e-05
I0831 17:42:50.437352 12026 solver.cpp:228] Iteration 38600, loss = 0.745145
I0831 17:42:50.437543 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.729687 (* 1 = 0.729687 loss)
I0831 17:42:50.437571 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92039 (* 0.1 = 0.192039 loss)
I0831 17:42:50.437592 12026 sgd_solver.cpp:106] Iteration 38600, lr = 1e-05
I0831 17:43:30.759654 12026 solver.cpp:228] Iteration 38700, loss = 0.727085
I0831 17:43:30.759858 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.585065 (* 1 = 0.585065 loss)
I0831 17:43:30.759884 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00955 (* 0.1 = 0.200955 loss)
I0831 17:43:30.759912 12026 sgd_solver.cpp:106] Iteration 38700, lr = 1e-05
I0831 17:44:11.077806 12026 solver.cpp:228] Iteration 38800, loss = 0.715627
I0831 17:44:11.078011 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.5219 (* 1 = 0.5219 loss)
I0831 17:44:11.078037 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.7277 (* 0.1 = 0.17277 loss)
I0831 17:44:11.078061 12026 sgd_solver.cpp:106] Iteration 38800, lr = 1e-05
I0831 17:44:51.411593 12026 solver.cpp:228] Iteration 38900, loss = 0.730776
I0831 17:44:51.411813 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.576569 (* 1 = 0.576569 loss)
I0831 17:44:51.411841 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89835 (* 0.1 = 0.189835 loss)
I0831 17:44:51.411865 12026 sgd_solver.cpp:106] Iteration 38900, lr = 1e-05
I0831 17:45:31.342680 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_39000.caffemodel
I0831 17:45:32.075754 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_39000.solverstate
I0831 17:45:32.268954 12026 solver.cpp:337] Iteration 39000, Testing net (#0)
I0831 17:45:39.741369 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.779714
I0831 17:45:39.741474 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988
I0831 17:45:39.741503 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.658776 (* 1 = 0.658776 loss)
I0831 17:45:39.741524 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.17019 (* 0.1 = 0.317019 loss)
I0831 17:45:39.857779 12026 solver.cpp:228] Iteration 39000, loss = 0.752242
I0831 17:45:39.857861 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.742393 (* 1 = 0.742393 loss)
I0831 17:45:39.857888 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.38631 (* 0.1 = 0.238631 loss)
I0831 17:45:39.857921 12026 sgd_solver.cpp:106] Iteration 39000, lr = 1e-05
I0831 17:46:20.191887 12026 solver.cpp:228] Iteration 39100, loss = 0.723533
I0831 17:46:20.192145 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.379495 (* 1 = 0.379495 loss)
I0831 17:46:20.192173 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.58898 (* 0.1 = 0.158898 loss)
I0831 17:46:20.192195 12026 sgd_solver.cpp:106] Iteration 39100, lr = 1e-05
I0831 17:47:00.517573 12026 solver.cpp:228] Iteration 39200, loss = 0.729795
I0831 17:47:00.517789 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.54681 (* 1 = 0.54681 loss)
I0831 17:47:00.517817 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.95546 (* 0.1 = 0.195546 loss)
I0831 17:47:00.517839 12026 sgd_solver.cpp:106] Iteration 39200, lr = 1e-05
I0831 17:47:40.832345 12026 solver.cpp:228] Iteration 39300, loss = 0.734954
I0831 17:47:40.832597 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.438501 (* 1 = 0.438501 loss)
I0831 17:47:40.832624 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.74619 (* 0.1 = 0.174619 loss)
I0831 17:47:40.832651 12026 sgd_solver.cpp:106] Iteration 39300, lr = 1e-05
I0831 17:48:21.147094 12026 solver.cpp:228] Iteration 39400, loss = 0.694593
I0831 17:48:21.147320 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.483923 (* 1 = 0.483923 loss)
I0831 17:48:21.147348 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.88405 (* 0.1 = 0.188405 loss)
I0831 17:48:21.147368 12026 sgd_solver.cpp:106] Iteration 39400, lr = 1e-05
I0831 17:49:01.466004 12026 solver.cpp:228] Iteration 39500, loss = 0.715056
I0831 17:49:01.466231 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.572917 (* 1 = 0.572917 loss)
I0831 17:49:01.466259 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.31181 (* 0.1 = 0.231181 loss)
I0831 17:49:01.466280 12026 sgd_solver.cpp:106] Iteration 39500, lr = 1e-05
I0831 17:49:41.786636 12026 solver.cpp:228] Iteration 39600, loss = 0.745433
I0831 17:49:41.786911 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.668513 (* 1 = 0.668513 loss)
I0831 17:49:41.786948 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89232 (* 0.1 = 0.189232 loss)
I0831 17:49:41.786969 12026 sgd_solver.cpp:106] Iteration 39600, lr = 1e-05
I0831 17:50:22.107558 12026 solver.cpp:228] Iteration 39700, loss = 0.742287
I0831 17:50:22.107774 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.385196 (* 1 = 0.385196 loss)
I0831 17:50:22.107802 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.71043 (* 0.1 = 0.171043 loss)
I0831 17:50:22.107828 12026 sgd_solver.cpp:106] Iteration 39700, lr = 1e-05
I0831 17:51:02.430521 12026 solver.cpp:228] Iteration 39800, loss = 0.716263
I0831 17:51:02.430806 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.537037 (* 1 = 0.537037 loss)
I0831 17:51:02.430836 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.12058 (* 0.1 = 0.212058 loss)
I0831 17:51:02.430851 12026 sgd_solver.cpp:106] Iteration 39800, lr = 1e-05
I0831 17:51:42.760445 12026 solver.cpp:228] Iteration 39900, loss = 0.734479
I0831 17:51:42.760709 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.476556 (* 1 = 0.476556 loss)
I0831 17:51:42.760735 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.81331 (* 0.1 = 0.181331 loss)
I0831 17:51:42.760758 12026 sgd_solver.cpp:106] Iteration 39900, lr = 1e-05
I0831 17:52:22.683681 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_40000.caffemodel
I0831 17:52:23.421344 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_40000.solverstate
I0831 17:52:23.632318 12026 solver.cpp:337] Iteration 40000, Testing net (#0)
I0831 17:52:31.118451 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.772
I0831 17:52:31.118537 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.989143
I0831 17:52:31.118571 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.646285 (* 1 = 0.646285 loss)
I0831 17:52:31.118593 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.2021 (* 0.1 = 0.32021 loss)
I0831 17:52:31.235891 12026 solver.cpp:228] Iteration 40000, loss = 0.730534
I0831 17:52:31.235981 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.311776 (* 1 = 0.311776 loss)
I0831 17:52:31.236004 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.76886 (* 0.1 = 0.176886 loss)
I0831 17:52:31.236027 12026 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 2
I0831 17:52:31.236096 12026 sgd_solver.cpp:106] Iteration 40000, lr = 1e-06
I0831 17:53:11.557246 12026 solver.cpp:228] Iteration 40100, loss = 0.679464
I0831 17:53:11.557462 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.736331 (* 1 = 0.736331 loss)
I0831 17:53:11.557489 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.30045 (* 0.1 = 0.230045 loss)
I0831 17:53:11.557510 12026 sgd_solver.cpp:106] Iteration 40100, lr = 1e-06
I0831 17:53:51.875995 12026 solver.cpp:228] Iteration 40200, loss = 0.721971
I0831 17:53:51.876194 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.515997 (* 1 = 0.515997 loss)
I0831 17:53:51.876220 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.91057 (* 0.1 = 0.191057 loss)
I0831 17:53:51.876242 12026 sgd_solver.cpp:106] Iteration 40200, lr = 1e-06
I0831 17:54:32.197170 12026 solver.cpp:228] Iteration 40300, loss = 0.733509
I0831 17:54:32.197324 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.498902 (* 1 = 0.498902 loss)
I0831 17:54:32.197351 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.75965 (* 0.1 = 0.175965 loss)
I0831 17:54:32.197372 12026 sgd_solver.cpp:106] Iteration 40300, lr = 1e-06
I0831 17:55:12.526545 12026 solver.cpp:228] Iteration 40400, loss = 0.756556
I0831 17:55:12.526787 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.674386 (* 1 = 0.674386 loss)
I0831 17:55:12.526818 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.04951 (* 0.1 = 0.204951 loss)
I0831 17:55:12.526831 12026 sgd_solver.cpp:106] Iteration 40400, lr = 1e-06
I0831 17:55:52.855918 12026 solver.cpp:228] Iteration 40500, loss = 0.694881
I0831 17:55:52.856101 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.407319 (* 1 = 0.407319 loss)
I0831 17:55:52.856127 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.78502 (* 0.1 = 0.178502 loss)
I0831 17:55:52.856148 12026 sgd_solver.cpp:106] Iteration 40500, lr = 1e-06
I0831 17:56:33.182217 12026 solver.cpp:228] Iteration 40600, loss = 0.726006
I0831 17:56:33.182458 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.404811 (* 1 = 0.404811 loss)
I0831 17:56:33.182487 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.82023 (* 0.1 = 0.182023 loss)
I0831 17:56:33.182512 12026 sgd_solver.cpp:106] Iteration 40600, lr = 1e-06
I0831 17:57:13.525635 12026 solver.cpp:228] Iteration 40700, loss = 0.707118
I0831 17:57:13.525825 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.582826 (* 1 = 0.582826 loss)
I0831 17:57:13.525852 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08402 (* 0.1 = 0.208402 loss)
I0831 17:57:13.525877 12026 sgd_solver.cpp:106] Iteration 40700, lr = 1e-06
I0831 17:57:53.849390 12026 solver.cpp:228] Iteration 40800, loss = 0.698618
I0831 17:57:53.849649 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.604125 (* 1 = 0.604125 loss)
I0831 17:57:53.849676 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.41628 (* 0.1 = 0.241628 loss)
I0831 17:57:53.849699 12026 sgd_solver.cpp:106] Iteration 40800, lr = 1e-06
I0831 17:58:34.191215 12026 solver.cpp:228] Iteration 40900, loss = 0.71321
I0831 17:58:34.191447 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.609512 (* 1 = 0.609512 loss)
I0831 17:58:34.191475 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28791 (* 0.1 = 0.228791 loss)
I0831 17:58:34.191498 12026 sgd_solver.cpp:106] Iteration 40900, lr = 1e-06
I0831 17:59:14.109910 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_41000.caffemodel
I0831 17:59:14.845029 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_41000.solverstate
I0831 17:59:15.039394 12026 solver.cpp:337] Iteration 41000, Testing net (#0)
I0831 17:59:22.514166 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.783143
I0831 17:59:22.514263 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988857
I0831 17:59:22.514291 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.651272 (* 1 = 0.651272 loss)
I0831 17:59:22.514312 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.09232 (* 0.1 = 0.309233 loss)
I0831 17:59:22.631618 12026 solver.cpp:228] Iteration 41000, loss = 0.743726
I0831 17:59:22.631711 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.45878 (* 1 = 0.45878 loss)
I0831 17:59:22.631733 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.06248 (* 0.1 = 0.206248 loss)
I0831 17:59:22.631759 12026 sgd_solver.cpp:106] Iteration 41000, lr = 1e-06
I0831 18:00:02.944242 12026 solver.cpp:228] Iteration 41100, loss = 0.730282
I0831 18:00:02.944435 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.480028 (* 1 = 0.480028 loss)
I0831 18:00:02.944463 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.58726 (* 0.1 = 0.158726 loss)
I0831 18:00:02.944488 12026 sgd_solver.cpp:106] Iteration 41100, lr = 1e-06
I0831 18:00:43.277248 12026 solver.cpp:228] Iteration 41200, loss = 0.709267
I0831 18:00:43.277438 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.260172 (* 1 = 0.260172 loss)
I0831 18:00:43.277465 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.5326 (* 0.1 = 0.15326 loss)
I0831 18:00:43.277487 12026 sgd_solver.cpp:106] Iteration 41200, lr = 1e-06
I0831 18:01:23.590559 12026 solver.cpp:228] Iteration 41300, loss = 0.721979
I0831 18:01:23.590888 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.434957 (* 1 = 0.434957 loss)
I0831 18:01:23.590941 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.79824 (* 0.1 = 0.179824 loss)
I0831 18:01:23.590991 12026 sgd_solver.cpp:106] Iteration 41300, lr = 1e-06
I0831 18:02:12.213873 12026 solver.cpp:228] Iteration 41400, loss = 0.688809
I0831 18:02:12.214062 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.408904 (* 1 = 0.408904 loss)
I0831 18:02:12.214089 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.81724 (* 0.1 = 0.181724 loss)
I0831 18:02:12.214110 12026 sgd_solver.cpp:106] Iteration 41400, lr = 1e-06
I0831 18:03:24.195293 12026 solver.cpp:228] Iteration 41500, loss = 0.726197
I0831 18:03:24.195487 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.387293 (* 1 = 0.387293 loss)
I0831 18:03:24.195513 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92663 (* 0.1 = 0.192663 loss)
I0831 18:03:24.195538 12026 sgd_solver.cpp:106] Iteration 41500, lr = 1e-06
I0831 18:04:36.236822 12026 solver.cpp:228] Iteration 41600, loss = 0.721597
I0831 18:04:36.236999 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.503767 (* 1 = 0.503767 loss)
I0831 18:04:36.237025 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.77176 (* 0.1 = 0.177176 loss)
I0831 18:04:36.237047 12026 sgd_solver.cpp:106] Iteration 41600, lr = 1e-06
I0831 18:05:48.291605 12026 solver.cpp:228] Iteration 41700, loss = 0.744094
I0831 18:05:48.291909 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.381946 (* 1 = 0.381946 loss)
I0831 18:05:48.291939 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.07864 (* 0.1 = 0.207864 loss)
I0831 18:05:48.291968 12026 sgd_solver.cpp:106] Iteration 41700, lr = 1e-06
I0831 18:06:57.406189 12026 solver.cpp:228] Iteration 41800, loss = 0.715795
I0831 18:06:57.406510 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.385125 (* 1 = 0.385125 loss)
I0831 18:06:57.406568 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89269 (* 0.1 = 0.189269 loss)
I0831 18:06:57.406620 12026 sgd_solver.cpp:106] Iteration 41800, lr = 1e-06
I0831 18:07:37.713508 12026 solver.cpp:228] Iteration 41900, loss = 0.698986
I0831 18:07:37.713737 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.353115 (* 1 = 0.353115 loss)
I0831 18:07:37.713762 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.52766 (* 0.1 = 0.152766 loss)
I0831 18:07:37.713794 12026 sgd_solver.cpp:106] Iteration 41900, lr = 1e-06
I0831 18:08:17.631969 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_42000.caffemodel
I0831 18:08:18.370146 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_42000.solverstate
I0831 18:08:18.565187 12026 solver.cpp:337] Iteration 42000, Testing net (#0)
I0831 18:08:25.962955 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.773429
I0831 18:08:25.963078 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988571
I0831 18:08:25.963105 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.641387 (* 1 = 0.641387 loss)
I0831 18:08:25.963126 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.13632 (* 0.1 = 0.313632 loss)
I0831 18:08:26.080234 12026 solver.cpp:228] Iteration 42000, loss = 0.723332
I0831 18:08:26.080325 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.542359 (* 1 = 0.542359 loss)
I0831 18:08:26.080349 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.06764 (* 0.1 = 0.206764 loss)
I0831 18:08:26.080375 12026 sgd_solver.cpp:106] Iteration 42000, lr = 1e-06
I0831 18:09:06.396562 12026 solver.cpp:228] Iteration 42100, loss = 0.676993
I0831 18:09:06.396770 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.649278 (* 1 = 0.649278 loss)
I0831 18:09:06.396797 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98568 (* 0.1 = 0.198568 loss)
I0831 18:09:06.396819 12026 sgd_solver.cpp:106] Iteration 42100, lr = 1e-06
I0831 18:09:46.718088 12026 solver.cpp:228] Iteration 42200, loss = 0.708328
I0831 18:09:46.718243 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.427595 (* 1 = 0.427595 loss)
I0831 18:09:46.718269 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92743 (* 0.1 = 0.192743 loss)
I0831 18:09:46.718291 12026 sgd_solver.cpp:106] Iteration 42200, lr = 1e-06
I0831 18:10:27.056507 12026 solver.cpp:228] Iteration 42300, loss = 0.729325
I0831 18:10:27.056649 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.575232 (* 1 = 0.575232 loss)
I0831 18:10:27.056675 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.91714 (* 0.1 = 0.191714 loss)
I0831 18:10:27.056696 12026 sgd_solver.cpp:106] Iteration 42300, lr = 1e-06
I0831 18:11:07.368516 12026 solver.cpp:228] Iteration 42400, loss = 0.745395
I0831 18:11:07.368721 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.568434 (* 1 = 0.568434 loss)
I0831 18:11:07.368748 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05971 (* 0.1 = 0.205971 loss)
I0831 18:11:07.368769 12026 sgd_solver.cpp:106] Iteration 42400, lr = 1e-06
I0831 18:11:47.675994 12026 solver.cpp:228] Iteration 42500, loss = 0.712713
I0831 18:11:47.676251 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.607944 (* 1 = 0.607944 loss)
I0831 18:11:47.676291 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.13791 (* 0.1 = 0.213791 loss)
I0831 18:11:47.676313 12026 sgd_solver.cpp:106] Iteration 42500, lr = 1e-06
I0831 18:12:27.992427 12026 solver.cpp:228] Iteration 42600, loss = 0.717184
I0831 18:12:27.992624 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.505741 (* 1 = 0.505741 loss)
I0831 18:12:27.992650 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.93167 (* 0.1 = 0.193167 loss)
I0831 18:12:27.992672 12026 sgd_solver.cpp:106] Iteration 42600, lr = 1e-06
I0831 18:13:08.317189 12026 solver.cpp:228] Iteration 42700, loss = 0.702783
I0831 18:13:08.317394 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.536963 (* 1 = 0.536963 loss)
I0831 18:13:08.317420 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.90279 (* 0.1 = 0.190279 loss)
I0831 18:13:08.317445 12026 sgd_solver.cpp:106] Iteration 42700, lr = 1e-06
I0831 18:13:48.623899 12026 solver.cpp:228] Iteration 42800, loss = 0.673401
I0831 18:13:48.624131 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.57877 (* 1 = 0.57877 loss)
I0831 18:13:48.624159 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42243 (* 0.1 = 0.242243 loss)
I0831 18:13:48.624181 12026 sgd_solver.cpp:106] Iteration 42800, lr = 1e-06
I0831 18:14:28.933749 12026 solver.cpp:228] Iteration 42900, loss = 0.721385
I0831 18:14:28.933929 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.547736 (* 1 = 0.547736 loss)
I0831 18:14:28.933955 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.87134 (* 0.1 = 0.187134 loss)
I0831 18:14:28.933976 12026 sgd_solver.cpp:106] Iteration 42900, lr = 1e-06
I0831 18:15:08.844297 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_43000.caffemodel
I0831 18:15:09.579524 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_43000.solverstate
I0831 18:15:09.768051 12026 solver.cpp:337] Iteration 43000, Testing net (#0)
I0831 18:15:17.250888 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.782286
I0831 18:15:17.250988 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988571
I0831 18:15:17.251016 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.651362 (* 1 = 0.651362 loss)
I0831 18:15:17.251037 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.0841 (* 0.1 = 0.30841 loss)
I0831 18:15:17.369096 12026 solver.cpp:228] Iteration 43000, loss = 0.750283
I0831 18:15:17.369199 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.373632 (* 1 = 0.373632 loss)
I0831 18:15:17.369222 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.74299 (* 0.1 = 0.174299 loss)
I0831 18:15:17.369251 12026 sgd_solver.cpp:106] Iteration 43000, lr = 1e-06
I0831 18:15:57.681496 12026 solver.cpp:228] Iteration 43100, loss = 0.726296
I0831 18:15:57.681699 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.448088 (* 1 = 0.448088 loss)
I0831 18:15:57.681725 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.85928 (* 0.1 = 0.185928 loss)
I0831 18:15:57.681746 12026 sgd_solver.cpp:106] Iteration 43100, lr = 1e-06
I0831 18:16:37.996397 12026 solver.cpp:228] Iteration 43200, loss = 0.699367
I0831 18:16:37.996587 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.378136 (* 1 = 0.378136 loss)
I0831 18:16:37.996614 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.67014 (* 0.1 = 0.167014 loss)
I0831 18:16:37.996635 12026 sgd_solver.cpp:106] Iteration 43200, lr = 1e-06
I0831 18:17:18.315793 12026 solver.cpp:228] Iteration 43300, loss = 0.718334
I0831 18:17:18.315980 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.665066 (* 1 = 0.665066 loss)
I0831 18:17:18.316007 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.15239 (* 0.1 = 0.215239 loss)
I0831 18:17:18.316030 12026 sgd_solver.cpp:106] Iteration 43300, lr = 1e-06
I0831 18:17:58.651813 12026 solver.cpp:228] Iteration 43400, loss = 0.715493
I0831 18:17:58.652037 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.489543 (* 1 = 0.489543 loss)
I0831 18:17:58.652065 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.17604 (* 0.1 = 0.217604 loss)
I0831 18:17:58.652088 12026 sgd_solver.cpp:106] Iteration 43400, lr = 1e-06
I0831 18:18:38.971429 12026 solver.cpp:228] Iteration 43500, loss = 0.699845
I0831 18:18:38.971654 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.471273 (* 1 = 0.471273 loss)
I0831 18:18:38.971681 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.1126 (* 0.1 = 0.21126 loss)
I0831 18:18:38.971706 12026 sgd_solver.cpp:106] Iteration 43500, lr = 1e-06
I0831 18:19:19.282176 12026 solver.cpp:228] Iteration 43600, loss = 0.727198
I0831 18:19:19.282366 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.529509 (* 1 = 0.529509 loss)
I0831 18:19:19.282397 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98178 (* 0.1 = 0.198178 loss)
I0831 18:19:19.282418 12026 sgd_solver.cpp:106] Iteration 43600, lr = 1e-06
I0831 18:19:59.591189 12026 solver.cpp:228] Iteration 43700, loss = 0.729737
I0831 18:19:59.591401 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.739843 (* 1 = 0.739843 loss)
I0831 18:19:59.591428 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.33405 (* 0.1 = 0.233405 loss)
I0831 18:19:59.591449 12026 sgd_solver.cpp:106] Iteration 43700, lr = 1e-06
I0831 18:20:39.920265 12026 solver.cpp:228] Iteration 43800, loss = 0.725911
I0831 18:20:39.920440 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.490217 (* 1 = 0.490217 loss)
I0831 18:20:39.920467 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.94464 (* 0.1 = 0.194464 loss)
I0831 18:20:39.920490 12026 sgd_solver.cpp:106] Iteration 43800, lr = 1e-06
I0831 18:21:20.246551 12026 solver.cpp:228] Iteration 43900, loss = 0.709159
I0831 18:21:20.246731 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.912431 (* 1 = 0.912431 loss)
I0831 18:21:20.246759 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.73624 (* 0.1 = 0.273624 loss)
I0831 18:21:20.246780 12026 sgd_solver.cpp:106] Iteration 43900, lr = 1e-06
I0831 18:22:00.154320 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_44000.caffemodel
I0831 18:22:00.960026 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_44000.solverstate
I0831 18:22:01.175809 12026 solver.cpp:337] Iteration 44000, Testing net (#0)
I0831 18:22:08.649379 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.773143
I0831 18:22:08.649472 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988285
I0831 18:22:08.649499 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.642915 (* 1 = 0.642915 loss)
I0831 18:22:08.649523 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.12499 (* 0.1 = 0.312499 loss)
I0831 18:22:08.768909 12026 solver.cpp:228] Iteration 44000, loss = 0.727428
I0831 18:22:08.769021 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.603009 (* 1 = 0.603009 loss)
I0831 18:22:08.769047 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.25087 (* 0.1 = 0.225087 loss)
I0831 18:22:08.769070 12026 sgd_solver.cpp:106] Iteration 44000, lr = 1e-06
I0831 18:22:49.098665 12026 solver.cpp:228] Iteration 44100, loss = 0.680222
I0831 18:22:49.098865 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.485134 (* 1 = 0.485134 loss)
I0831 18:22:49.098891 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.23861 (* 0.1 = 0.223861 loss)
I0831 18:22:49.098914 12026 sgd_solver.cpp:106] Iteration 44100, lr = 1e-06
I0831 18:23:29.429246 12026 solver.cpp:228] Iteration 44200, loss = 0.720916
I0831 18:23:29.429453 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.464839 (* 1 = 0.464839 loss)
I0831 18:23:29.429479 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.32967 (* 0.1 = 0.232967 loss)
I0831 18:23:29.429502 12026 sgd_solver.cpp:106] Iteration 44200, lr = 1e-06
I0831 18:24:09.750777 12026 solver.cpp:228] Iteration 44300, loss = 0.729156
I0831 18:24:09.751044 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.519045 (* 1 = 0.519045 loss)
I0831 18:24:09.751071 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.52558 (* 0.1 = 0.252558 loss)
I0831 18:24:09.751094 12026 sgd_solver.cpp:106] Iteration 44300, lr = 1e-06
I0831 18:24:50.078169 12026 solver.cpp:228] Iteration 44400, loss = 0.743422
I0831 18:24:50.078341 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.477512 (* 1 = 0.477512 loss)
I0831 18:24:50.078373 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.9788 (* 0.1 = 0.19788 loss)
I0831 18:24:50.078397 12026 sgd_solver.cpp:106] Iteration 44400, lr = 1e-06
I0831 18:25:30.413780 12026 solver.cpp:228] Iteration 44500, loss = 0.707636
I0831 18:25:30.414048 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.404208 (* 1 = 0.404208 loss)
I0831 18:25:30.414075 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.78961 (* 0.1 = 0.178961 loss)
I0831 18:25:30.414100 12026 sgd_solver.cpp:106] Iteration 44500, lr = 1e-06
I0831 18:26:10.738353 12026 solver.cpp:228] Iteration 44600, loss = 0.725912
I0831 18:26:10.738543 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.386899 (* 1 = 0.386899 loss)
I0831 18:26:10.738569 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28085 (* 0.1 = 0.228085 loss)
I0831 18:26:10.738597 12026 sgd_solver.cpp:106] Iteration 44600, lr = 1e-06
I0831 18:26:51.065785 12026 solver.cpp:228] Iteration 44700, loss = 0.70686
I0831 18:26:51.065961 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.548719 (* 1 = 0.548719 loss)
I0831 18:26:51.065996 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.88385 (* 0.1 = 0.188385 loss)
I0831 18:26:51.066018 12026 sgd_solver.cpp:106] Iteration 44700, lr = 1e-06
I0831 18:27:31.390246 12026 solver.cpp:228] Iteration 44800, loss = 0.682732
I0831 18:27:31.390467 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.438555 (* 1 = 0.438555 loss)
I0831 18:27:31.390494 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.59223 (* 0.1 = 0.159223 loss)
I0831 18:27:31.390516 12026 sgd_solver.cpp:106] Iteration 44800, lr = 1e-06
I0831 18:28:11.721202 12026 solver.cpp:228] Iteration 44900, loss = 0.723378
I0831 18:28:11.721402 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.410223 (* 1 = 0.410223 loss)
I0831 18:28:11.721429 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.97983 (* 0.1 = 0.197983 loss)
I0831 18:28:11.721451 12026 sgd_solver.cpp:106] Iteration 44900, lr = 1e-06
I0831 18:28:51.637698 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_45000.caffemodel
I0831 18:28:52.374678 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_45000.solverstate
I0831 18:28:52.570307 12026 solver.cpp:337] Iteration 45000, Testing net (#0)
I0831 18:29:00.059430 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.784
I0831 18:29:00.059509 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988571
I0831 18:29:00.059540 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.651037 (* 1 = 0.651037 loss)
I0831 18:29:00.059561 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.091 (* 0.1 = 0.3091 loss)
I0831 18:29:00.177067 12026 solver.cpp:228] Iteration 45000, loss = 0.733993
I0831 18:29:00.177153 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.463349 (* 1 = 0.463349 loss)
I0831 18:29:00.177177 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.91676 (* 0.1 = 0.191676 loss)
I0831 18:29:00.177198 12026 sgd_solver.cpp:46] MultiStep Status: Iteration 45000, step = 3
I0831 18:29:00.177222 12026 sgd_solver.cpp:106] Iteration 45000, lr = 1e-07
I0831 18:29:40.508512 12026 solver.cpp:228] Iteration 45100, loss = 0.742111
I0831 18:29:40.508785 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.542125 (* 1 = 0.542125 loss)
I0831 18:29:40.508818 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.18835 (* 0.1 = 0.218835 loss)
I0831 18:29:40.508846 12026 sgd_solver.cpp:106] Iteration 45100, lr = 1e-07
I0831 18:30:20.832986 12026 solver.cpp:228] Iteration 45200, loss = 0.69267
I0831 18:30:20.833281 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.365913 (* 1 = 0.365913 loss)
I0831 18:30:20.833308 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.69932 (* 0.1 = 0.169932 loss)
I0831 18:30:20.833331 12026 sgd_solver.cpp:106] Iteration 45200, lr = 1e-07
I0831 18:31:01.148459 12026 solver.cpp:228] Iteration 45300, loss = 0.719635
I0831 18:31:01.148670 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.349247 (* 1 = 0.349247 loss)
I0831 18:31:01.148697 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.85712 (* 0.1 = 0.185712 loss)
I0831 18:31:01.148723 12026 sgd_solver.cpp:106] Iteration 45300, lr = 1e-07
I0831 18:31:41.469489 12026 solver.cpp:228] Iteration 45400, loss = 0.699382
I0831 18:31:41.469696 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.54815 (* 1 = 0.54815 loss)
I0831 18:31:41.469724 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11884 (* 0.1 = 0.211884 loss)
I0831 18:31:41.469750 12026 sgd_solver.cpp:106] Iteration 45400, lr = 1e-07
I0831 18:32:21.785957 12026 solver.cpp:228] Iteration 45500, loss = 0.692278
I0831 18:32:21.786227 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.489991 (* 1 = 0.489991 loss)
I0831 18:32:21.786253 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.9271 (* 0.1 = 0.19271 loss)
I0831 18:32:21.786278 12026 sgd_solver.cpp:106] Iteration 45500, lr = 1e-07
I0831 18:33:02.103936 12026 solver.cpp:228] Iteration 45600, loss = 0.723931
I0831 18:33:02.104135 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.669854 (* 1 = 0.669854 loss)
I0831 18:33:02.104162 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05408 (* 0.1 = 0.205408 loss)
I0831 18:33:02.104184 12026 sgd_solver.cpp:106] Iteration 45600, lr = 1e-07
I0831 18:33:42.412578 12026 solver.cpp:228] Iteration 45700, loss = 0.752143
I0831 18:33:42.412776 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.687115 (* 1 = 0.687115 loss)
I0831 18:33:42.412803 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.28268 (* 0.1 = 0.228268 loss)
I0831 18:33:42.412827 12026 sgd_solver.cpp:106] Iteration 45700, lr = 1e-07
I0831 18:34:22.724395 12026 solver.cpp:228] Iteration 45800, loss = 0.727327
I0831 18:34:22.724596 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.565824 (* 1 = 0.565824 loss)
I0831 18:34:22.724623 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.56555 (* 0.1 = 0.256555 loss)
I0831 18:34:22.724649 12026 sgd_solver.cpp:106] Iteration 45800, lr = 1e-07
I0831 18:35:03.045594 12026 solver.cpp:228] Iteration 45900, loss = 0.70904
I0831 18:35:03.045790 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.472566 (* 1 = 0.472566 loss)
I0831 18:35:03.045816 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.15719 (* 0.1 = 0.215719 loss)
I0831 18:35:03.045840 12026 sgd_solver.cpp:106] Iteration 45900, lr = 1e-07
I0831 18:35:42.959728 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_46000.caffemodel
I0831 18:35:43.694959 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_46000.solverstate
I0831 18:35:43.889580 12026 solver.cpp:337] Iteration 46000, Testing net (#0)
I0831 18:35:51.371199 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.773429
I0831 18:35:51.371281 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988286
I0831 18:35:51.371315 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.641617 (* 1 = 0.641617 loss)
I0831 18:35:51.371336 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.14335 (* 0.1 = 0.314335 loss)
I0831 18:35:51.488631 12026 solver.cpp:228] Iteration 46000, loss = 0.720194
I0831 18:35:51.488720 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.653221 (* 1 = 0.653221 loss)
I0831 18:35:51.488745 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.98271 (* 0.1 = 0.198271 loss)
I0831 18:35:51.488773 12026 sgd_solver.cpp:106] Iteration 46000, lr = 1e-07
I0831 18:36:31.817138 12026 solver.cpp:228] Iteration 46100, loss = 0.696101
I0831 18:36:31.817421 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.64028 (* 1 = 0.64028 loss)
I0831 18:36:31.817450 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.97385 (* 0.1 = 0.197385 loss)
I0831 18:36:31.817471 12026 sgd_solver.cpp:106] Iteration 46100, lr = 1e-07
I0831 18:37:12.143024 12026 solver.cpp:228] Iteration 46200, loss = 0.717879
I0831 18:37:12.143210 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.359761 (* 1 = 0.359761 loss)
I0831 18:37:12.143237 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.8378 (* 0.1 = 0.18378 loss)
I0831 18:37:12.143261 12026 sgd_solver.cpp:106] Iteration 46200, lr = 1e-07
I0831 18:37:52.473364 12026 solver.cpp:228] Iteration 46300, loss = 0.710333
I0831 18:37:52.473523 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.427048 (* 1 = 0.427048 loss)
I0831 18:37:52.473549 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.90137 (* 0.1 = 0.190137 loss)
I0831 18:37:52.473572 12026 sgd_solver.cpp:106] Iteration 46300, lr = 1e-07
I0831 18:38:32.805671 12026 solver.cpp:228] Iteration 46400, loss = 0.73917
I0831 18:38:32.805876 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.648603 (* 1 = 0.648603 loss)
I0831 18:38:32.805902 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92722 (* 0.1 = 0.192722 loss)
I0831 18:38:32.805928 12026 sgd_solver.cpp:106] Iteration 46400, lr = 1e-07
I0831 18:39:13.132849 12026 solver.cpp:228] Iteration 46500, loss = 0.715868
I0831 18:39:13.133045 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.517618 (* 1 = 0.517618 loss)
I0831 18:39:13.133071 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.41835 (* 0.1 = 0.241835 loss)
I0831 18:39:13.133095 12026 sgd_solver.cpp:106] Iteration 46500, lr = 1e-07
I0831 18:39:53.464653 12026 solver.cpp:228] Iteration 46600, loss = 0.721554
I0831 18:39:53.464860 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.392544 (* 1 = 0.392544 loss)
I0831 18:39:53.464887 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.01269 (* 0.1 = 0.201269 loss)
I0831 18:39:53.464915 12026 sgd_solver.cpp:106] Iteration 46600, lr = 1e-07
I0831 18:40:33.795680 12026 solver.cpp:228] Iteration 46700, loss = 0.7185
I0831 18:40:33.795912 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.570399 (* 1 = 0.570399 loss)
I0831 18:40:33.795938 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.24276 (* 0.1 = 0.224276 loss)
I0831 18:40:33.795960 12026 sgd_solver.cpp:106] Iteration 46700, lr = 1e-07
I0831 18:41:14.116458 12026 solver.cpp:228] Iteration 46800, loss = 0.691477
I0831 18:41:14.116658 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.613101 (* 1 = 0.613101 loss)
I0831 18:41:14.116685 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.14482 (* 0.1 = 0.214482 loss)
I0831 18:41:14.116714 12026 sgd_solver.cpp:106] Iteration 46800, lr = 1e-07
I0831 18:41:54.459228 12026 solver.cpp:228] Iteration 46900, loss = 0.708592
I0831 18:41:54.459484 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.667549 (* 1 = 0.667549 loss)
I0831 18:41:54.459511 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.23761 (* 0.1 = 0.223761 loss)
I0831 18:41:54.459548 12026 sgd_solver.cpp:106] Iteration 46900, lr = 1e-07
I0831 18:42:34.383592 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_47000.caffemodel
I0831 18:42:35.120391 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_47000.solverstate
I0831 18:42:35.316586 12026 solver.cpp:337] Iteration 47000, Testing net (#0)
I0831 18:42:42.802547 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.780857
I0831 18:42:42.802630 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.989429
I0831 18:42:42.802657 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.650262 (* 1 = 0.650262 loss)
I0831 18:42:42.802678 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.07972 (* 0.1 = 0.307972 loss)
I0831 18:42:42.919558 12026 solver.cpp:228] Iteration 47000, loss = 0.713715
I0831 18:42:42.919649 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.465377 (* 1 = 0.465377 loss)
I0831 18:42:42.919673 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.92357 (* 0.1 = 0.192357 loss)
I0831 18:42:42.919700 12026 sgd_solver.cpp:106] Iteration 47000, lr = 1e-07
I0831 18:43:23.231945 12026 solver.cpp:228] Iteration 47100, loss = 0.72829
I0831 18:43:23.232174 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.713585 (* 1 = 0.713585 loss)
I0831 18:43:23.232201 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.21985 (* 0.1 = 0.221985 loss)
I0831 18:43:23.232224 12026 sgd_solver.cpp:106] Iteration 47100, lr = 1e-07
I0831 18:44:03.547897 12026 solver.cpp:228] Iteration 47200, loss = 0.698964
I0831 18:44:03.548091 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.441226 (* 1 = 0.441226 loss)
I0831 18:44:03.548117 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.08602 (* 0.1 = 0.208602 loss)
I0831 18:44:03.548141 12026 sgd_solver.cpp:106] Iteration 47200, lr = 1e-07
I0831 18:44:43.862081 12026 solver.cpp:228] Iteration 47300, loss = 0.723732
I0831 18:44:43.862330 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.484569 (* 1 = 0.484569 loss)
I0831 18:44:43.862357 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.44659 (* 0.1 = 0.244659 loss)
I0831 18:44:43.862386 12026 sgd_solver.cpp:106] Iteration 47300, lr = 1e-07
I0831 18:45:24.191417 12026 solver.cpp:228] Iteration 47400, loss = 0.708834
I0831 18:45:24.191684 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.379579 (* 1 = 0.379579 loss)
I0831 18:45:24.191710 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.57033 (* 0.1 = 0.157033 loss)
I0831 18:45:24.191740 12026 sgd_solver.cpp:106] Iteration 47400, lr = 1e-07
I0831 18:46:04.499538 12026 solver.cpp:228] Iteration 47500, loss = 0.688296
I0831 18:46:04.499719 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.266611 (* 1 = 0.266611 loss)
I0831 18:46:04.499745 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.70039 (* 0.1 = 0.170039 loss)
I0831 18:46:04.499768 12026 sgd_solver.cpp:106] Iteration 47500, lr = 1e-07
I0831 18:46:44.811353 12026 solver.cpp:228] Iteration 47600, loss = 0.734079
I0831 18:46:44.811560 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.563089 (* 1 = 0.563089 loss)
I0831 18:46:44.811588 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.7362 (* 0.1 = 0.17362 loss)
I0831 18:46:44.811611 12026 sgd_solver.cpp:106] Iteration 47600, lr = 1e-07
I0831 18:47:25.125237 12026 solver.cpp:228] Iteration 47700, loss = 0.743146
I0831 18:47:25.125458 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.51091 (* 1 = 0.51091 loss)
I0831 18:47:25.125485 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.26266 (* 0.1 = 0.226266 loss)
I0831 18:47:25.125510 12026 sgd_solver.cpp:106] Iteration 47700, lr = 1e-07
I0831 18:48:05.442580 12026 solver.cpp:228] Iteration 47800, loss = 0.730629
I0831 18:48:05.442769 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.422239 (* 1 = 0.422239 loss)
I0831 18:48:05.442795 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.87648 (* 0.1 = 0.187648 loss)
I0831 18:48:05.442819 12026 sgd_solver.cpp:106] Iteration 47800, lr = 1e-07
I0831 18:48:45.767796 12026 solver.cpp:228] Iteration 47900, loss = 0.704178
I0831 18:48:45.768075 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.808429 (* 1 = 0.808429 loss)
I0831 18:48:45.768103 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.29994 (* 0.1 = 0.229994 loss)
I0831 18:48:45.768127 12026 sgd_solver.cpp:106] Iteration 47900, lr = 1e-07
I0831 18:49:25.678422 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_48000.caffemodel
I0831 18:49:26.415004 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_48000.solverstate
I0831 18:49:26.610648 12026 solver.cpp:337] Iteration 48000, Testing net (#0)
I0831 18:49:34.094903 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.772857
I0831 18:49:34.095003 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.987714
I0831 18:49:34.095031 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.641399 (* 1 = 0.641399 loss)
I0831 18:49:34.095052 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.1337 (* 0.1 = 0.31337 loss)
I0831 18:49:34.212174 12026 solver.cpp:228] Iteration 48000, loss = 0.706897
I0831 18:49:34.212267 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.627101 (* 1 = 0.627101 loss)
I0831 18:49:34.212291 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.90406 (* 0.1 = 0.190406 loss)
I0831 18:49:34.212318 12026 sgd_solver.cpp:106] Iteration 48000, lr = 1e-07
I0831 18:50:14.531632 12026 solver.cpp:228] Iteration 48100, loss = 0.70342
I0831 18:50:14.531900 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.59838 (* 1 = 0.59838 loss)
I0831 18:50:14.531926 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42529 (* 0.1 = 0.242529 loss)
I0831 18:50:14.531950 12026 sgd_solver.cpp:106] Iteration 48100, lr = 1e-07
I0831 18:50:54.845849 12026 solver.cpp:228] Iteration 48200, loss = 0.705312
I0831 18:50:54.846034 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.57603 (* 1 = 0.57603 loss)
I0831 18:50:54.846060 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.78261 (* 0.1 = 0.178261 loss)
I0831 18:50:54.846086 12026 sgd_solver.cpp:106] Iteration 48200, lr = 1e-07
I0831 18:51:35.154726 12026 solver.cpp:228] Iteration 48300, loss = 0.713743
I0831 18:51:35.154891 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.388718 (* 1 = 0.388718 loss)
I0831 18:51:35.154917 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.88016 (* 0.1 = 0.188016 loss)
I0831 18:51:35.154940 12026 sgd_solver.cpp:106] Iteration 48300, lr = 1e-07
I0831 18:52:15.464917 12026 solver.cpp:228] Iteration 48400, loss = 0.721754
I0831 18:52:15.465131 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.60261 (* 1 = 0.60261 loss)
I0831 18:52:15.465157 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.8066 (* 0.1 = 0.18066 loss)
I0831 18:52:15.465178 12026 sgd_solver.cpp:106] Iteration 48400, lr = 1e-07
I0831 18:52:55.779409 12026 solver.cpp:228] Iteration 48500, loss = 0.724293
I0831 18:52:55.779618 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.53462 (* 1 = 0.53462 loss)
I0831 18:52:55.779645 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.11151 (* 0.1 = 0.211151 loss)
I0831 18:52:55.779670 12026 sgd_solver.cpp:106] Iteration 48500, lr = 1e-07
I0831 18:53:36.096688 12026 solver.cpp:228] Iteration 48600, loss = 0.697187
I0831 18:53:36.096892 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.457013 (* 1 = 0.457013 loss)
I0831 18:53:36.096918 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.42279 (* 0.1 = 0.242279 loss)
I0831 18:53:36.096943 12026 sgd_solver.cpp:106] Iteration 48600, lr = 1e-07
I0831 18:54:16.407269 12026 solver.cpp:228] Iteration 48700, loss = 0.72712
I0831 18:54:16.407529 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.434849 (* 1 = 0.434849 loss)
I0831 18:54:16.407557 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.86619 (* 0.1 = 0.186619 loss)
I0831 18:54:16.407579 12026 sgd_solver.cpp:106] Iteration 48700, lr = 1e-07
I0831 18:54:56.729024 12026 solver.cpp:228] Iteration 48800, loss = 0.679638
I0831 18:54:56.729225 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.441174 (* 1 = 0.441174 loss)
I0831 18:54:56.729251 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.89816 (* 0.1 = 0.189816 loss)
I0831 18:54:56.729274 12026 sgd_solver.cpp:106] Iteration 48800, lr = 1e-07
I0831 18:55:37.047642 12026 solver.cpp:228] Iteration 48900, loss = 0.709069
I0831 18:55:37.047821 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.270571 (* 1 = 0.270571 loss)
I0831 18:55:37.047849 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.83913 (* 0.1 = 0.183913 loss)
I0831 18:55:37.047871 12026 sgd_solver.cpp:106] Iteration 48900, lr = 1e-07
I0831 18:56:16.955610 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_49000.caffemodel
I0831 18:56:17.689524 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_49000.solverstate
I0831 18:56:17.883900 12026 solver.cpp:337] Iteration 49000, Testing net (#0)
I0831 18:56:25.359347 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.781714
I0831 18:56:25.359447 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.989143
I0831 18:56:25.359474 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.65035 (* 1 = 0.65035 loss)
I0831 18:56:25.359495 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.07255 (* 0.1 = 0.307255 loss)
I0831 18:56:25.476802 12026 solver.cpp:228] Iteration 49000, loss = 0.725455
I0831 18:56:25.476896 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.575142 (* 1 = 0.575142 loss)
I0831 18:56:25.476919 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.07326 (* 0.1 = 0.207326 loss)
I0831 18:56:25.476946 12026 sgd_solver.cpp:106] Iteration 49000, lr = 1e-07
I0831 18:57:05.789067 12026 solver.cpp:228] Iteration 49100, loss = 0.735788
I0831 18:57:05.789269 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.528395 (* 1 = 0.528395 loss)
I0831 18:57:05.789297 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.00728 (* 0.1 = 0.200728 loss)
I0831 18:57:05.789320 12026 sgd_solver.cpp:106] Iteration 49100, lr = 1e-07
I0831 18:57:46.095512 12026 solver.cpp:228] Iteration 49200, loss = 0.718057
I0831 18:57:46.095757 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.278651 (* 1 = 0.278651 loss)
I0831 18:57:46.095809 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.68686 (* 0.1 = 0.168686 loss)
I0831 18:57:46.095839 12026 sgd_solver.cpp:106] Iteration 49200, lr = 1e-07
I0831 18:58:26.407196 12026 solver.cpp:228] Iteration 49300, loss = 0.719863
I0831 18:58:26.407346 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.586607 (* 1 = 0.586607 loss)
I0831 18:58:26.407371 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.99438 (* 0.1 = 0.199438 loss)
I0831 18:58:26.407395 12026 sgd_solver.cpp:106] Iteration 49300, lr = 1e-07
I0831 18:59:06.724565 12026 solver.cpp:228] Iteration 49400, loss = 0.711022
I0831 18:59:06.724750 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.465991 (* 1 = 0.465991 loss)
I0831 18:59:06.724776 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.97573 (* 0.1 = 0.197573 loss)
I0831 18:59:06.724797 12026 sgd_solver.cpp:106] Iteration 49400, lr = 1e-07
I0831 18:59:47.041347 12026 solver.cpp:228] Iteration 49500, loss = 0.682769
I0831 18:59:47.041533 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.542596 (* 1 = 0.542596 loss)
I0831 18:59:47.041559 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.17794 (* 0.1 = 0.217794 loss)
I0831 18:59:47.041585 12026 sgd_solver.cpp:106] Iteration 49500, lr = 1e-07
I0831 19:00:27.355656 12026 solver.cpp:228] Iteration 49600, loss = 0.713063
I0831 19:00:27.355937 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.554245 (* 1 = 0.554245 loss)
I0831 19:00:27.355964 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.05934 (* 0.1 = 0.205934 loss)
I0831 19:00:27.355989 12026 sgd_solver.cpp:106] Iteration 49600, lr = 1e-07
I0831 19:01:07.671308 12026 solver.cpp:228] Iteration 49700, loss = 0.730814
I0831 19:01:07.671488 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.576935 (* 1 = 0.576935 loss)
I0831 19:01:07.671514 12026 solver.cpp:244]     Train net output #1: loss_hash = 1.82935 (* 0.1 = 0.182935 loss)
I0831 19:01:07.671541 12026 sgd_solver.cpp:106] Iteration 49700, lr = 1e-07
I0831 19:01:47.983554 12026 solver.cpp:228] Iteration 49800, loss = 0.738948
I0831 19:01:47.983774 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.530693 (* 1 = 0.530693 loss)
I0831 19:01:47.983801 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.24439 (* 0.1 = 0.224439 loss)
I0831 19:01:47.983824 12026 sgd_solver.cpp:106] Iteration 49800, lr = 1e-07
I0831 19:02:28.298957 12026 solver.cpp:228] Iteration 49900, loss = 0.687218
I0831 19:02:28.299109 12026 solver.cpp:244]     Train net output #0: loss_classification = 0.393994 (* 1 = 0.393994 loss)
I0831 19:02:28.299134 12026 solver.cpp:244]     Train net output #1: loss_hash = 2.23774 (* 0.1 = 0.223774 loss)
I0831 19:02:28.299156 12026 sgd_solver.cpp:106] Iteration 49900, lr = 1e-07
I0831 19:03:08.215956 12026 solver.cpp:454] Snapshotting to binary proto file PATTERN/pattern_cnn_iter_50000.caffemodel
I0831 19:03:09.029242 12026 sgd_solver.cpp:273] Snapshotting solver state to binary proto file PATTERN/pattern_cnn_iter_50000.solverstate
I0831 19:03:09.349074 12026 solver.cpp:317] Iteration 50000, loss = 0.724345
I0831 19:03:09.349145 12026 solver.cpp:337] Iteration 50000, Testing net (#0)
I0831 19:03:16.807171 12026 solver.cpp:404]     Test net output #0: accuracy_at_1 = 0.772857
I0831 19:03:16.807296 12026 solver.cpp:404]     Test net output #1: accuracy_at_5 = 0.988
I0831 19:03:16.807325 12026 solver.cpp:404]     Test net output #2: loss_classification = 0.641703 (* 1 = 0.641703 loss)
I0831 19:03:16.807346 12026 solver.cpp:404]     Test net output #3: loss_hash = 3.12795 (* 0.1 = 0.312795 loss)
I0831 19:03:16.807365 12026 solver.cpp:322] Optimization Done.
I0831 19:03:16.807379 12026 caffe.cpp:222] Optimization Done.
