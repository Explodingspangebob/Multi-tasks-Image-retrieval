Log file created at: 2017/08/18 12:02:47
Running on machine: img08
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0818 12:02:47.814813 20702 caffe.cpp:185] Using GPUs 0
I0818 12:02:48.978693 20702 caffe.cpp:190] GPU 0: GeForce GTX TITAN Black
I0818 12:02:49.356895 20702 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 2000
base_lr: 0.001
display: 100
max_iter: 70000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.004
snapshot: 10000
snapshot_prefix: "CIFAR-10/cifar10"
solver_mode: GPU
device_id: 0
net: "CIFAR-10/train_test.prototxt"
test_initialization: false
average_loss: 100
stepvalue: 60000
stepvalue: 65000
I0818 12:02:49.357431 20702 solver.cpp:91] Creating training net from net file: CIFAR-10/train_test.prototxt
I0818 12:02:49.358717 20702 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0818 12:02:49.359117 20702 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "CIFAR-10/mean.binaryproto"
  }
  data_param {
    source: "CIFAR-10/cifar10_train_lmdb"
    batch_size: 200
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_ip2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HashingLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
  hashing_loss_param {
    bi_margin: 24
    tradeoff: 0.01
  }
}
I0818 12:02:49.361382 20702 layer_factory.hpp:77] Creating layer cifar
I0818 12:02:49.362927 20702 net.cpp:91] Creating Layer cifar
I0818 12:02:49.363014 20702 net.cpp:399] cifar -> data
I0818 12:02:49.363131 20702 net.cpp:399] cifar -> label
I0818 12:02:49.363214 20702 data_transformer.cpp:25] Loading mean file from: CIFAR-10/mean.binaryproto
I0818 12:02:49.364855 20707 db_lmdb.cpp:38] Opened lmdb CIFAR-10/cifar10_train_lmdb
I0818 12:02:49.395066 20702 data_layer.cpp:41] output data size: 200,3,32,32
I0818 12:02:49.404775 20702 net.cpp:141] Setting up cifar
I0818 12:02:49.404876 20702 net.cpp:148] Top shape: 200 3 32 32 (614400)
I0818 12:02:49.404930 20702 net.cpp:148] Top shape: 200 1 1 1 (200)
I0818 12:02:49.404966 20702 net.cpp:156] Memory required for data: 2458400
I0818 12:02:49.405011 20702 layer_factory.hpp:77] Creating layer conv1
I0818 12:02:49.405102 20702 net.cpp:91] Creating Layer conv1
I0818 12:02:49.405149 20702 net.cpp:425] conv1 <- data
I0818 12:02:49.405213 20702 net.cpp:399] conv1 -> conv1
I0818 12:02:49.407022 20702 net.cpp:141] Setting up conv1
I0818 12:02:49.407083 20702 net.cpp:148] Top shape: 200 32 32 32 (6553600)
I0818 12:02:49.407115 20702 net.cpp:156] Memory required for data: 28672800
I0818 12:02:49.407184 20702 layer_factory.hpp:77] Creating layer pool1
I0818 12:02:49.407243 20702 net.cpp:91] Creating Layer pool1
I0818 12:02:49.407284 20702 net.cpp:425] pool1 <- conv1
I0818 12:02:49.407331 20702 net.cpp:399] pool1 -> pool1
I0818 12:02:49.407804 20702 net.cpp:141] Setting up pool1
I0818 12:02:49.407867 20702 net.cpp:148] Top shape: 200 32 16 16 (1638400)
I0818 12:02:49.407912 20702 net.cpp:156] Memory required for data: 35226400
I0818 12:02:49.407948 20702 layer_factory.hpp:77] Creating layer relu1
I0818 12:02:49.407984 20702 net.cpp:91] Creating Layer relu1
I0818 12:02:49.408017 20702 net.cpp:425] relu1 <- pool1
I0818 12:02:49.408068 20702 net.cpp:386] relu1 -> pool1 (in-place)
I0818 12:02:49.408118 20702 net.cpp:141] Setting up relu1
I0818 12:02:49.408165 20702 net.cpp:148] Top shape: 200 32 16 16 (1638400)
I0818 12:02:49.408198 20702 net.cpp:156] Memory required for data: 41780000
I0818 12:02:49.408232 20702 layer_factory.hpp:77] Creating layer norm1
I0818 12:02:49.408282 20702 net.cpp:91] Creating Layer norm1
I0818 12:02:49.408320 20702 net.cpp:425] norm1 <- pool1
I0818 12:02:49.408365 20702 net.cpp:399] norm1 -> norm1
I0818 12:02:49.408690 20702 net.cpp:141] Setting up norm1
I0818 12:02:49.408746 20702 net.cpp:148] Top shape: 200 32 16 16 (1638400)
I0818 12:02:49.408783 20702 net.cpp:156] Memory required for data: 48333600
I0818 12:02:49.408818 20702 layer_factory.hpp:77] Creating layer conv2
I0818 12:02:49.408874 20702 net.cpp:91] Creating Layer conv2
I0818 12:02:49.408910 20702 net.cpp:425] conv2 <- norm1
I0818 12:02:49.408960 20702 net.cpp:399] conv2 -> conv2
I0818 12:02:49.411044 20702 net.cpp:141] Setting up conv2
I0818 12:02:49.411109 20702 net.cpp:148] Top shape: 200 32 16 16 (1638400)
I0818 12:02:49.411146 20702 net.cpp:156] Memory required for data: 54887200
I0818 12:02:49.411190 20702 layer_factory.hpp:77] Creating layer pool2
I0818 12:02:49.411238 20702 net.cpp:91] Creating Layer pool2
I0818 12:02:49.411283 20702 net.cpp:425] pool2 <- conv2
I0818 12:02:49.411322 20702 net.cpp:399] pool2 -> pool2
I0818 12:02:49.411402 20702 net.cpp:141] Setting up pool2
I0818 12:02:49.411448 20702 net.cpp:148] Top shape: 200 32 8 8 (409600)
I0818 12:02:49.411483 20702 net.cpp:156] Memory required for data: 56525600
I0818 12:02:49.411511 20702 layer_factory.hpp:77] Creating layer relu2
I0818 12:02:49.411550 20702 net.cpp:91] Creating Layer relu2
I0818 12:02:49.411590 20702 net.cpp:425] relu2 <- pool2
I0818 12:02:49.411623 20702 net.cpp:386] relu2 -> pool2 (in-place)
I0818 12:02:49.411664 20702 net.cpp:141] Setting up relu2
I0818 12:02:49.411700 20702 net.cpp:148] Top shape: 200 32 8 8 (409600)
I0818 12:02:49.411731 20702 net.cpp:156] Memory required for data: 58164000
I0818 12:02:49.411769 20702 layer_factory.hpp:77] Creating layer norm2
I0818 12:02:49.411813 20702 net.cpp:91] Creating Layer norm2
I0818 12:02:49.411845 20702 net.cpp:425] norm2 <- pool2
I0818 12:02:49.411957 20702 net.cpp:399] norm2 -> norm2
I0818 12:02:49.412205 20702 net.cpp:141] Setting up norm2
I0818 12:02:49.412256 20702 net.cpp:148] Top shape: 200 32 8 8 (409600)
I0818 12:02:49.412289 20702 net.cpp:156] Memory required for data: 59802400
I0818 12:02:49.412322 20702 layer_factory.hpp:77] Creating layer conv3
I0818 12:02:49.412375 20702 net.cpp:91] Creating Layer conv3
I0818 12:02:49.412410 20702 net.cpp:425] conv3 <- norm2
I0818 12:02:49.412448 20702 net.cpp:399] conv3 -> conv3
I0818 12:02:49.413801 20702 net.cpp:141] Setting up conv3
I0818 12:02:49.413874 20702 net.cpp:148] Top shape: 200 64 8 8 (819200)
I0818 12:02:49.413905 20702 net.cpp:156] Memory required for data: 63079200
I0818 12:02:49.413949 20702 layer_factory.hpp:77] Creating layer relu3
I0818 12:02:49.414005 20702 net.cpp:91] Creating Layer relu3
I0818 12:02:49.414036 20702 net.cpp:425] relu3 <- conv3
I0818 12:02:49.414069 20702 net.cpp:386] relu3 -> conv3 (in-place)
I0818 12:02:49.414110 20702 net.cpp:141] Setting up relu3
I0818 12:02:49.414147 20702 net.cpp:148] Top shape: 200 64 8 8 (819200)
I0818 12:02:49.414183 20702 net.cpp:156] Memory required for data: 66356000
I0818 12:02:49.414217 20702 layer_factory.hpp:77] Creating layer pool3
I0818 12:02:49.414258 20702 net.cpp:91] Creating Layer pool3
I0818 12:02:49.414294 20702 net.cpp:425] pool3 <- conv3
I0818 12:02:49.414332 20702 net.cpp:399] pool3 -> pool3
I0818 12:02:49.414412 20702 net.cpp:141] Setting up pool3
I0818 12:02:49.414458 20702 net.cpp:148] Top shape: 200 64 4 4 (204800)
I0818 12:02:49.414491 20702 net.cpp:156] Memory required for data: 67175200
I0818 12:02:49.414525 20702 layer_factory.hpp:77] Creating layer ip2
I0818 12:02:49.414575 20702 net.cpp:91] Creating Layer ip2
I0818 12:02:49.414613 20702 net.cpp:425] ip2 <- pool3
I0818 12:02:49.414654 20702 net.cpp:399] ip2 -> ip2
I0818 12:02:49.425508 20702 net.cpp:141] Setting up ip2
I0818 12:02:49.425565 20702 net.cpp:148] Top shape: 200 500 (100000)
I0818 12:02:49.425596 20702 net.cpp:156] Memory required for data: 67575200
I0818 12:02:49.425634 20702 layer_factory.hpp:77] Creating layer relu_ip2
I0818 12:02:49.425685 20702 net.cpp:91] Creating Layer relu_ip2
I0818 12:02:49.425721 20702 net.cpp:425] relu_ip2 <- ip2
I0818 12:02:49.425765 20702 net.cpp:386] relu_ip2 -> ip2 (in-place)
I0818 12:02:49.425817 20702 net.cpp:141] Setting up relu_ip2
I0818 12:02:49.425855 20702 net.cpp:148] Top shape: 200 500 (100000)
I0818 12:02:49.425890 20702 net.cpp:156] Memory required for data: 67975200
I0818 12:02:49.425926 20702 layer_factory.hpp:77] Creating layer ip1
I0818 12:02:49.425966 20702 net.cpp:91] Creating Layer ip1
I0818 12:02:49.426002 20702 net.cpp:425] ip1 <- ip2
I0818 12:02:49.426048 20702 net.cpp:399] ip1 -> ip1
I0818 12:02:49.427697 20702 net.cpp:141] Setting up ip1
I0818 12:02:49.427758 20702 net.cpp:148] Top shape: 200 12 (2400)
I0818 12:02:49.427790 20702 net.cpp:156] Memory required for data: 67984800
I0818 12:02:49.427840 20702 layer_factory.hpp:77] Creating layer loss
I0818 12:02:49.427892 20702 net.cpp:91] Creating Layer loss
I0818 12:02:49.427929 20702 net.cpp:425] loss <- ip1
I0818 12:02:49.427968 20702 net.cpp:425] loss <- label
I0818 12:02:49.428012 20702 net.cpp:399] loss -> loss
I0818 12:02:49.428232 20702 net.cpp:141] Setting up loss
I0818 12:02:49.428285 20702 net.cpp:148] Top shape: (1)
I0818 12:02:49.428328 20702 net.cpp:151]     with loss weight 1
I0818 12:02:49.428397 20702 net.cpp:156] Memory required for data: 67984804
I0818 12:02:49.428432 20702 net.cpp:217] loss needs backward computation.
I0818 12:02:49.428467 20702 net.cpp:217] ip1 needs backward computation.
I0818 12:02:49.428499 20702 net.cpp:217] relu_ip2 needs backward computation.
I0818 12:02:49.428527 20702 net.cpp:217] ip2 needs backward computation.
I0818 12:02:49.428556 20702 net.cpp:217] pool3 needs backward computation.
I0818 12:02:49.428593 20702 net.cpp:217] relu3 needs backward computation.
I0818 12:02:49.428638 20702 net.cpp:217] conv3 needs backward computation.
I0818 12:02:49.428668 20702 net.cpp:217] norm2 needs backward computation.
I0818 12:02:49.428742 20702 net.cpp:217] relu2 needs backward computation.
I0818 12:02:49.428781 20702 net.cpp:217] pool2 needs backward computation.
I0818 12:02:49.428815 20702 net.cpp:217] conv2 needs backward computation.
I0818 12:02:49.428845 20702 net.cpp:217] norm1 needs backward computation.
I0818 12:02:49.428874 20702 net.cpp:217] relu1 needs backward computation.
I0818 12:02:49.428902 20702 net.cpp:217] pool1 needs backward computation.
I0818 12:02:49.428935 20702 net.cpp:217] conv1 needs backward computation.
I0818 12:02:49.428966 20702 net.cpp:219] cifar does not need backward computation.
I0818 12:02:49.428993 20702 net.cpp:261] This network produces output loss
I0818 12:02:49.429049 20702 net.cpp:274] Network initialization done.
I0818 12:02:49.430074 20702 solver.cpp:181] Creating test net (#0) specified by net file: CIFAR-10/train_test.prototxt
I0818 12:02:49.430192 20702 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0818 12:02:49.430550 20702 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_file: "CIFAR-10/mean.binaryproto"
  }
  data_param {
    source: "CIFAR-10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu_ip2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 12
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HashingLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
  hashing_loss_param {
    bi_margin: 24
    tradeoff: 0.01
  }
}
I0818 12:02:49.432801 20702 layer_factory.hpp:77] Creating layer cifar
I0818 12:02:49.433109 20702 net.cpp:91] Creating Layer cifar
I0818 12:02:49.433168 20702 net.cpp:399] cifar -> data
I0818 12:02:49.433220 20702 net.cpp:399] cifar -> label
I0818 12:02:49.433269 20702 data_transformer.cpp:25] Loading mean file from: CIFAR-10/mean.binaryproto
I0818 12:02:49.434911 20709 db_lmdb.cpp:38] Opened lmdb CIFAR-10/cifar10_test_lmdb
I0818 12:02:49.435220 20702 data_layer.cpp:41] output data size: 100,3,32,32
I0818 12:02:49.441107 20702 net.cpp:141] Setting up cifar
I0818 12:02:49.441177 20702 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0818 12:02:49.441218 20702 net.cpp:148] Top shape: 100 1 1 1 (100)
I0818 12:02:49.441248 20702 net.cpp:156] Memory required for data: 1229200
I0818 12:02:49.441284 20702 layer_factory.hpp:77] Creating layer conv1
I0818 12:02:49.441355 20702 net.cpp:91] Creating Layer conv1
I0818 12:02:49.441395 20702 net.cpp:425] conv1 <- data
I0818 12:02:49.441448 20702 net.cpp:399] conv1 -> conv1
I0818 12:02:49.442068 20702 net.cpp:141] Setting up conv1
I0818 12:02:49.442121 20702 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I0818 12:02:49.442153 20702 net.cpp:156] Memory required for data: 14336400
I0818 12:02:49.442198 20702 layer_factory.hpp:77] Creating layer pool1
I0818 12:02:49.442263 20702 net.cpp:91] Creating Layer pool1
I0818 12:02:49.442301 20702 net.cpp:425] pool1 <- conv1
I0818 12:02:49.442335 20702 net.cpp:399] pool1 -> pool1
I0818 12:02:49.442457 20702 net.cpp:141] Setting up pool1
I0818 12:02:49.442505 20702 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0818 12:02:49.442538 20702 net.cpp:156] Memory required for data: 17613200
I0818 12:02:49.442570 20702 layer_factory.hpp:77] Creating layer relu1
I0818 12:02:49.442607 20702 net.cpp:91] Creating Layer relu1
I0818 12:02:49.442639 20702 net.cpp:425] relu1 <- pool1
I0818 12:02:49.442680 20702 net.cpp:386] relu1 -> pool1 (in-place)
I0818 12:02:49.442723 20702 net.cpp:141] Setting up relu1
I0818 12:02:49.442764 20702 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0818 12:02:49.442796 20702 net.cpp:156] Memory required for data: 20890000
I0818 12:02:49.442826 20702 layer_factory.hpp:77] Creating layer norm1
I0818 12:02:49.442867 20702 net.cpp:91] Creating Layer norm1
I0818 12:02:49.442900 20702 net.cpp:425] norm1 <- pool1
I0818 12:02:49.442939 20702 net.cpp:399] norm1 -> norm1
I0818 12:02:49.443392 20702 net.cpp:141] Setting up norm1
I0818 12:02:49.443444 20702 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0818 12:02:49.443476 20702 net.cpp:156] Memory required for data: 24166800
I0818 12:02:49.443509 20702 layer_factory.hpp:77] Creating layer conv2
I0818 12:02:49.443558 20702 net.cpp:91] Creating Layer conv2
I0818 12:02:49.443593 20702 net.cpp:425] conv2 <- norm1
I0818 12:02:49.443634 20702 net.cpp:399] conv2 -> conv2
I0818 12:02:49.444561 20702 net.cpp:141] Setting up conv2
I0818 12:02:49.444634 20702 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0818 12:02:49.444685 20702 net.cpp:156] Memory required for data: 27443600
I0818 12:02:49.444733 20702 layer_factory.hpp:77] Creating layer pool2
I0818 12:02:49.444780 20702 net.cpp:91] Creating Layer pool2
I0818 12:02:49.444818 20702 net.cpp:425] pool2 <- conv2
I0818 12:02:49.444855 20702 net.cpp:399] pool2 -> pool2
I0818 12:02:49.444928 20702 net.cpp:141] Setting up pool2
I0818 12:02:49.444972 20702 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0818 12:02:49.445004 20702 net.cpp:156] Memory required for data: 28262800
I0818 12:02:49.445034 20702 layer_factory.hpp:77] Creating layer relu2
I0818 12:02:49.445076 20702 net.cpp:91] Creating Layer relu2
I0818 12:02:49.445111 20702 net.cpp:425] relu2 <- pool2
I0818 12:02:49.445145 20702 net.cpp:386] relu2 -> pool2 (in-place)
I0818 12:02:49.445194 20702 net.cpp:141] Setting up relu2
I0818 12:02:49.445273 20702 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0818 12:02:49.445308 20702 net.cpp:156] Memory required for data: 29082000
I0818 12:02:49.445340 20702 layer_factory.hpp:77] Creating layer norm2
I0818 12:02:49.445387 20702 net.cpp:91] Creating Layer norm2
I0818 12:02:49.445422 20702 net.cpp:425] norm2 <- pool2
I0818 12:02:49.445461 20702 net.cpp:399] norm2 -> norm2
I0818 12:02:49.445704 20702 net.cpp:141] Setting up norm2
I0818 12:02:49.445752 20702 net.cpp:148] Top shape: 100 32 8 8 (204800)
I0818 12:02:49.445785 20702 net.cpp:156] Memory required for data: 29901200
I0818 12:02:49.445817 20702 layer_factory.hpp:77] Creating layer conv3
I0818 12:02:49.445868 20702 net.cpp:91] Creating Layer conv3
I0818 12:02:49.445904 20702 net.cpp:425] conv3 <- norm2
I0818 12:02:49.445943 20702 net.cpp:399] conv3 -> conv3
I0818 12:02:49.447341 20702 net.cpp:141] Setting up conv3
I0818 12:02:49.447392 20702 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0818 12:02:49.447427 20702 net.cpp:156] Memory required for data: 31539600
I0818 12:02:49.447473 20702 layer_factory.hpp:77] Creating layer relu3
I0818 12:02:49.447516 20702 net.cpp:91] Creating Layer relu3
I0818 12:02:49.447549 20702 net.cpp:425] relu3 <- conv3
I0818 12:02:49.447585 20702 net.cpp:386] relu3 -> conv3 (in-place)
I0818 12:02:49.447624 20702 net.cpp:141] Setting up relu3
I0818 12:02:49.447660 20702 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0818 12:02:49.447691 20702 net.cpp:156] Memory required for data: 33178000
I0818 12:02:49.447723 20702 layer_factory.hpp:77] Creating layer pool3
I0818 12:02:49.447765 20702 net.cpp:91] Creating Layer pool3
I0818 12:02:49.447798 20702 net.cpp:425] pool3 <- conv3
I0818 12:02:49.447834 20702 net.cpp:399] pool3 -> pool3
I0818 12:02:49.447928 20702 net.cpp:141] Setting up pool3
I0818 12:02:49.447978 20702 net.cpp:148] Top shape: 100 64 4 4 (102400)
I0818 12:02:49.448015 20702 net.cpp:156] Memory required for data: 33587600
I0818 12:02:49.448047 20702 layer_factory.hpp:77] Creating layer ip2
I0818 12:02:49.448086 20702 net.cpp:91] Creating Layer ip2
I0818 12:02:49.448118 20702 net.cpp:425] ip2 <- pool3
I0818 12:02:49.448166 20702 net.cpp:399] ip2 -> ip2
I0818 12:02:49.459003 20702 net.cpp:141] Setting up ip2
I0818 12:02:49.459065 20702 net.cpp:148] Top shape: 100 500 (50000)
I0818 12:02:49.459098 20702 net.cpp:156] Memory required for data: 33787600
I0818 12:02:49.459144 20702 layer_factory.hpp:77] Creating layer relu_ip2
I0818 12:02:49.459184 20702 net.cpp:91] Creating Layer relu_ip2
I0818 12:02:49.459218 20702 net.cpp:425] relu_ip2 <- ip2
I0818 12:02:49.459267 20702 net.cpp:386] relu_ip2 -> ip2 (in-place)
I0818 12:02:49.459311 20702 net.cpp:141] Setting up relu_ip2
I0818 12:02:49.459347 20702 net.cpp:148] Top shape: 100 500 (50000)
I0818 12:02:49.459378 20702 net.cpp:156] Memory required for data: 33987600
I0818 12:02:49.459410 20702 layer_factory.hpp:77] Creating layer ip1
I0818 12:02:49.459450 20702 net.cpp:91] Creating Layer ip1
I0818 12:02:49.459481 20702 net.cpp:425] ip1 <- ip2
I0818 12:02:49.459525 20702 net.cpp:399] ip1 -> ip1
I0818 12:02:49.459873 20702 net.cpp:141] Setting up ip1
I0818 12:02:49.459923 20702 net.cpp:148] Top shape: 100 12 (1200)
I0818 12:02:49.459954 20702 net.cpp:156] Memory required for data: 33992400
I0818 12:02:49.460000 20702 layer_factory.hpp:77] Creating layer loss
I0818 12:02:49.460047 20702 net.cpp:91] Creating Layer loss
I0818 12:02:49.460079 20702 net.cpp:425] loss <- ip1
I0818 12:02:49.460114 20702 net.cpp:425] loss <- label
I0818 12:02:49.460150 20702 net.cpp:399] loss -> loss
I0818 12:02:49.460319 20702 net.cpp:141] Setting up loss
I0818 12:02:49.460364 20702 net.cpp:148] Top shape: (1)
I0818 12:02:49.460397 20702 net.cpp:151]     with loss weight 1
I0818 12:02:49.460443 20702 net.cpp:156] Memory required for data: 33992404
I0818 12:02:49.460474 20702 net.cpp:217] loss needs backward computation.
I0818 12:02:49.460507 20702 net.cpp:217] ip1 needs backward computation.
I0818 12:02:49.460539 20702 net.cpp:217] relu_ip2 needs backward computation.
I0818 12:02:49.460572 20702 net.cpp:217] ip2 needs backward computation.
I0818 12:02:49.460651 20702 net.cpp:217] pool3 needs backward computation.
I0818 12:02:49.460686 20702 net.cpp:217] relu3 needs backward computation.
I0818 12:02:49.460716 20702 net.cpp:217] conv3 needs backward computation.
I0818 12:02:49.460747 20702 net.cpp:217] norm2 needs backward computation.
I0818 12:02:49.460778 20702 net.cpp:217] relu2 needs backward computation.
I0818 12:02:49.460808 20702 net.cpp:217] pool2 needs backward computation.
I0818 12:02:49.460840 20702 net.cpp:217] conv2 needs backward computation.
I0818 12:02:49.460871 20702 net.cpp:217] norm1 needs backward computation.
I0818 12:02:49.460902 20702 net.cpp:217] relu1 needs backward computation.
I0818 12:02:49.460933 20702 net.cpp:217] pool1 needs backward computation.
I0818 12:02:49.460965 20702 net.cpp:217] conv1 needs backward computation.
I0818 12:02:49.461004 20702 net.cpp:219] cifar does not need backward computation.
I0818 12:02:49.461035 20702 net.cpp:261] This network produces output loss
I0818 12:02:49.461081 20702 net.cpp:274] Network initialization done.
I0818 12:02:49.461215 20702 solver.cpp:60] Solver scaffolding done.
I0818 12:02:49.461935 20702 caffe.cpp:219] Starting Optimization
I0818 12:02:49.461987 20702 solver.cpp:279] Solving CIFAR10_full
I0818 12:02:49.462018 20702 solver.cpp:280] Learning Rate Policy: multistep
I0818 12:02:49.566694 20702 solver.cpp:228] Iteration 0, loss = 22.3826
I0818 12:02:49.566789 20702 solver.cpp:244]     Train net output #0: loss = 22.3826 (* 1 = 22.3826 loss)
I0818 12:02:49.566865 20702 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0818 12:03:00.206041 20702 solver.cpp:228] Iteration 100, loss = 2.34595
I0818 12:03:00.206131 20702 solver.cpp:244]     Train net output #0: loss = 2.05154 (* 1 = 2.05154 loss)
I0818 12:03:00.206154 20702 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0818 12:03:10.827883 20702 solver.cpp:228] Iteration 200, loss = 2.02286
I0818 12:03:10.827966 20702 solver.cpp:244]     Train net output #0: loss = 1.98133 (* 1 = 1.98133 loss)
I0818 12:03:10.827988 20702 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0818 12:03:21.447854 20702 solver.cpp:228] Iteration 300, loss = 1.96836
I0818 12:03:21.448009 20702 solver.cpp:244]     Train net output #0: loss = 2.0525 (* 1 = 2.0525 loss)
I0818 12:03:21.448031 20702 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0818 12:03:32.062479 20702 solver.cpp:228] Iteration 400, loss = 1.92635
I0818 12:03:32.062564 20702 solver.cpp:244]     Train net output #0: loss = 1.90633 (* 1 = 1.90633 loss)
I0818 12:03:32.062587 20702 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0818 12:03:42.694772 20702 solver.cpp:228] Iteration 500, loss = 1.90706
I0818 12:03:42.694846 20702 solver.cpp:244]     Train net output #0: loss = 1.90504 (* 1 = 1.90504 loss)
I0818 12:03:42.694867 20702 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0818 12:03:53.415524 20702 solver.cpp:228] Iteration 600, loss = 1.89424
I0818 12:03:53.415750 20702 solver.cpp:244]     Train net output #0: loss = 1.88328 (* 1 = 1.88328 loss)
I0818 12:03:53.415783 20702 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0818 12:04:04.154942 20702 solver.cpp:228] Iteration 700, loss = 1.86812
I0818 12:04:04.155017 20702 solver.cpp:244]     Train net output #0: loss = 1.84023 (* 1 = 1.84023 loss)
I0818 12:04:04.155040 20702 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0818 12:04:14.872674 20702 solver.cpp:228] Iteration 800, loss = 1.8622
I0818 12:04:14.872747 20702 solver.cpp:244]     Train net output #0: loss = 1.94345 (* 1 = 1.94345 loss)
I0818 12:04:14.872769 20702 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0818 12:04:25.582902 20702 solver.cpp:228] Iteration 900, loss = 1.84774
I0818 12:04:25.583163 20702 solver.cpp:244]     Train net output #0: loss = 1.82522 (* 1 = 1.82522 loss)
I0818 12:04:25.583199 20702 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0818 12:04:36.293761 20702 solver.cpp:228] Iteration 1000, loss = 1.83514
I0818 12:04:36.293833 20702 solver.cpp:244]     Train net output #0: loss = 1.83572 (* 1 = 1.83572 loss)
I0818 12:04:36.293856 20702 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0818 12:04:47.003954 20702 solver.cpp:228] Iteration 1100, loss = 1.83387
I0818 12:04:47.004027 20702 solver.cpp:244]     Train net output #0: loss = 1.84225 (* 1 = 1.84225 loss)
I0818 12:04:47.004050 20702 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0818 12:04:57.714607 20702 solver.cpp:228] Iteration 1200, loss = 1.81486
I0818 12:04:57.714792 20702 solver.cpp:244]     Train net output #0: loss = 1.79391 (* 1 = 1.79391 loss)
I0818 12:04:57.714820 20702 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0818 12:05:08.450933 20702 solver.cpp:228] Iteration 1300, loss = 1.81133
I0818 12:05:08.451009 20702 solver.cpp:244]     Train net output #0: loss = 1.86697 (* 1 = 1.86697 loss)
I0818 12:05:08.451033 20702 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0818 12:05:19.159057 20702 solver.cpp:228] Iteration 1400, loss = 1.79823
I0818 12:05:19.159140 20702 solver.cpp:244]     Train net output #0: loss = 1.79405 (* 1 = 1.79405 loss)
I0818 12:05:19.159162 20702 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0818 12:05:29.865154 20702 solver.cpp:228] Iteration 1500, loss = 1.79217
I0818 12:05:29.865380 20702 solver.cpp:244]     Train net output #0: loss = 1.78508 (* 1 = 1.78508 loss)
I0818 12:05:29.865411 20702 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0818 12:05:40.568845 20702 solver.cpp:228] Iteration 1600, loss = 1.79449
I0818 12:05:40.568922 20702 solver.cpp:244]     Train net output #0: loss = 1.77543 (* 1 = 1.77543 loss)
I0818 12:05:40.568943 20702 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0818 12:05:51.269263 20702 solver.cpp:228] Iteration 1700, loss = 1.7779
I0818 12:05:51.269345 20702 solver.cpp:244]     Train net output #0: loss = 1.78162 (* 1 = 1.78162 loss)
I0818 12:05:51.269366 20702 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0818 12:06:01.971180 20702 solver.cpp:228] Iteration 1800, loss = 1.77814
I0818 12:06:01.971349 20702 solver.cpp:244]     Train net output #0: loss = 1.82758 (* 1 = 1.82758 loss)
I0818 12:06:01.971376 20702 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0818 12:06:12.696323 20702 solver.cpp:228] Iteration 1900, loss = 1.76389
I0818 12:06:12.696400 20702 solver.cpp:244]     Train net output #0: loss = 1.75127 (* 1 = 1.75127 loss)
I0818 12:06:12.696422 20702 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0818 12:06:23.290397 20702 solver.cpp:337] Iteration 2000, Testing net (#0)
I0818 12:06:25.419018 20702 solver.cpp:404]     Test net output #0: loss = 1.78624 (* 1 = 1.78624 loss)
I0818 12:06:25.490304 20702 solver.cpp:228] Iteration 2000, loss = 1.76367
I0818 12:06:25.490353 20702 solver.cpp:244]     Train net output #0: loss = 1.75474 (* 1 = 1.75474 loss)
I0818 12:06:25.490381 20702 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0818 12:06:36.188606 20702 solver.cpp:228] Iteration 2100, loss = 1.76435
I0818 12:06:36.188786 20702 solver.cpp:244]     Train net output #0: loss = 1.74967 (* 1 = 1.74967 loss)
I0818 12:06:36.188822 20702 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0818 12:06:46.886032 20702 solver.cpp:228] Iteration 2200, loss = 1.74516
I0818 12:06:46.886111 20702 solver.cpp:244]     Train net output #0: loss = 1.71163 (* 1 = 1.71163 loss)
I0818 12:06:46.886132 20702 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0818 12:06:57.582697 20702 solver.cpp:228] Iteration 2300, loss = 1.74333
I0818 12:06:57.582782 20702 solver.cpp:244]     Train net output #0: loss = 1.81517 (* 1 = 1.81517 loss)
I0818 12:06:57.582804 20702 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0818 12:07:08.278568 20702 solver.cpp:228] Iteration 2400, loss = 1.73263
I0818 12:07:08.278697 20702 solver.cpp:244]     Train net output #0: loss = 1.72846 (* 1 = 1.72846 loss)
I0818 12:07:08.278723 20702 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0818 12:07:18.991502 20702 solver.cpp:228] Iteration 2500, loss = 1.74139
I0818 12:07:18.991580 20702 solver.cpp:244]     Train net output #0: loss = 1.73008 (* 1 = 1.73008 loss)
I0818 12:07:18.991602 20702 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0818 12:07:29.697829 20702 solver.cpp:228] Iteration 2600, loss = 1.73595
I0818 12:07:29.697919 20702 solver.cpp:244]     Train net output #0: loss = 1.72228 (* 1 = 1.72228 loss)
I0818 12:07:29.697940 20702 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0818 12:07:40.396817 20702 solver.cpp:228] Iteration 2700, loss = 1.71877
I0818 12:07:40.397105 20702 solver.cpp:244]     Train net output #0: loss = 1.7006 (* 1 = 1.7006 loss)
I0818 12:07:40.397142 20702 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0818 12:07:51.116681 20702 solver.cpp:228] Iteration 2800, loss = 1.72106
I0818 12:07:51.116758 20702 solver.cpp:244]     Train net output #0: loss = 1.77945 (* 1 = 1.77945 loss)
I0818 12:07:51.116780 20702 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0818 12:08:01.814301 20702 solver.cpp:228] Iteration 2900, loss = 1.71258
I0818 12:08:01.814383 20702 solver.cpp:244]     Train net output #0: loss = 1.71293 (* 1 = 1.71293 loss)
I0818 12:08:01.814406 20702 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0818 12:08:12.510813 20702 solver.cpp:228] Iteration 3000, loss = 1.71392
I0818 12:08:12.511045 20702 solver.cpp:244]     Train net output #0: loss = 1.68618 (* 1 = 1.68618 loss)
I0818 12:08:12.511071 20702 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0818 12:08:23.208734 20702 solver.cpp:228] Iteration 3100, loss = 1.71213
I0818 12:08:23.208807 20702 solver.cpp:244]     Train net output #0: loss = 1.73284 (* 1 = 1.73284 loss)
I0818 12:08:23.208830 20702 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0818 12:08:33.904858 20702 solver.cpp:228] Iteration 3200, loss = 1.69439
I0818 12:08:33.904940 20702 solver.cpp:244]     Train net output #0: loss = 1.66828 (* 1 = 1.66828 loss)
I0818 12:08:33.904963 20702 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0818 12:08:44.602020 20702 solver.cpp:228] Iteration 3300, loss = 1.69898
I0818 12:08:44.602185 20702 solver.cpp:244]     Train net output #0: loss = 1.77674 (* 1 = 1.77674 loss)
I0818 12:08:44.602213 20702 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0818 12:08:55.298140 20702 solver.cpp:228] Iteration 3400, loss = 1.69148
I0818 12:08:55.298213 20702 solver.cpp:244]     Train net output #0: loss = 1.68272 (* 1 = 1.68272 loss)
I0818 12:08:55.298233 20702 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0818 12:09:05.996157 20702 solver.cpp:228] Iteration 3500, loss = 1.69101
I0818 12:09:05.996240 20702 solver.cpp:244]     Train net output #0: loss = 1.68394 (* 1 = 1.68394 loss)
I0818 12:09:05.996263 20702 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0818 12:09:16.692364 20702 solver.cpp:228] Iteration 3600, loss = 1.68947
I0818 12:09:16.692519 20702 solver.cpp:244]     Train net output #0: loss = 1.69141 (* 1 = 1.69141 loss)
I0818 12:09:16.692545 20702 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0818 12:09:27.410043 20702 solver.cpp:228] Iteration 3700, loss = 1.67172
I0818 12:09:27.410133 20702 solver.cpp:244]     Train net output #0: loss = 1.65625 (* 1 = 1.65625 loss)
I0818 12:09:27.410157 20702 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0818 12:09:38.103299 20702 solver.cpp:228] Iteration 3800, loss = 1.67546
I0818 12:09:38.103376 20702 solver.cpp:244]     Train net output #0: loss = 1.71891 (* 1 = 1.71891 loss)
I0818 12:09:38.103399 20702 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0818 12:09:48.797253 20702 solver.cpp:228] Iteration 3900, loss = 1.66782
I0818 12:09:48.797427 20702 solver.cpp:244]     Train net output #0: loss = 1.68968 (* 1 = 1.68968 loss)
I0818 12:09:48.797461 20702 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0818 12:09:59.387269 20702 solver.cpp:337] Iteration 4000, Testing net (#0)
I0818 12:10:01.511833 20702 solver.cpp:404]     Test net output #0: loss = 1.68018 (* 1 = 1.68018 loss)
I0818 12:10:01.583008 20702 solver.cpp:228] Iteration 4000, loss = 1.66707
I0818 12:10:01.583081 20702 solver.cpp:244]     Train net output #0: loss = 1.63442 (* 1 = 1.63442 loss)
I0818 12:10:01.583106 20702 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0818 12:10:12.294107 20702 solver.cpp:228] Iteration 4100, loss = 1.67381
I0818 12:10:12.294186 20702 solver.cpp:244]     Train net output #0: loss = 1.70208 (* 1 = 1.70208 loss)
I0818 12:10:12.294209 20702 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0818 12:10:22.989270 20702 solver.cpp:228] Iteration 4200, loss = 1.65234
I0818 12:10:22.989500 20702 solver.cpp:244]     Train net output #0: loss = 1.6568 (* 1 = 1.6568 loss)
I0818 12:10:22.989526 20702 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0818 12:10:33.718344 20702 solver.cpp:228] Iteration 4300, loss = 1.65677
I0818 12:10:33.718487 20702 solver.cpp:244]     Train net output #0: loss = 1.70651 (* 1 = 1.70651 loss)
I0818 12:10:33.718534 20702 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0818 12:10:44.398085 20702 solver.cpp:228] Iteration 4400, loss = 1.65062
I0818 12:10:44.398157 20702 solver.cpp:244]     Train net output #0: loss = 1.65367 (* 1 = 1.65367 loss)
I0818 12:10:44.398185 20702 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0818 12:10:55.179989 20702 solver.cpp:228] Iteration 4500, loss = 1.64946
I0818 12:10:55.180213 20702 solver.cpp:244]     Train net output #0: loss = 1.64846 (* 1 = 1.64846 loss)
I0818 12:10:55.180249 20702 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0818 12:11:05.961287 20702 solver.cpp:228] Iteration 4600, loss = 1.65423
I0818 12:11:05.961371 20702 solver.cpp:244]     Train net output #0: loss = 1.68032 (* 1 = 1.68032 loss)
I0818 12:11:05.961395 20702 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0818 12:11:16.682515 20702 solver.cpp:228] Iteration 4700, loss = 1.6392
I0818 12:11:16.682598 20702 solver.cpp:244]     Train net output #0: loss = 1.58858 (* 1 = 1.58858 loss)
I0818 12:11:16.682620 20702 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0818 12:11:27.376574 20702 solver.cpp:228] Iteration 4800, loss = 1.64179
I0818 12:11:27.376773 20702 solver.cpp:244]     Train net output #0: loss = 1.6885 (* 1 = 1.6885 loss)
I0818 12:11:27.376797 20702 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0818 12:11:38.071894 20702 solver.cpp:228] Iteration 4900, loss = 1.63335
I0818 12:11:38.071965 20702 solver.cpp:244]     Train net output #0: loss = 1.66 (* 1 = 1.66 loss)
I0818 12:11:38.071986 20702 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0818 12:11:48.766268 20702 solver.cpp:228] Iteration 5000, loss = 1.6282
I0818 12:11:48.766332 20702 solver.cpp:244]     Train net output #0: loss = 1.58056 (* 1 = 1.58056 loss)
I0818 12:11:48.766353 20702 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0818 12:11:59.460346 20702 solver.cpp:228] Iteration 5100, loss = 1.6368
I0818 12:11:59.460518 20702 solver.cpp:244]     Train net output #0: loss = 1.66123 (* 1 = 1.66123 loss)
I0818 12:11:59.460541 20702 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0818 12:12:10.154768 20702 solver.cpp:228] Iteration 5200, loss = 1.62165
I0818 12:12:10.154844 20702 solver.cpp:244]     Train net output #0: loss = 1.60181 (* 1 = 1.60181 loss)
I0818 12:12:10.154866 20702 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0818 12:12:20.867580 20702 solver.cpp:228] Iteration 5300, loss = 1.62051
I0818 12:12:20.867657 20702 solver.cpp:244]     Train net output #0: loss = 1.6507 (* 1 = 1.6507 loss)
I0818 12:12:20.867679 20702 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0818 12:12:31.615478 20702 solver.cpp:228] Iteration 5400, loss = 1.61587
I0818 12:12:31.615690 20702 solver.cpp:244]     Train net output #0: loss = 1.63215 (* 1 = 1.63215 loss)
I0818 12:12:31.615720 20702 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0818 12:12:42.370400 20702 solver.cpp:228] Iteration 5500, loss = 1.61478
I0818 12:12:42.370471 20702 solver.cpp:244]     Train net output #0: loss = 1.57281 (* 1 = 1.57281 loss)
I0818 12:12:42.370493 20702 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0818 12:12:53.127501 20702 solver.cpp:228] Iteration 5600, loss = 1.61987
I0818 12:12:53.127573 20702 solver.cpp:244]     Train net output #0: loss = 1.66228 (* 1 = 1.66228 loss)
I0818 12:12:53.127594 20702 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0818 12:13:03.875213 20702 solver.cpp:228] Iteration 5700, loss = 1.60156
I0818 12:13:03.875444 20702 solver.cpp:244]     Train net output #0: loss = 1.55129 (* 1 = 1.55129 loss)
I0818 12:13:03.875468 20702 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0818 12:13:14.568617 20702 solver.cpp:228] Iteration 5800, loss = 1.59846
I0818 12:13:14.568691 20702 solver.cpp:244]     Train net output #0: loss = 1.62963 (* 1 = 1.62963 loss)
I0818 12:13:14.568711 20702 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0818 12:13:25.261570 20702 solver.cpp:228] Iteration 5900, loss = 1.60091
I0818 12:13:25.261644 20702 solver.cpp:244]     Train net output #0: loss = 1.61792 (* 1 = 1.61792 loss)
I0818 12:13:25.261665 20702 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0818 12:13:35.849624 20702 solver.cpp:337] Iteration 6000, Testing net (#0)
I0818 12:13:37.985867 20702 solver.cpp:404]     Test net output #0: loss = 1.61664 (* 1 = 1.61664 loss)
I0818 12:13:38.056813 20702 solver.cpp:228] Iteration 6000, loss = 1.59055
I0818 12:13:38.056861 20702 solver.cpp:244]     Train net output #0: loss = 1.53347 (* 1 = 1.53347 loss)
I0818 12:13:38.056885 20702 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I0818 12:13:48.750681 20702 solver.cpp:228] Iteration 6100, loss = 1.60293
I0818 12:13:48.750757 20702 solver.cpp:244]     Train net output #0: loss = 1.63146 (* 1 = 1.63146 loss)
I0818 12:13:48.750778 20702 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I0818 12:13:59.440174 20702 solver.cpp:228] Iteration 6200, loss = 1.58465
I0818 12:13:59.440258 20702 solver.cpp:244]     Train net output #0: loss = 1.5454 (* 1 = 1.5454 loss)
I0818 12:13:59.440279 20702 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I0818 12:14:10.131744 20702 solver.cpp:228] Iteration 6300, loss = 1.58126
I0818 12:14:10.131963 20702 solver.cpp:244]     Train net output #0: loss = 1.6222 (* 1 = 1.6222 loss)
I0818 12:14:10.131999 20702 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I0818 12:14:20.821714 20702 solver.cpp:228] Iteration 6400, loss = 1.59168
I0818 12:14:20.821790 20702 solver.cpp:244]     Train net output #0: loss = 1.61226 (* 1 = 1.61226 loss)
I0818 12:14:20.821810 20702 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I0818 12:14:31.512656 20702 solver.cpp:228] Iteration 6500, loss = 1.57644
I0818 12:14:31.512742 20702 solver.cpp:244]     Train net output #0: loss = 1.52988 (* 1 = 1.52988 loss)
I0818 12:14:31.512764 20702 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I0818 12:14:42.204368 20702 solver.cpp:228] Iteration 6600, loss = 1.59011
I0818 12:14:42.204525 20702 solver.cpp:244]     Train net output #0: loss = 1.62691 (* 1 = 1.62691 loss)
I0818 12:14:42.204548 20702 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I0818 12:14:52.895601 20702 solver.cpp:228] Iteration 6700, loss = 1.5703
I0818 12:14:52.895678 20702 solver.cpp:244]     Train net output #0: loss = 1.51788 (* 1 = 1.51788 loss)
I0818 12:14:52.895699 20702 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I0818 12:15:03.601511 20702 solver.cpp:228] Iteration 6800, loss = 1.56843
I0818 12:15:03.601583 20702 solver.cpp:244]     Train net output #0: loss = 1.67003 (* 1 = 1.67003 loss)
I0818 12:15:03.601604 20702 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I0818 12:15:14.309998 20702 solver.cpp:228] Iteration 6900, loss = 1.57143
I0818 12:15:14.310240 20702 solver.cpp:244]     Train net output #0: loss = 1.5993 (* 1 = 1.5993 loss)
I0818 12:15:14.310272 20702 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I0818 12:15:25.023815 20702 solver.cpp:228] Iteration 7000, loss = 1.56088
I0818 12:15:25.023893 20702 solver.cpp:244]     Train net output #0: loss = 1.48323 (* 1 = 1.48323 loss)
I0818 12:15:25.023916 20702 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I0818 12:15:35.716859 20702 solver.cpp:228] Iteration 7100, loss = 1.57229
I0818 12:15:35.716944 20702 solver.cpp:244]     Train net output #0: loss = 1.60591 (* 1 = 1.60591 loss)
I0818 12:15:35.716967 20702 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I0818 12:15:46.410681 20702 solver.cpp:228] Iteration 7200, loss = 1.55449
I0818 12:15:46.410944 20702 solver.cpp:244]     Train net output #0: loss = 1.49339 (* 1 = 1.49339 loss)
I0818 12:15:46.410974 20702 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I0818 12:15:57.101950 20702 solver.cpp:228] Iteration 7300, loss = 1.55205
I0818 12:15:57.102038 20702 solver.cpp:244]     Train net output #0: loss = 1.59087 (* 1 = 1.59087 loss)
I0818 12:15:57.102059 20702 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I0818 12:16:07.795121 20702 solver.cpp:228] Iteration 7400, loss = 1.55565
I0818 12:16:07.795202 20702 solver.cpp:244]     Train net output #0: loss = 1.5702 (* 1 = 1.5702 loss)
I0818 12:16:07.795222 20702 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I0818 12:16:18.487625 20702 solver.cpp:228] Iteration 7500, loss = 1.54719
I0818 12:16:18.487833 20702 solver.cpp:244]     Train net output #0: loss = 1.45604 (* 1 = 1.45604 loss)
I0818 12:16:18.487862 20702 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I0818 12:16:29.201499 20702 solver.cpp:228] Iteration 7600, loss = 1.55811
I0818 12:16:29.201576 20702 solver.cpp:244]     Train net output #0: loss = 1.59401 (* 1 = 1.59401 loss)
I0818 12:16:29.201601 20702 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I0818 12:16:39.893384 20702 solver.cpp:228] Iteration 7700, loss = 1.54038
I0818 12:16:39.893460 20702 solver.cpp:244]     Train net output #0: loss = 1.48467 (* 1 = 1.48467 loss)
I0818 12:16:39.893481 20702 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I0818 12:16:50.584866 20702 solver.cpp:228] Iteration 7800, loss = 1.53479
I0818 12:16:50.585041 20702 solver.cpp:244]     Train net output #0: loss = 1.53516 (* 1 = 1.53516 loss)
I0818 12:16:50.585065 20702 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I0818 12:17:01.276156 20702 solver.cpp:228] Iteration 7900, loss = 1.53725
I0818 12:17:01.276240 20702 solver.cpp:244]     Train net output #0: loss = 1.51204 (* 1 = 1.51204 loss)
I0818 12:17:01.276262 20702 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I0818 12:17:11.863884 20702 solver.cpp:337] Iteration 8000, Testing net (#0)
I0818 12:17:13.994411 20702 solver.cpp:404]     Test net output #0: loss = 1.57794 (* 1 = 1.57794 loss)
I0818 12:17:14.065546 20702 solver.cpp:228] Iteration 8000, loss = 1.53087
I0818 12:17:14.065598 20702 solver.cpp:244]     Train net output #0: loss = 1.46862 (* 1 = 1.46862 loss)
I0818 12:17:14.065620 20702 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I0818 12:17:24.785212 20702 solver.cpp:228] Iteration 8100, loss = 1.54656
I0818 12:17:24.785408 20702 solver.cpp:244]     Train net output #0: loss = 1.58449 (* 1 = 1.58449 loss)
I0818 12:17:24.785430 20702 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I0818 12:17:35.538414 20702 solver.cpp:228] Iteration 8200, loss = 1.52507
I0818 12:17:35.538496 20702 solver.cpp:244]     Train net output #0: loss = 1.40197 (* 1 = 1.40197 loss)
I0818 12:17:35.538517 20702 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I0818 12:17:46.292172 20702 solver.cpp:228] Iteration 8300, loss = 1.51997
I0818 12:17:46.292242 20702 solver.cpp:244]     Train net output #0: loss = 1.53584 (* 1 = 1.53584 loss)
I0818 12:17:46.292263 20702 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I0818 12:17:56.998112 20702 solver.cpp:228] Iteration 8400, loss = 1.52048
I0818 12:17:56.998361 20702 solver.cpp:244]     Train net output #0: loss = 1.55353 (* 1 = 1.55353 loss)
I0818 12:17:56.998397 20702 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I0818 12:18:07.692149 20702 solver.cpp:228] Iteration 8500, loss = 1.51672
I0818 12:18:07.692226 20702 solver.cpp:244]     Train net output #0: loss = 1.43503 (* 1 = 1.43503 loss)
I0818 12:18:07.692248 20702 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I0818 12:18:18.384976 20702 solver.cpp:228] Iteration 8600, loss = 1.52973
I0818 12:18:18.385046 20702 solver.cpp:244]     Train net output #0: loss = 1.58991 (* 1 = 1.58991 loss)
I0818 12:18:18.385067 20702 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I0818 12:18:29.075929 20702 solver.cpp:228] Iteration 8700, loss = 1.51129
I0818 12:18:29.076124 20702 solver.cpp:244]     Train net output #0: loss = 1.41042 (* 1 = 1.41042 loss)
I0818 12:18:29.076151 20702 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I0818 12:18:39.768898 20702 solver.cpp:228] Iteration 8800, loss = 1.50832
I0818 12:18:39.768975 20702 solver.cpp:244]     Train net output #0: loss = 1.55353 (* 1 = 1.55353 loss)
I0818 12:18:39.768997 20702 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I0818 12:18:50.461205 20702 solver.cpp:228] Iteration 8900, loss = 1.5117
I0818 12:18:50.461279 20702 solver.cpp:244]     Train net output #0: loss = 1.51647 (* 1 = 1.51647 loss)
I0818 12:18:50.461300 20702 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I0818 12:19:01.152189 20702 solver.cpp:228] Iteration 9000, loss = 1.49984
I0818 12:19:01.152463 20702 solver.cpp:244]     Train net output #0: loss = 1.42392 (* 1 = 1.42392 loss)
I0818 12:19:01.152503 20702 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I0818 12:19:11.844070 20702 solver.cpp:228] Iteration 9100, loss = 1.51337
I0818 12:19:11.844146 20702 solver.cpp:244]     Train net output #0: loss = 1.56298 (* 1 = 1.56298 loss)
I0818 12:19:11.844168 20702 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I0818 12:19:22.535238 20702 solver.cpp:228] Iteration 9200, loss = 1.50405
I0818 12:19:22.535315 20702 solver.cpp:244]     Train net output #0: loss = 1.417 (* 1 = 1.417 loss)
I0818 12:19:22.535336 20702 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I0818 12:19:33.227322 20702 solver.cpp:228] Iteration 9300, loss = 1.49606
I0818 12:19:33.227494 20702 solver.cpp:244]     Train net output #0: loss = 1.53348 (* 1 = 1.53348 loss)
I0818 12:19:33.227517 20702 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I0818 12:19:43.917886 20702 solver.cpp:228] Iteration 9400, loss = 1.5007
I0818 12:19:43.917961 20702 solver.cpp:244]     Train net output #0: loss = 1.49248 (* 1 = 1.49248 loss)
I0818 12:19:43.917982 20702 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I0818 12:19:54.610927 20702 solver.cpp:228] Iteration 9500, loss = 1.49073
I0818 12:19:54.611007 20702 solver.cpp:244]     Train net output #0: loss = 1.44783 (* 1 = 1.44783 loss)
I0818 12:19:54.611028 20702 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I0818 12:20:05.313905 20702 solver.cpp:228] Iteration 9600, loss = 1.5028
I0818 12:20:05.314126 20702 solver.cpp:244]     Train net output #0: loss = 1.55495 (* 1 = 1.55495 loss)
I0818 12:20:05.314157 20702 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I0818 12:20:16.014410 20702 solver.cpp:228] Iteration 9700, loss = 1.48672
I0818 12:20:16.014490 20702 solver.cpp:244]     Train net output #0: loss = 1.39939 (* 1 = 1.39939 loss)
I0818 12:20:16.014513 20702 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I0818 12:20:26.705919 20702 solver.cpp:228] Iteration 9800, loss = 1.4794
I0818 12:20:26.706001 20702 solver.cpp:244]     Train net output #0: loss = 1.50373 (* 1 = 1.50373 loss)
I0818 12:20:26.706023 20702 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I0818 12:20:37.396373 20702 solver.cpp:228] Iteration 9900, loss = 1.48584
I0818 12:20:37.396590 20702 solver.cpp:244]     Train net output #0: loss = 1.50841 (* 1 = 1.50841 loss)
I0818 12:20:37.396636 20702 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I0818 12:20:47.982183 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_10000.caffemodel
I0818 12:20:48.031289 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_10000.solverstate
I0818 12:20:48.036722 20702 solver.cpp:337] Iteration 10000, Testing net (#0)
I0818 12:20:50.123937 20702 solver.cpp:404]     Test net output #0: loss = 1.52178 (* 1 = 1.52178 loss)
I0818 12:20:50.195024 20702 solver.cpp:228] Iteration 10000, loss = 1.47847
I0818 12:20:50.195072 20702 solver.cpp:244]     Train net output #0: loss = 1.4152 (* 1 = 1.4152 loss)
I0818 12:20:50.195096 20702 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0818 12:21:00.885736 20702 solver.cpp:228] Iteration 10100, loss = 1.48891
I0818 12:21:00.885817 20702 solver.cpp:244]     Train net output #0: loss = 1.52596 (* 1 = 1.52596 loss)
I0818 12:21:00.885838 20702 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0818 12:21:11.576059 20702 solver.cpp:228] Iteration 10200, loss = 1.47369
I0818 12:21:11.576262 20702 solver.cpp:244]     Train net output #0: loss = 1.38191 (* 1 = 1.38191 loss)
I0818 12:21:11.576289 20702 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0818 12:21:22.267515 20702 solver.cpp:228] Iteration 10300, loss = 1.47329
I0818 12:21:22.267591 20702 solver.cpp:244]     Train net output #0: loss = 1.48825 (* 1 = 1.48825 loss)
I0818 12:21:22.267612 20702 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0818 12:21:32.957726 20702 solver.cpp:228] Iteration 10400, loss = 1.47636
I0818 12:21:32.957809 20702 solver.cpp:244]     Train net output #0: loss = 1.49411 (* 1 = 1.49411 loss)
I0818 12:21:32.957831 20702 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0818 12:21:43.647301 20702 solver.cpp:228] Iteration 10500, loss = 1.46595
I0818 12:21:43.647461 20702 solver.cpp:244]     Train net output #0: loss = 1.34755 (* 1 = 1.34755 loss)
I0818 12:21:43.647485 20702 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0818 12:21:54.339355 20702 solver.cpp:228] Iteration 10600, loss = 1.47291
I0818 12:21:54.339433 20702 solver.cpp:244]     Train net output #0: loss = 1.53599 (* 1 = 1.53599 loss)
I0818 12:21:54.339454 20702 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0818 12:22:05.031271 20702 solver.cpp:228] Iteration 10700, loss = 1.46316
I0818 12:22:05.031358 20702 solver.cpp:244]     Train net output #0: loss = 1.37501 (* 1 = 1.37501 loss)
I0818 12:22:05.031380 20702 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0818 12:22:15.730859 20702 solver.cpp:228] Iteration 10800, loss = 1.45679
I0818 12:22:15.731017 20702 solver.cpp:244]     Train net output #0: loss = 1.48047 (* 1 = 1.48047 loss)
I0818 12:22:15.731043 20702 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0818 12:22:26.436822 20702 solver.cpp:228] Iteration 10900, loss = 1.45639
I0818 12:22:26.436905 20702 solver.cpp:244]     Train net output #0: loss = 1.45097 (* 1 = 1.45097 loss)
I0818 12:22:26.436928 20702 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0818 12:22:37.127948 20702 solver.cpp:228] Iteration 11000, loss = 1.45239
I0818 12:22:37.128021 20702 solver.cpp:244]     Train net output #0: loss = 1.35965 (* 1 = 1.35965 loss)
I0818 12:22:37.128042 20702 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0818 12:22:47.818830 20702 solver.cpp:228] Iteration 11100, loss = 1.46205
I0818 12:22:47.818992 20702 solver.cpp:244]     Train net output #0: loss = 1.53026 (* 1 = 1.53026 loss)
I0818 12:22:47.819016 20702 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0818 12:22:58.507689 20702 solver.cpp:228] Iteration 11200, loss = 1.44943
I0818 12:22:58.507767 20702 solver.cpp:244]     Train net output #0: loss = 1.3897 (* 1 = 1.3897 loss)
I0818 12:22:58.507789 20702 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0818 12:23:09.197360 20702 solver.cpp:228] Iteration 11300, loss = 1.44338
I0818 12:23:09.197428 20702 solver.cpp:244]     Train net output #0: loss = 1.43262 (* 1 = 1.43262 loss)
I0818 12:23:09.197450 20702 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I0818 12:23:19.888157 20702 solver.cpp:228] Iteration 11400, loss = 1.44615
I0818 12:23:19.888373 20702 solver.cpp:244]     Train net output #0: loss = 1.43589 (* 1 = 1.43589 loss)
I0818 12:23:19.888403 20702 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0818 12:23:30.599681 20702 solver.cpp:228] Iteration 11500, loss = 1.44027
I0818 12:23:30.599767 20702 solver.cpp:244]     Train net output #0: loss = 1.36474 (* 1 = 1.36474 loss)
I0818 12:23:30.599791 20702 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0818 12:23:41.292287 20702 solver.cpp:228] Iteration 11600, loss = 1.44921
I0818 12:23:41.292363 20702 solver.cpp:244]     Train net output #0: loss = 1.46989 (* 1 = 1.46989 loss)
I0818 12:23:41.292385 20702 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0818 12:23:51.983379 20702 solver.cpp:228] Iteration 11700, loss = 1.43453
I0818 12:23:51.983558 20702 solver.cpp:244]     Train net output #0: loss = 1.30267 (* 1 = 1.30267 loss)
I0818 12:23:51.983594 20702 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0818 12:24:02.697916 20702 solver.cpp:228] Iteration 11800, loss = 1.43241
I0818 12:24:02.698005 20702 solver.cpp:244]     Train net output #0: loss = 1.46177 (* 1 = 1.46177 loss)
I0818 12:24:02.698029 20702 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0818 12:24:13.387967 20702 solver.cpp:228] Iteration 11900, loss = 1.43576
I0818 12:24:13.388043 20702 solver.cpp:244]     Train net output #0: loss = 1.44095 (* 1 = 1.44095 loss)
I0818 12:24:13.388064 20702 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I0818 12:24:23.974149 20702 solver.cpp:337] Iteration 12000, Testing net (#0)
I0818 12:24:26.130790 20702 solver.cpp:404]     Test net output #0: loss = 1.5056 (* 1 = 1.5056 loss)
I0818 12:24:26.201802 20702 solver.cpp:228] Iteration 12000, loss = 1.43176
I0818 12:24:26.201840 20702 solver.cpp:244]     Train net output #0: loss = 1.35874 (* 1 = 1.35874 loss)
I0818 12:24:26.201870 20702 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0818 12:24:36.890214 20702 solver.cpp:228] Iteration 12100, loss = 1.43975
I0818 12:24:36.890292 20702 solver.cpp:244]     Train net output #0: loss = 1.4947 (* 1 = 1.4947 loss)
I0818 12:24:36.890314 20702 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I0818 12:24:47.578969 20702 solver.cpp:228] Iteration 12200, loss = 1.42437
I0818 12:24:47.579046 20702 solver.cpp:244]     Train net output #0: loss = 1.36414 (* 1 = 1.36414 loss)
I0818 12:24:47.579068 20702 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0818 12:24:58.268419 20702 solver.cpp:228] Iteration 12300, loss = 1.4201
I0818 12:24:58.268579 20702 solver.cpp:244]     Train net output #0: loss = 1.41636 (* 1 = 1.41636 loss)
I0818 12:24:58.268607 20702 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0818 12:25:08.983922 20702 solver.cpp:228] Iteration 12400, loss = 1.42626
I0818 12:25:08.984004 20702 solver.cpp:244]     Train net output #0: loss = 1.41967 (* 1 = 1.41967 loss)
I0818 12:25:08.984025 20702 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0818 12:25:19.675642 20702 solver.cpp:228] Iteration 12500, loss = 1.41471
I0818 12:25:19.675720 20702 solver.cpp:244]     Train net output #0: loss = 1.3327 (* 1 = 1.3327 loss)
I0818 12:25:19.675741 20702 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0818 12:25:30.368120 20702 solver.cpp:228] Iteration 12600, loss = 1.42509
I0818 12:25:30.368415 20702 solver.cpp:244]     Train net output #0: loss = 1.47257 (* 1 = 1.47257 loss)
I0818 12:25:30.368446 20702 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0818 12:25:41.079466 20702 solver.cpp:228] Iteration 12700, loss = 1.40919
I0818 12:25:41.079543 20702 solver.cpp:244]     Train net output #0: loss = 1.30258 (* 1 = 1.30258 loss)
I0818 12:25:41.079566 20702 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I0818 12:25:51.768735 20702 solver.cpp:228] Iteration 12800, loss = 1.40744
I0818 12:25:51.768801 20702 solver.cpp:244]     Train net output #0: loss = 1.42155 (* 1 = 1.42155 loss)
I0818 12:25:51.768826 20702 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0818 12:26:02.458076 20702 solver.cpp:228] Iteration 12900, loss = 1.41545
I0818 12:26:02.458243 20702 solver.cpp:244]     Train net output #0: loss = 1.40088 (* 1 = 1.40088 loss)
I0818 12:26:02.458267 20702 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0818 12:26:13.146440 20702 solver.cpp:228] Iteration 13000, loss = 1.40782
I0818 12:26:13.146517 20702 solver.cpp:244]     Train net output #0: loss = 1.31469 (* 1 = 1.31469 loss)
I0818 12:26:13.146539 20702 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0818 12:26:23.835678 20702 solver.cpp:228] Iteration 13100, loss = 1.41738
I0818 12:26:23.835744 20702 solver.cpp:244]     Train net output #0: loss = 1.46513 (* 1 = 1.46513 loss)
I0818 12:26:23.835767 20702 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I0818 12:26:34.525987 20702 solver.cpp:228] Iteration 13200, loss = 1.40203
I0818 12:26:34.526140 20702 solver.cpp:244]     Train net output #0: loss = 1.29409 (* 1 = 1.29409 loss)
I0818 12:26:34.526166 20702 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0818 12:26:45.216989 20702 solver.cpp:228] Iteration 13300, loss = 1.3992
I0818 12:26:45.217063 20702 solver.cpp:244]     Train net output #0: loss = 1.41777 (* 1 = 1.41777 loss)
I0818 12:26:45.217085 20702 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I0818 12:26:55.906690 20702 solver.cpp:228] Iteration 13400, loss = 1.40453
I0818 12:26:55.906762 20702 solver.cpp:244]     Train net output #0: loss = 1.37369 (* 1 = 1.37369 loss)
I0818 12:26:55.906785 20702 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0818 12:27:06.596549 20702 solver.cpp:228] Iteration 13500, loss = 1.40117
I0818 12:27:06.596760 20702 solver.cpp:244]     Train net output #0: loss = 1.30501 (* 1 = 1.30501 loss)
I0818 12:27:06.596788 20702 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0818 12:27:17.300977 20702 solver.cpp:228] Iteration 13600, loss = 1.40649
I0818 12:27:17.301051 20702 solver.cpp:244]     Train net output #0: loss = 1.46155 (* 1 = 1.46155 loss)
I0818 12:27:17.301074 20702 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0818 12:27:28.002465 20702 solver.cpp:228] Iteration 13700, loss = 1.38724
I0818 12:27:28.002549 20702 solver.cpp:244]     Train net output #0: loss = 1.25794 (* 1 = 1.25794 loss)
I0818 12:27:28.002573 20702 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I0818 12:27:38.693720 20702 solver.cpp:228] Iteration 13800, loss = 1.38724
I0818 12:27:38.693902 20702 solver.cpp:244]     Train net output #0: loss = 1.38145 (* 1 = 1.38145 loss)
I0818 12:27:38.693928 20702 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0818 12:27:49.385385 20702 solver.cpp:228] Iteration 13900, loss = 1.39349
I0818 12:27:49.385459 20702 solver.cpp:244]     Train net output #0: loss = 1.39966 (* 1 = 1.39966 loss)
I0818 12:27:49.385481 20702 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I0818 12:27:59.969949 20702 solver.cpp:337] Iteration 14000, Testing net (#0)
I0818 12:28:02.092406 20702 solver.cpp:404]     Test net output #0: loss = 1.44973 (* 1 = 1.44973 loss)
I0818 12:28:02.163321 20702 solver.cpp:228] Iteration 14000, loss = 1.38424
I0818 12:28:02.163369 20702 solver.cpp:244]     Train net output #0: loss = 1.27677 (* 1 = 1.27677 loss)
I0818 12:28:02.163394 20702 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0818 12:28:12.855620 20702 solver.cpp:228] Iteration 14100, loss = 1.39672
I0818 12:28:12.855806 20702 solver.cpp:244]     Train net output #0: loss = 1.47853 (* 1 = 1.47853 loss)
I0818 12:28:12.855839 20702 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0818 12:28:23.569808 20702 solver.cpp:228] Iteration 14200, loss = 1.37806
I0818 12:28:23.569885 20702 solver.cpp:244]     Train net output #0: loss = 1.30972 (* 1 = 1.30972 loss)
I0818 12:28:23.569908 20702 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0818 12:28:34.262006 20702 solver.cpp:228] Iteration 14300, loss = 1.37786
I0818 12:28:34.262091 20702 solver.cpp:244]     Train net output #0: loss = 1.38925 (* 1 = 1.38925 loss)
I0818 12:28:34.262118 20702 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I0818 12:28:44.953552 20702 solver.cpp:228] Iteration 14400, loss = 1.38019
I0818 12:28:44.953732 20702 solver.cpp:244]     Train net output #0: loss = 1.36507 (* 1 = 1.36507 loss)
I0818 12:28:44.953768 20702 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0818 12:28:55.668678 20702 solver.cpp:228] Iteration 14500, loss = 1.37655
I0818 12:28:55.668762 20702 solver.cpp:244]     Train net output #0: loss = 1.25431 (* 1 = 1.25431 loss)
I0818 12:28:55.668786 20702 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0818 12:29:06.359771 20702 solver.cpp:228] Iteration 14600, loss = 1.38736
I0818 12:29:06.359843 20702 solver.cpp:244]     Train net output #0: loss = 1.44698 (* 1 = 1.44698 loss)
I0818 12:29:06.359863 20702 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0818 12:29:17.050542 20702 solver.cpp:228] Iteration 14700, loss = 1.36901
I0818 12:29:17.050710 20702 solver.cpp:244]     Train net output #0: loss = 1.25143 (* 1 = 1.25143 loss)
I0818 12:29:17.050734 20702 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0818 12:29:27.740272 20702 solver.cpp:228] Iteration 14800, loss = 1.36952
I0818 12:29:27.740357 20702 solver.cpp:244]     Train net output #0: loss = 1.34955 (* 1 = 1.34955 loss)
I0818 12:29:27.740381 20702 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0818 12:29:38.430140 20702 solver.cpp:228] Iteration 14900, loss = 1.36982
I0818 12:29:38.430209 20702 solver.cpp:244]     Train net output #0: loss = 1.3661 (* 1 = 1.3661 loss)
I0818 12:29:38.430232 20702 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I0818 12:29:49.121294 20702 solver.cpp:228] Iteration 15000, loss = 1.36587
I0818 12:29:49.121526 20702 solver.cpp:244]     Train net output #0: loss = 1.27991 (* 1 = 1.27991 loss)
I0818 12:29:49.121551 20702 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0818 12:29:59.811540 20702 solver.cpp:228] Iteration 15100, loss = 1.3775
I0818 12:29:59.811626 20702 solver.cpp:244]     Train net output #0: loss = 1.44966 (* 1 = 1.44966 loss)
I0818 12:29:59.811648 20702 sgd_solver.cpp:106] Iteration 15100, lr = 0.001
I0818 12:30:10.524147 20702 solver.cpp:228] Iteration 15200, loss = 1.36097
I0818 12:30:10.524227 20702 solver.cpp:244]     Train net output #0: loss = 1.23731 (* 1 = 1.23731 loss)
I0818 12:30:10.524250 20702 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0818 12:30:21.212724 20702 solver.cpp:228] Iteration 15300, loss = 1.35266
I0818 12:30:21.212944 20702 solver.cpp:244]     Train net output #0: loss = 1.36188 (* 1 = 1.36188 loss)
I0818 12:30:21.212977 20702 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I0818 12:30:31.904283 20702 solver.cpp:228] Iteration 15400, loss = 1.36122
I0818 12:30:31.904364 20702 solver.cpp:244]     Train net output #0: loss = 1.36043 (* 1 = 1.36043 loss)
I0818 12:30:31.904386 20702 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0818 12:30:42.593211 20702 solver.cpp:228] Iteration 15500, loss = 1.35353
I0818 12:30:42.593287 20702 solver.cpp:244]     Train net output #0: loss = 1.2435 (* 1 = 1.2435 loss)
I0818 12:30:42.593308 20702 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I0818 12:30:53.280535 20702 solver.cpp:228] Iteration 15600, loss = 1.36551
I0818 12:30:53.280738 20702 solver.cpp:244]     Train net output #0: loss = 1.41916 (* 1 = 1.41916 loss)
I0818 12:30:53.280763 20702 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0818 12:31:03.971791 20702 solver.cpp:228] Iteration 15700, loss = 1.34922
I0818 12:31:03.971875 20702 solver.cpp:244]     Train net output #0: loss = 1.23847 (* 1 = 1.23847 loss)
I0818 12:31:03.971899 20702 sgd_solver.cpp:106] Iteration 15700, lr = 0.001
I0818 12:31:14.661059 20702 solver.cpp:228] Iteration 15800, loss = 1.34791
I0818 12:31:14.661134 20702 solver.cpp:244]     Train net output #0: loss = 1.3616 (* 1 = 1.3616 loss)
I0818 12:31:14.661156 20702 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0818 12:31:25.350270 20702 solver.cpp:228] Iteration 15900, loss = 1.35043
I0818 12:31:25.350440 20702 solver.cpp:244]     Train net output #0: loss = 1.35484 (* 1 = 1.35484 loss)
I0818 12:31:25.350466 20702 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I0818 12:31:35.933200 20702 solver.cpp:337] Iteration 16000, Testing net (#0)
I0818 12:31:38.055011 20702 solver.cpp:404]     Test net output #0: loss = 1.41195 (* 1 = 1.41195 loss)
I0818 12:31:38.125943 20702 solver.cpp:228] Iteration 16000, loss = 1.34574
I0818 12:31:38.125982 20702 solver.cpp:244]     Train net output #0: loss = 1.25608 (* 1 = 1.25608 loss)
I0818 12:31:38.126008 20702 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0818 12:31:48.815270 20702 solver.cpp:228] Iteration 16100, loss = 1.35607
I0818 12:31:48.815335 20702 solver.cpp:244]     Train net output #0: loss = 1.40702 (* 1 = 1.40702 loss)
I0818 12:31:48.815358 20702 sgd_solver.cpp:106] Iteration 16100, lr = 0.001
I0818 12:31:59.504207 20702 solver.cpp:228] Iteration 16200, loss = 1.33836
I0818 12:31:59.504472 20702 solver.cpp:244]     Train net output #0: loss = 1.22444 (* 1 = 1.22444 loss)
I0818 12:31:59.504510 20702 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0818 12:32:10.225428 20702 solver.cpp:228] Iteration 16300, loss = 1.33687
I0818 12:32:10.225503 20702 solver.cpp:244]     Train net output #0: loss = 1.31616 (* 1 = 1.31616 loss)
I0818 12:32:10.225525 20702 sgd_solver.cpp:106] Iteration 16300, lr = 0.001
I0818 12:32:20.935241 20702 solver.cpp:228] Iteration 16400, loss = 1.33884
I0818 12:32:20.935318 20702 solver.cpp:244]     Train net output #0: loss = 1.33192 (* 1 = 1.33192 loss)
I0818 12:32:20.935343 20702 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0818 12:32:31.645074 20702 solver.cpp:228] Iteration 16500, loss = 1.33843
I0818 12:32:31.645336 20702 solver.cpp:244]     Train net output #0: loss = 1.20315 (* 1 = 1.20315 loss)
I0818 12:32:31.645373 20702 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0818 12:32:42.356405 20702 solver.cpp:228] Iteration 16600, loss = 1.34944
I0818 12:32:42.356482 20702 solver.cpp:244]     Train net output #0: loss = 1.40662 (* 1 = 1.40662 loss)
I0818 12:32:42.356503 20702 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0818 12:32:53.048272 20702 solver.cpp:228] Iteration 16700, loss = 1.33058
I0818 12:32:53.048349 20702 solver.cpp:244]     Train net output #0: loss = 1.19447 (* 1 = 1.19447 loss)
I0818 12:32:53.048370 20702 sgd_solver.cpp:106] Iteration 16700, lr = 0.001
I0818 12:33:03.739106 20702 solver.cpp:228] Iteration 16800, loss = 1.32922
I0818 12:33:03.739285 20702 solver.cpp:244]     Train net output #0: loss = 1.30097 (* 1 = 1.30097 loss)
I0818 12:33:03.739315 20702 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0818 12:33:14.452483 20702 solver.cpp:228] Iteration 16900, loss = 1.33327
I0818 12:33:14.452564 20702 solver.cpp:244]     Train net output #0: loss = 1.32273 (* 1 = 1.32273 loss)
I0818 12:33:14.452586 20702 sgd_solver.cpp:106] Iteration 16900, lr = 0.001
I0818 12:33:25.143173 20702 solver.cpp:228] Iteration 17000, loss = 1.32673
I0818 12:33:25.143250 20702 solver.cpp:244]     Train net output #0: loss = 1.26119 (* 1 = 1.26119 loss)
I0818 12:33:25.143272 20702 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0818 12:33:35.832571 20702 solver.cpp:228] Iteration 17100, loss = 1.33575
I0818 12:33:35.832839 20702 solver.cpp:244]     Train net output #0: loss = 1.37702 (* 1 = 1.37702 loss)
I0818 12:33:35.832868 20702 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I0818 12:33:46.544565 20702 solver.cpp:228] Iteration 17200, loss = 1.31904
I0818 12:33:46.544646 20702 solver.cpp:244]     Train net output #0: loss = 1.19781 (* 1 = 1.19781 loss)
I0818 12:33:46.544669 20702 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0818 12:33:57.233182 20702 solver.cpp:228] Iteration 17300, loss = 1.31676
I0818 12:33:57.233269 20702 solver.cpp:244]     Train net output #0: loss = 1.33755 (* 1 = 1.33755 loss)
I0818 12:33:57.233291 20702 sgd_solver.cpp:106] Iteration 17300, lr = 0.001
I0818 12:34:07.925014 20702 solver.cpp:228] Iteration 17400, loss = 1.32164
I0818 12:34:07.925242 20702 solver.cpp:244]     Train net output #0: loss = 1.30702 (* 1 = 1.30702 loss)
I0818 12:34:07.925279 20702 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0818 12:34:18.638327 20702 solver.cpp:228] Iteration 17500, loss = 1.31457
I0818 12:34:18.638402 20702 solver.cpp:244]     Train net output #0: loss = 1.22253 (* 1 = 1.22253 loss)
I0818 12:34:18.638424 20702 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I0818 12:34:29.328624 20702 solver.cpp:228] Iteration 17600, loss = 1.32797
I0818 12:34:29.328706 20702 solver.cpp:244]     Train net output #0: loss = 1.36387 (* 1 = 1.36387 loss)
I0818 12:34:29.328727 20702 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0818 12:34:40.020277 20702 solver.cpp:228] Iteration 17700, loss = 1.31129
I0818 12:34:40.020396 20702 solver.cpp:244]     Train net output #0: loss = 1.19139 (* 1 = 1.19139 loss)
I0818 12:34:40.020419 20702 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I0818 12:34:50.709959 20702 solver.cpp:228] Iteration 17800, loss = 1.31126
I0818 12:34:50.710034 20702 solver.cpp:244]     Train net output #0: loss = 1.31711 (* 1 = 1.31711 loss)
I0818 12:34:50.710059 20702 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0818 12:35:01.398123 20702 solver.cpp:228] Iteration 17900, loss = 1.31627
I0818 12:35:01.398211 20702 solver.cpp:244]     Train net output #0: loss = 1.30684 (* 1 = 1.30684 loss)
I0818 12:35:01.398238 20702 sgd_solver.cpp:106] Iteration 17900, lr = 0.001
I0818 12:35:12.003762 20702 solver.cpp:337] Iteration 18000, Testing net (#0)
I0818 12:35:14.189906 20702 solver.cpp:404]     Test net output #0: loss = 1.3928 (* 1 = 1.3928 loss)
I0818 12:35:14.260946 20702 solver.cpp:228] Iteration 18000, loss = 1.30945
I0818 12:35:14.260995 20702 solver.cpp:244]     Train net output #0: loss = 1.19456 (* 1 = 1.19456 loss)
I0818 12:35:14.261019 20702 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0818 12:35:24.952525 20702 solver.cpp:228] Iteration 18100, loss = 1.31722
I0818 12:35:24.952608 20702 solver.cpp:244]     Train net output #0: loss = 1.36998 (* 1 = 1.36998 loss)
I0818 12:35:24.952635 20702 sgd_solver.cpp:106] Iteration 18100, lr = 0.001
I0818 12:35:35.642514 20702 solver.cpp:228] Iteration 18200, loss = 1.29975
I0818 12:35:35.642596 20702 solver.cpp:244]     Train net output #0: loss = 1.18113 (* 1 = 1.18113 loss)
I0818 12:35:35.642618 20702 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0818 12:35:46.335266 20702 solver.cpp:228] Iteration 18300, loss = 1.29861
I0818 12:35:46.335501 20702 solver.cpp:244]     Train net output #0: loss = 1.30646 (* 1 = 1.30646 loss)
I0818 12:35:46.335531 20702 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I0818 12:35:57.081545 20702 solver.cpp:228] Iteration 18400, loss = 1.30208
I0818 12:35:57.081640 20702 solver.cpp:244]     Train net output #0: loss = 1.29636 (* 1 = 1.29636 loss)
I0818 12:35:57.081662 20702 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0818 12:36:07.771529 20702 solver.cpp:228] Iteration 18500, loss = 1.30037
I0818 12:36:07.771607 20702 solver.cpp:244]     Train net output #0: loss = 1.23047 (* 1 = 1.23047 loss)
I0818 12:36:07.771632 20702 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I0818 12:36:18.461736 20702 solver.cpp:228] Iteration 18600, loss = 1.31093
I0818 12:36:18.461884 20702 solver.cpp:244]     Train net output #0: loss = 1.34244 (* 1 = 1.34244 loss)
I0818 12:36:18.461910 20702 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0818 12:36:29.151643 20702 solver.cpp:228] Iteration 18700, loss = 1.29182
I0818 12:36:29.151729 20702 solver.cpp:244]     Train net output #0: loss = 1.13336 (* 1 = 1.13336 loss)
I0818 12:36:29.151751 20702 sgd_solver.cpp:106] Iteration 18700, lr = 0.001
I0818 12:36:39.842453 20702 solver.cpp:228] Iteration 18800, loss = 1.29174
I0818 12:36:39.842530 20702 solver.cpp:244]     Train net output #0: loss = 1.2978 (* 1 = 1.2978 loss)
I0818 12:36:39.842553 20702 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0818 12:36:50.533372 20702 solver.cpp:228] Iteration 18900, loss = 1.29192
I0818 12:36:50.533591 20702 solver.cpp:244]     Train net output #0: loss = 1.29487 (* 1 = 1.29487 loss)
I0818 12:36:50.533620 20702 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I0818 12:37:01.259975 20702 solver.cpp:228] Iteration 19000, loss = 1.28825
I0818 12:37:01.260058 20702 solver.cpp:244]     Train net output #0: loss = 1.18538 (* 1 = 1.18538 loss)
I0818 12:37:01.260079 20702 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0818 12:37:11.955775 20702 solver.cpp:228] Iteration 19100, loss = 1.29934
I0818 12:37:11.955854 20702 solver.cpp:244]     Train net output #0: loss = 1.37129 (* 1 = 1.37129 loss)
I0818 12:37:11.955878 20702 sgd_solver.cpp:106] Iteration 19100, lr = 0.001
I0818 12:37:22.663560 20702 solver.cpp:228] Iteration 19200, loss = 1.28057
I0818 12:37:22.663727 20702 solver.cpp:244]     Train net output #0: loss = 1.18326 (* 1 = 1.18326 loss)
I0818 12:37:22.663749 20702 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0818 12:37:33.353199 20702 solver.cpp:228] Iteration 19300, loss = 1.2816
I0818 12:37:33.353284 20702 solver.cpp:244]     Train net output #0: loss = 1.24417 (* 1 = 1.24417 loss)
I0818 12:37:33.353307 20702 sgd_solver.cpp:106] Iteration 19300, lr = 0.001
I0818 12:37:44.041721 20702 solver.cpp:228] Iteration 19400, loss = 1.28515
I0818 12:37:44.041797 20702 solver.cpp:244]     Train net output #0: loss = 1.26409 (* 1 = 1.26409 loss)
I0818 12:37:44.041820 20702 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0818 12:37:54.730871 20702 solver.cpp:228] Iteration 19500, loss = 1.27768
I0818 12:37:54.731052 20702 solver.cpp:244]     Train net output #0: loss = 1.17827 (* 1 = 1.17827 loss)
I0818 12:37:54.731094 20702 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0818 12:38:05.421243 20702 solver.cpp:228] Iteration 19600, loss = 1.28958
I0818 12:38:05.421330 20702 solver.cpp:244]     Train net output #0: loss = 1.34583 (* 1 = 1.34583 loss)
I0818 12:38:05.421352 20702 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0818 12:38:16.109299 20702 solver.cpp:228] Iteration 19700, loss = 1.27502
I0818 12:38:16.109375 20702 solver.cpp:244]     Train net output #0: loss = 1.14556 (* 1 = 1.14556 loss)
I0818 12:38:16.109397 20702 sgd_solver.cpp:106] Iteration 19700, lr = 0.001
I0818 12:38:26.798552 20702 solver.cpp:228] Iteration 19800, loss = 1.26878
I0818 12:38:26.798815 20702 solver.cpp:244]     Train net output #0: loss = 1.24032 (* 1 = 1.24032 loss)
I0818 12:38:26.798852 20702 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0818 12:38:37.509446 20702 solver.cpp:228] Iteration 19900, loss = 1.27282
I0818 12:38:37.509523 20702 solver.cpp:244]     Train net output #0: loss = 1.24999 (* 1 = 1.24999 loss)
I0818 12:38:37.509546 20702 sgd_solver.cpp:106] Iteration 19900, lr = 0.001
I0818 12:38:48.091325 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_20000.caffemodel
I0818 12:38:48.139358 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_20000.solverstate
I0818 12:38:48.144848 20702 solver.cpp:337] Iteration 20000, Testing net (#0)
I0818 12:38:50.231549 20702 solver.cpp:404]     Test net output #0: loss = 1.37336 (* 1 = 1.37336 loss)
I0818 12:38:50.302392 20702 solver.cpp:228] Iteration 20000, loss = 1.27325
I0818 12:38:50.302431 20702 solver.cpp:244]     Train net output #0: loss = 1.20881 (* 1 = 1.20881 loss)
I0818 12:38:50.302459 20702 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I0818 12:39:00.990842 20702 solver.cpp:228] Iteration 20100, loss = 1.2816
I0818 12:39:00.991088 20702 solver.cpp:244]     Train net output #0: loss = 1.3688 (* 1 = 1.3688 loss)
I0818 12:39:00.991117 20702 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I0818 12:39:11.700722 20702 solver.cpp:228] Iteration 20200, loss = 1.26175
I0818 12:39:11.700804 20702 solver.cpp:244]     Train net output #0: loss = 1.12299 (* 1 = 1.12299 loss)
I0818 12:39:11.700827 20702 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I0818 12:39:22.389600 20702 solver.cpp:228] Iteration 20300, loss = 1.26546
I0818 12:39:22.389675 20702 solver.cpp:244]     Train net output #0: loss = 1.24389 (* 1 = 1.24389 loss)
I0818 12:39:22.389698 20702 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I0818 12:39:33.079008 20702 solver.cpp:228] Iteration 20400, loss = 1.27045
I0818 12:39:33.079174 20702 solver.cpp:244]     Train net output #0: loss = 1.28196 (* 1 = 1.28196 loss)
I0818 12:39:33.079202 20702 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I0818 12:39:43.770205 20702 solver.cpp:228] Iteration 20500, loss = 1.26728
I0818 12:39:43.770282 20702 solver.cpp:244]     Train net output #0: loss = 1.16456 (* 1 = 1.16456 loss)
I0818 12:39:43.770303 20702 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I0818 12:39:54.459499 20702 solver.cpp:228] Iteration 20600, loss = 1.27704
I0818 12:39:54.459573 20702 solver.cpp:244]     Train net output #0: loss = 1.31168 (* 1 = 1.31168 loss)
I0818 12:39:54.459594 20702 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I0818 12:40:05.173017 20702 solver.cpp:228] Iteration 20700, loss = 1.25651
I0818 12:40:05.173250 20702 solver.cpp:244]     Train net output #0: loss = 1.11247 (* 1 = 1.11247 loss)
I0818 12:40:05.173286 20702 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I0818 12:40:15.892076 20702 solver.cpp:228] Iteration 20800, loss = 1.25863
I0818 12:40:15.892149 20702 solver.cpp:244]     Train net output #0: loss = 1.21247 (* 1 = 1.21247 loss)
I0818 12:40:15.892171 20702 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I0818 12:40:26.581465 20702 solver.cpp:228] Iteration 20900, loss = 1.25368
I0818 12:40:26.581549 20702 solver.cpp:244]     Train net output #0: loss = 1.23846 (* 1 = 1.23846 loss)
I0818 12:40:26.581571 20702 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I0818 12:40:37.271345 20702 solver.cpp:228] Iteration 21000, loss = 1.25837
I0818 12:40:37.271625 20702 solver.cpp:244]     Train net output #0: loss = 1.1927 (* 1 = 1.1927 loss)
I0818 12:40:37.271656 20702 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I0818 12:40:47.983062 20702 solver.cpp:228] Iteration 21100, loss = 1.27208
I0818 12:40:47.983139 20702 solver.cpp:244]     Train net output #0: loss = 1.32873 (* 1 = 1.32873 loss)
I0818 12:40:47.983162 20702 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I0818 12:40:58.671880 20702 solver.cpp:228] Iteration 21200, loss = 1.25165
I0818 12:40:58.671960 20702 solver.cpp:244]     Train net output #0: loss = 1.11373 (* 1 = 1.11373 loss)
I0818 12:40:58.671983 20702 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I0818 12:41:09.360729 20702 solver.cpp:228] Iteration 21300, loss = 1.25369
I0818 12:41:09.360944 20702 solver.cpp:244]     Train net output #0: loss = 1.2052 (* 1 = 1.2052 loss)
I0818 12:41:09.360980 20702 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I0818 12:41:20.070494 20702 solver.cpp:228] Iteration 21400, loss = 1.25397
I0818 12:41:20.070572 20702 solver.cpp:244]     Train net output #0: loss = 1.24363 (* 1 = 1.24363 loss)
I0818 12:41:20.070595 20702 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I0818 12:41:30.758360 20702 solver.cpp:228] Iteration 21500, loss = 1.24875
I0818 12:41:30.758442 20702 solver.cpp:244]     Train net output #0: loss = 1.16507 (* 1 = 1.16507 loss)
I0818 12:41:30.758464 20702 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I0818 12:41:41.446676 20702 solver.cpp:228] Iteration 21600, loss = 1.26131
I0818 12:41:41.446913 20702 solver.cpp:244]     Train net output #0: loss = 1.31042 (* 1 = 1.31042 loss)
I0818 12:41:41.446947 20702 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I0818 12:41:52.133915 20702 solver.cpp:228] Iteration 21700, loss = 1.24226
I0818 12:41:52.133991 20702 solver.cpp:244]     Train net output #0: loss = 1.09031 (* 1 = 1.09031 loss)
I0818 12:41:52.134012 20702 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I0818 12:42:02.820623 20702 solver.cpp:228] Iteration 21800, loss = 1.2392
I0818 12:42:02.820698 20702 solver.cpp:244]     Train net output #0: loss = 1.2134 (* 1 = 1.2134 loss)
I0818 12:42:02.820719 20702 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I0818 12:42:13.512296 20702 solver.cpp:228] Iteration 21900, loss = 1.24122
I0818 12:42:13.512444 20702 solver.cpp:244]     Train net output #0: loss = 1.24833 (* 1 = 1.24833 loss)
I0818 12:42:13.512470 20702 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I0818 12:42:24.105659 20702 solver.cpp:337] Iteration 22000, Testing net (#0)
I0818 12:42:26.228149 20702 solver.cpp:404]     Test net output #0: loss = 1.35917 (* 1 = 1.35917 loss)
I0818 12:42:26.299119 20702 solver.cpp:228] Iteration 22000, loss = 1.24341
I0818 12:42:26.299159 20702 solver.cpp:244]     Train net output #0: loss = 1.14993 (* 1 = 1.14993 loss)
I0818 12:42:26.299187 20702 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I0818 12:42:36.986557 20702 solver.cpp:228] Iteration 22100, loss = 1.25671
I0818 12:42:36.986632 20702 solver.cpp:244]     Train net output #0: loss = 1.33161 (* 1 = 1.33161 loss)
I0818 12:42:36.986655 20702 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I0818 12:42:47.674648 20702 solver.cpp:228] Iteration 22200, loss = 1.23008
I0818 12:42:47.674871 20702 solver.cpp:244]     Train net output #0: loss = 1.10151 (* 1 = 1.10151 loss)
I0818 12:42:47.674902 20702 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I0818 12:42:58.379961 20702 solver.cpp:228] Iteration 22300, loss = 1.23648
I0818 12:42:58.380043 20702 solver.cpp:244]     Train net output #0: loss = 1.18953 (* 1 = 1.18953 loss)
I0818 12:42:58.380065 20702 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I0818 12:43:09.069705 20702 solver.cpp:228] Iteration 22400, loss = 1.24602
I0818 12:43:09.069782 20702 solver.cpp:244]     Train net output #0: loss = 1.1986 (* 1 = 1.1986 loss)
I0818 12:43:09.069804 20702 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I0818 12:43:19.758239 20702 solver.cpp:228] Iteration 22500, loss = 1.23851
I0818 12:43:19.758500 20702 solver.cpp:244]     Train net output #0: loss = 1.14249 (* 1 = 1.14249 loss)
I0818 12:43:19.758529 20702 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I0818 12:43:30.466189 20702 solver.cpp:228] Iteration 22600, loss = 1.24495
I0818 12:43:30.466275 20702 solver.cpp:244]     Train net output #0: loss = 1.27336 (* 1 = 1.27336 loss)
I0818 12:43:30.466298 20702 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I0818 12:43:41.155180 20702 solver.cpp:228] Iteration 22700, loss = 1.22942
I0818 12:43:41.155259 20702 solver.cpp:244]     Train net output #0: loss = 1.0734 (* 1 = 1.0734 loss)
I0818 12:43:41.155282 20702 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I0818 12:43:51.842438 20702 solver.cpp:228] Iteration 22800, loss = 1.23057
I0818 12:43:51.842639 20702 solver.cpp:244]     Train net output #0: loss = 1.18829 (* 1 = 1.18829 loss)
I0818 12:43:51.842665 20702 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I0818 12:44:02.551298 20702 solver.cpp:228] Iteration 22900, loss = 1.23145
I0818 12:44:02.551389 20702 solver.cpp:244]     Train net output #0: loss = 1.15805 (* 1 = 1.15805 loss)
I0818 12:44:02.551414 20702 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I0818 12:44:13.238636 20702 solver.cpp:228] Iteration 23000, loss = 1.22915
I0818 12:44:13.238714 20702 solver.cpp:244]     Train net output #0: loss = 1.16095 (* 1 = 1.16095 loss)
I0818 12:44:13.238735 20702 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I0818 12:44:23.926323 20702 solver.cpp:228] Iteration 23100, loss = 1.23879
I0818 12:44:23.926570 20702 solver.cpp:244]     Train net output #0: loss = 1.29989 (* 1 = 1.29989 loss)
I0818 12:44:23.926604 20702 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I0818 12:44:34.636628 20702 solver.cpp:228] Iteration 23200, loss = 1.21809
I0818 12:44:34.636713 20702 solver.cpp:244]     Train net output #0: loss = 1.07869 (* 1 = 1.07869 loss)
I0818 12:44:34.636735 20702 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I0818 12:44:45.322911 20702 solver.cpp:228] Iteration 23300, loss = 1.21728
I0818 12:44:45.322985 20702 solver.cpp:244]     Train net output #0: loss = 1.15436 (* 1 = 1.15436 loss)
I0818 12:44:45.323007 20702 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I0818 12:44:56.012091 20702 solver.cpp:228] Iteration 23400, loss = 1.21955
I0818 12:44:56.012248 20702 solver.cpp:244]     Train net output #0: loss = 1.20994 (* 1 = 1.20994 loss)
I0818 12:44:56.012274 20702 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I0818 12:45:06.710023 20702 solver.cpp:228] Iteration 23500, loss = 1.2192
I0818 12:45:06.710095 20702 solver.cpp:244]     Train net output #0: loss = 1.11552 (* 1 = 1.11552 loss)
I0818 12:45:06.710116 20702 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I0818 12:45:17.404976 20702 solver.cpp:228] Iteration 23600, loss = 1.22715
I0818 12:45:17.405055 20702 solver.cpp:244]     Train net output #0: loss = 1.28221 (* 1 = 1.28221 loss)
I0818 12:45:17.405077 20702 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I0818 12:45:28.093374 20702 solver.cpp:228] Iteration 23700, loss = 1.21238
I0818 12:45:28.093554 20702 solver.cpp:244]     Train net output #0: loss = 1.05872 (* 1 = 1.05872 loss)
I0818 12:45:28.093586 20702 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I0818 12:45:38.781587 20702 solver.cpp:228] Iteration 23800, loss = 1.21366
I0818 12:45:38.781667 20702 solver.cpp:244]     Train net output #0: loss = 1.16674 (* 1 = 1.16674 loss)
I0818 12:45:38.781689 20702 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I0818 12:45:49.471870 20702 solver.cpp:228] Iteration 23900, loss = 1.21105
I0818 12:45:49.471947 20702 solver.cpp:244]     Train net output #0: loss = 1.16245 (* 1 = 1.16245 loss)
I0818 12:45:49.471969 20702 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I0818 12:46:00.055621 20702 solver.cpp:337] Iteration 24000, Testing net (#0)
I0818 12:46:02.180152 20702 solver.cpp:404]     Test net output #0: loss = 1.3355 (* 1 = 1.3355 loss)
I0818 12:46:02.251075 20702 solver.cpp:228] Iteration 24000, loss = 1.21334
I0818 12:46:02.251117 20702 solver.cpp:244]     Train net output #0: loss = 1.13505 (* 1 = 1.13505 loss)
I0818 12:46:02.251143 20702 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I0818 12:46:12.939755 20702 solver.cpp:228] Iteration 24100, loss = 1.21927
I0818 12:46:12.939831 20702 solver.cpp:244]     Train net output #0: loss = 1.26709 (* 1 = 1.26709 loss)
I0818 12:46:12.939852 20702 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I0818 12:46:23.627542 20702 solver.cpp:228] Iteration 24200, loss = 1.20288
I0818 12:46:23.627617 20702 solver.cpp:244]     Train net output #0: loss = 1.07576 (* 1 = 1.07576 loss)
I0818 12:46:23.627638 20702 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I0818 12:46:34.315506 20702 solver.cpp:228] Iteration 24300, loss = 1.20181
I0818 12:46:34.315732 20702 solver.cpp:244]     Train net output #0: loss = 1.18551 (* 1 = 1.18551 loss)
I0818 12:46:34.315781 20702 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I0818 12:46:45.004894 20702 solver.cpp:228] Iteration 24400, loss = 1.2071
I0818 12:46:45.004969 20702 solver.cpp:244]     Train net output #0: loss = 1.18711 (* 1 = 1.18711 loss)
I0818 12:46:45.004990 20702 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I0818 12:46:55.693357 20702 solver.cpp:228] Iteration 24500, loss = 1.20448
I0818 12:46:55.693440 20702 solver.cpp:244]     Train net output #0: loss = 1.13282 (* 1 = 1.13282 loss)
I0818 12:46:55.693461 20702 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I0818 12:47:06.381613 20702 solver.cpp:228] Iteration 24600, loss = 1.21452
I0818 12:47:06.381830 20702 solver.cpp:244]     Train net output #0: loss = 1.27888 (* 1 = 1.27888 loss)
I0818 12:47:06.381861 20702 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I0818 12:47:17.103874 20702 solver.cpp:228] Iteration 24700, loss = 1.19752
I0818 12:47:17.103950 20702 solver.cpp:244]     Train net output #0: loss = 1.07923 (* 1 = 1.07923 loss)
I0818 12:47:17.103973 20702 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I0818 12:47:27.803527 20702 solver.cpp:228] Iteration 24800, loss = 1.19397
I0818 12:47:27.803606 20702 solver.cpp:244]     Train net output #0: loss = 1.13374 (* 1 = 1.13374 loss)
I0818 12:47:27.803629 20702 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I0818 12:47:38.491317 20702 solver.cpp:228] Iteration 24900, loss = 1.19318
I0818 12:47:38.491482 20702 solver.cpp:244]     Train net output #0: loss = 1.17308 (* 1 = 1.17308 loss)
I0818 12:47:38.491506 20702 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I0818 12:47:49.179740 20702 solver.cpp:228] Iteration 25000, loss = 1.19786
I0818 12:47:49.179813 20702 solver.cpp:244]     Train net output #0: loss = 1.15031 (* 1 = 1.15031 loss)
I0818 12:47:49.179834 20702 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I0818 12:47:59.867463 20702 solver.cpp:228] Iteration 25100, loss = 1.20612
I0818 12:47:59.867542 20702 solver.cpp:244]     Train net output #0: loss = 1.24901 (* 1 = 1.24901 loss)
I0818 12:47:59.867563 20702 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I0818 12:48:10.556119 20702 solver.cpp:228] Iteration 25200, loss = 1.18984
I0818 12:48:10.556361 20702 solver.cpp:244]     Train net output #0: loss = 1.02986 (* 1 = 1.02986 loss)
I0818 12:48:10.556398 20702 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I0818 12:48:21.264176 20702 solver.cpp:228] Iteration 25300, loss = 1.18751
I0818 12:48:21.264251 20702 solver.cpp:244]     Train net output #0: loss = 1.09742 (* 1 = 1.09742 loss)
I0818 12:48:21.264273 20702 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I0818 12:48:31.951390 20702 solver.cpp:228] Iteration 25400, loss = 1.19169
I0818 12:48:31.951472 20702 solver.cpp:244]     Train net output #0: loss = 1.16972 (* 1 = 1.16972 loss)
I0818 12:48:31.951493 20702 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I0818 12:48:42.639387 20702 solver.cpp:228] Iteration 25500, loss = 1.18962
I0818 12:48:42.639549 20702 solver.cpp:244]     Train net output #0: loss = 1.11335 (* 1 = 1.11335 loss)
I0818 12:48:42.639575 20702 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I0818 12:48:53.326206 20702 solver.cpp:228] Iteration 25600, loss = 1.19296
I0818 12:48:53.326280 20702 solver.cpp:244]     Train net output #0: loss = 1.24407 (* 1 = 1.24407 loss)
I0818 12:48:53.326303 20702 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I0818 12:49:04.014417 20702 solver.cpp:228] Iteration 25700, loss = 1.18298
I0818 12:49:04.014503 20702 solver.cpp:244]     Train net output #0: loss = 1.02179 (* 1 = 1.02179 loss)
I0818 12:49:04.014524 20702 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I0818 12:49:14.702356 20702 solver.cpp:228] Iteration 25800, loss = 1.17675
I0818 12:49:14.702649 20702 solver.cpp:244]     Train net output #0: loss = 1.12556 (* 1 = 1.12556 loss)
I0818 12:49:14.702680 20702 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I0818 12:49:25.412266 20702 solver.cpp:228] Iteration 25900, loss = 1.17987
I0818 12:49:25.412350 20702 solver.cpp:244]     Train net output #0: loss = 1.14318 (* 1 = 1.14318 loss)
I0818 12:49:25.412376 20702 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I0818 12:49:35.993517 20702 solver.cpp:337] Iteration 26000, Testing net (#0)
I0818 12:49:38.115120 20702 solver.cpp:404]     Test net output #0: loss = 1.32213 (* 1 = 1.32213 loss)
I0818 12:49:38.186095 20702 solver.cpp:228] Iteration 26000, loss = 1.19001
I0818 12:49:38.186134 20702 solver.cpp:244]     Train net output #0: loss = 1.11525 (* 1 = 1.11525 loss)
I0818 12:49:38.186162 20702 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I0818 12:49:48.875846 20702 solver.cpp:228] Iteration 26100, loss = 1.1887
I0818 12:49:48.876042 20702 solver.cpp:244]     Train net output #0: loss = 1.22109 (* 1 = 1.22109 loss)
I0818 12:49:48.876070 20702 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I0818 12:49:59.584775 20702 solver.cpp:228] Iteration 26200, loss = 1.17415
I0818 12:49:59.584866 20702 solver.cpp:244]     Train net output #0: loss = 1.04786 (* 1 = 1.04786 loss)
I0818 12:49:59.584887 20702 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I0818 12:50:10.291891 20702 solver.cpp:228] Iteration 26300, loss = 1.16893
I0818 12:50:10.291957 20702 solver.cpp:244]     Train net output #0: loss = 1.10198 (* 1 = 1.10198 loss)
I0818 12:50:10.291980 20702 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I0818 12:50:20.979980 20702 solver.cpp:228] Iteration 26400, loss = 1.17256
I0818 12:50:20.980156 20702 solver.cpp:244]     Train net output #0: loss = 1.17687 (* 1 = 1.17687 loss)
I0818 12:50:20.980180 20702 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I0818 12:50:31.665474 20702 solver.cpp:228] Iteration 26500, loss = 1.1769
I0818 12:50:31.665554 20702 solver.cpp:244]     Train net output #0: loss = 1.09048 (* 1 = 1.09048 loss)
I0818 12:50:31.665575 20702 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I0818 12:50:42.352661 20702 solver.cpp:228] Iteration 26600, loss = 1.17841
I0818 12:50:42.352730 20702 solver.cpp:244]     Train net output #0: loss = 1.25496 (* 1 = 1.25496 loss)
I0818 12:50:42.352751 20702 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I0818 12:50:53.038235 20702 solver.cpp:228] Iteration 26700, loss = 1.16381
I0818 12:50:53.038437 20702 solver.cpp:244]     Train net output #0: loss = 1.03642 (* 1 = 1.03642 loss)
I0818 12:50:53.038468 20702 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I0818 12:51:03.724391 20702 solver.cpp:228] Iteration 26800, loss = 1.16471
I0818 12:51:03.724478 20702 solver.cpp:244]     Train net output #0: loss = 1.0772 (* 1 = 1.0772 loss)
I0818 12:51:03.724503 20702 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I0818 12:51:14.409133 20702 solver.cpp:228] Iteration 26900, loss = 1.16605
I0818 12:51:14.409209 20702 solver.cpp:244]     Train net output #0: loss = 1.1419 (* 1 = 1.1419 loss)
I0818 12:51:14.409231 20702 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I0818 12:51:25.095726 20702 solver.cpp:228] Iteration 27000, loss = 1.16615
I0818 12:51:25.095906 20702 solver.cpp:244]     Train net output #0: loss = 1.09564 (* 1 = 1.09564 loss)
I0818 12:51:25.095939 20702 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I0818 12:51:35.782541 20702 solver.cpp:228] Iteration 27100, loss = 1.17236
I0818 12:51:35.782624 20702 solver.cpp:244]     Train net output #0: loss = 1.19891 (* 1 = 1.19891 loss)
I0818 12:51:35.782646 20702 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I0818 12:51:46.471267 20702 solver.cpp:228] Iteration 27200, loss = 1.16255
I0818 12:51:46.471343 20702 solver.cpp:244]     Train net output #0: loss = 0.971693 (* 1 = 0.971693 loss)
I0818 12:51:46.471366 20702 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I0818 12:51:57.159185 20702 solver.cpp:228] Iteration 27300, loss = 1.16026
I0818 12:51:57.159451 20702 solver.cpp:244]     Train net output #0: loss = 1.09267 (* 1 = 1.09267 loss)
I0818 12:51:57.159484 20702 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I0818 12:52:07.846098 20702 solver.cpp:228] Iteration 27400, loss = 1.16187
I0818 12:52:07.846181 20702 solver.cpp:244]     Train net output #0: loss = 1.13435 (* 1 = 1.13435 loss)
I0818 12:52:07.846204 20702 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I0818 12:52:18.545577 20702 solver.cpp:228] Iteration 27500, loss = 1.16633
I0818 12:52:18.545655 20702 solver.cpp:244]     Train net output #0: loss = 1.08459 (* 1 = 1.08459 loss)
I0818 12:52:18.545676 20702 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I0818 12:52:29.235023 20702 solver.cpp:228] Iteration 27600, loss = 1.16435
I0818 12:52:29.235265 20702 solver.cpp:244]     Train net output #0: loss = 1.20356 (* 1 = 1.20356 loss)
I0818 12:52:29.235290 20702 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I0818 12:52:39.923300 20702 solver.cpp:228] Iteration 27700, loss = 1.15394
I0818 12:52:39.923378 20702 solver.cpp:244]     Train net output #0: loss = 1.02426 (* 1 = 1.02426 loss)
I0818 12:52:39.923400 20702 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I0818 12:52:50.610535 20702 solver.cpp:228] Iteration 27800, loss = 1.153
I0818 12:52:50.610615 20702 solver.cpp:244]     Train net output #0: loss = 1.1172 (* 1 = 1.1172 loss)
I0818 12:52:50.610636 20702 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I0818 12:53:01.298873 20702 solver.cpp:228] Iteration 27900, loss = 1.15491
I0818 12:53:01.299088 20702 solver.cpp:244]     Train net output #0: loss = 1.14653 (* 1 = 1.14653 loss)
I0818 12:53:01.299118 20702 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I0818 12:53:11.901618 20702 solver.cpp:337] Iteration 28000, Testing net (#0)
I0818 12:53:14.023221 20702 solver.cpp:404]     Test net output #0: loss = 1.30534 (* 1 = 1.30534 loss)
I0818 12:53:14.094141 20702 solver.cpp:228] Iteration 28000, loss = 1.1673
I0818 12:53:14.094189 20702 solver.cpp:244]     Train net output #0: loss = 1.08539 (* 1 = 1.08539 loss)
I0818 12:53:14.094213 20702 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I0818 12:53:24.780530 20702 solver.cpp:228] Iteration 28100, loss = 1.15639
I0818 12:53:24.780606 20702 solver.cpp:244]     Train net output #0: loss = 1.20952 (* 1 = 1.20952 loss)
I0818 12:53:24.780628 20702 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I0818 12:53:35.466168 20702 solver.cpp:228] Iteration 28200, loss = 1.14969
I0818 12:53:35.466344 20702 solver.cpp:244]     Train net output #0: loss = 1.00743 (* 1 = 1.00743 loss)
I0818 12:53:35.466368 20702 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I0818 12:53:46.151036 20702 solver.cpp:228] Iteration 28300, loss = 1.15238
I0818 12:53:46.151110 20702 solver.cpp:244]     Train net output #0: loss = 1.06165 (* 1 = 1.06165 loss)
I0818 12:53:46.151134 20702 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I0818 12:53:56.837802 20702 solver.cpp:228] Iteration 28400, loss = 1.1493
I0818 12:53:56.837885 20702 solver.cpp:244]     Train net output #0: loss = 1.13708 (* 1 = 1.13708 loss)
I0818 12:53:56.837906 20702 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I0818 12:54:07.523979 20702 solver.cpp:228] Iteration 28500, loss = 1.15121
I0818 12:54:07.524224 20702 solver.cpp:244]     Train net output #0: loss = 1.07131 (* 1 = 1.07131 loss)
I0818 12:54:07.524255 20702 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I0818 12:54:18.249524 20702 solver.cpp:228] Iteration 28600, loss = 1.15302
I0818 12:54:18.249596 20702 solver.cpp:244]     Train net output #0: loss = 1.20549 (* 1 = 1.20549 loss)
I0818 12:54:18.249619 20702 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I0818 12:54:28.935937 20702 solver.cpp:228] Iteration 28700, loss = 1.14064
I0818 12:54:28.936023 20702 solver.cpp:244]     Train net output #0: loss = 1.02063 (* 1 = 1.02063 loss)
I0818 12:54:28.936049 20702 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I0818 12:54:39.622169 20702 solver.cpp:228] Iteration 28800, loss = 1.13716
I0818 12:54:39.622444 20702 solver.cpp:244]     Train net output #0: loss = 1.04793 (* 1 = 1.04793 loss)
I0818 12:54:39.622469 20702 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I0818 12:54:50.306605 20702 solver.cpp:228] Iteration 28900, loss = 1.13756
I0818 12:54:50.306682 20702 solver.cpp:244]     Train net output #0: loss = 1.11368 (* 1 = 1.11368 loss)
I0818 12:54:50.306705 20702 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I0818 12:55:00.991673 20702 solver.cpp:228] Iteration 29000, loss = 1.14207
I0818 12:55:00.991760 20702 solver.cpp:244]     Train net output #0: loss = 1.10411 (* 1 = 1.10411 loss)
I0818 12:55:00.991783 20702 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I0818 12:55:11.705225 20702 solver.cpp:228] Iteration 29100, loss = 1.14407
I0818 12:55:11.705459 20702 solver.cpp:244]     Train net output #0: loss = 1.18772 (* 1 = 1.18772 loss)
I0818 12:55:11.705497 20702 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I0818 12:55:22.392340 20702 solver.cpp:228] Iteration 29200, loss = 1.13513
I0818 12:55:22.392415 20702 solver.cpp:244]     Train net output #0: loss = 1.05039 (* 1 = 1.05039 loss)
I0818 12:55:22.392436 20702 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I0818 12:55:33.078184 20702 solver.cpp:228] Iteration 29300, loss = 1.13479
I0818 12:55:33.078269 20702 solver.cpp:244]     Train net output #0: loss = 1.0695 (* 1 = 1.0695 loss)
I0818 12:55:33.078292 20702 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I0818 12:55:43.761745 20702 solver.cpp:228] Iteration 29400, loss = 1.13533
I0818 12:55:43.761939 20702 solver.cpp:244]     Train net output #0: loss = 1.13749 (* 1 = 1.13749 loss)
I0818 12:55:43.761970 20702 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I0818 12:55:54.448436 20702 solver.cpp:228] Iteration 29500, loss = 1.13973
I0818 12:55:54.448513 20702 solver.cpp:244]     Train net output #0: loss = 1.04853 (* 1 = 1.04853 loss)
I0818 12:55:54.448534 20702 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I0818 12:56:05.135202 20702 solver.cpp:228] Iteration 29600, loss = 1.13568
I0818 12:56:05.135293 20702 solver.cpp:244]     Train net output #0: loss = 1.15231 (* 1 = 1.15231 loss)
I0818 12:56:05.135313 20702 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I0818 12:56:15.822072 20702 solver.cpp:228] Iteration 29700, loss = 1.12305
I0818 12:56:15.822289 20702 solver.cpp:244]     Train net output #0: loss = 1.00473 (* 1 = 1.00473 loss)
I0818 12:56:15.822320 20702 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I0818 12:56:26.532045 20702 solver.cpp:228] Iteration 29800, loss = 1.12204
I0818 12:56:26.532126 20702 solver.cpp:244]     Train net output #0: loss = 1.07471 (* 1 = 1.07471 loss)
I0818 12:56:26.532150 20702 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I0818 12:56:37.217083 20702 solver.cpp:228] Iteration 29900, loss = 1.12753
I0818 12:56:37.217156 20702 solver.cpp:244]     Train net output #0: loss = 1.13759 (* 1 = 1.13759 loss)
I0818 12:56:37.217177 20702 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I0818 12:56:47.797480 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_30000.caffemodel
I0818 12:56:47.845932 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_30000.solverstate
I0818 12:56:47.851460 20702 solver.cpp:337] Iteration 30000, Testing net (#0)
I0818 12:56:49.971088 20702 solver.cpp:404]     Test net output #0: loss = 1.27598 (* 1 = 1.27598 loss)
I0818 12:56:50.041996 20702 solver.cpp:228] Iteration 30000, loss = 1.13461
I0818 12:56:50.042044 20702 solver.cpp:244]     Train net output #0: loss = 1.02115 (* 1 = 1.02115 loss)
I0818 12:56:50.042068 20702 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I0818 12:57:00.727691 20702 solver.cpp:228] Iteration 30100, loss = 1.12996
I0818 12:57:00.727774 20702 solver.cpp:244]     Train net output #0: loss = 1.18255 (* 1 = 1.18255 loss)
I0818 12:57:00.727795 20702 sgd_solver.cpp:106] Iteration 30100, lr = 0.001
I0818 12:57:11.414696 20702 solver.cpp:228] Iteration 30200, loss = 1.11777
I0818 12:57:11.414769 20702 solver.cpp:244]     Train net output #0: loss = 0.969055 (* 1 = 0.969055 loss)
I0818 12:57:11.414794 20702 sgd_solver.cpp:106] Iteration 30200, lr = 0.001
I0818 12:57:22.118106 20702 solver.cpp:228] Iteration 30300, loss = 1.11911
I0818 12:57:22.118314 20702 solver.cpp:244]     Train net output #0: loss = 1.04645 (* 1 = 1.04645 loss)
I0818 12:57:22.118340 20702 sgd_solver.cpp:106] Iteration 30300, lr = 0.001
I0818 12:57:32.803764 20702 solver.cpp:228] Iteration 30400, loss = 1.11816
I0818 12:57:32.803845 20702 solver.cpp:244]     Train net output #0: loss = 1.11595 (* 1 = 1.11595 loss)
I0818 12:57:32.803867 20702 sgd_solver.cpp:106] Iteration 30400, lr = 0.001
I0818 12:57:43.491215 20702 solver.cpp:228] Iteration 30500, loss = 1.12596
I0818 12:57:43.491289 20702 solver.cpp:244]     Train net output #0: loss = 1.02743 (* 1 = 1.02743 loss)
I0818 12:57:43.491310 20702 sgd_solver.cpp:106] Iteration 30500, lr = 0.001
I0818 12:57:54.175485 20702 solver.cpp:228] Iteration 30600, loss = 1.11995
I0818 12:57:54.175690 20702 solver.cpp:244]     Train net output #0: loss = 1.15698 (* 1 = 1.15698 loss)
I0818 12:57:54.175724 20702 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I0818 12:58:04.861527 20702 solver.cpp:228] Iteration 30700, loss = 1.11184
I0818 12:58:04.861619 20702 solver.cpp:244]     Train net output #0: loss = 1.01853 (* 1 = 1.01853 loss)
I0818 12:58:04.861640 20702 sgd_solver.cpp:106] Iteration 30700, lr = 0.001
I0818 12:58:15.545830 20702 solver.cpp:228] Iteration 30800, loss = 1.10814
I0818 12:58:15.545908 20702 solver.cpp:244]     Train net output #0: loss = 1.05822 (* 1 = 1.05822 loss)
I0818 12:58:15.545931 20702 sgd_solver.cpp:106] Iteration 30800, lr = 0.001
I0818 12:58:26.229847 20702 solver.cpp:228] Iteration 30900, loss = 1.10935
I0818 12:58:26.230057 20702 solver.cpp:244]     Train net output #0: loss = 1.09405 (* 1 = 1.09405 loss)
I0818 12:58:26.230087 20702 sgd_solver.cpp:106] Iteration 30900, lr = 0.001
I0818 12:58:36.934638 20702 solver.cpp:228] Iteration 31000, loss = 1.12387
I0818 12:58:36.934711 20702 solver.cpp:244]     Train net output #0: loss = 1.02347 (* 1 = 1.02347 loss)
I0818 12:58:36.934732 20702 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I0818 12:58:47.620275 20702 solver.cpp:228] Iteration 31100, loss = 1.11456
I0818 12:58:47.620348 20702 solver.cpp:244]     Train net output #0: loss = 1.1807 (* 1 = 1.1807 loss)
I0818 12:58:47.620371 20702 sgd_solver.cpp:106] Iteration 31100, lr = 0.001
I0818 12:58:58.307047 20702 solver.cpp:228] Iteration 31200, loss = 1.1045
I0818 12:58:58.307252 20702 solver.cpp:244]     Train net output #0: loss = 0.974358 (* 1 = 0.974358 loss)
I0818 12:58:58.307281 20702 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I0818 12:59:09.014082 20702 solver.cpp:228] Iteration 31300, loss = 1.10375
I0818 12:59:09.014158 20702 solver.cpp:244]     Train net output #0: loss = 1.02095 (* 1 = 1.02095 loss)
I0818 12:59:09.014181 20702 sgd_solver.cpp:106] Iteration 31300, lr = 0.001
I0818 12:59:19.698331 20702 solver.cpp:228] Iteration 31400, loss = 1.10602
I0818 12:59:19.698397 20702 solver.cpp:244]     Train net output #0: loss = 1.09652 (* 1 = 1.09652 loss)
I0818 12:59:19.698421 20702 sgd_solver.cpp:106] Iteration 31400, lr = 0.001
I0818 12:59:30.381525 20702 solver.cpp:228] Iteration 31500, loss = 1.11785
I0818 12:59:30.381742 20702 solver.cpp:244]     Train net output #0: loss = 1.03023 (* 1 = 1.03023 loss)
I0818 12:59:30.381773 20702 sgd_solver.cpp:106] Iteration 31500, lr = 0.001
I0818 12:59:41.089382 20702 solver.cpp:228] Iteration 31600, loss = 1.10924
I0818 12:59:41.089454 20702 solver.cpp:244]     Train net output #0: loss = 1.14853 (* 1 = 1.14853 loss)
I0818 12:59:41.089475 20702 sgd_solver.cpp:106] Iteration 31600, lr = 0.001
I0818 12:59:51.774615 20702 solver.cpp:228] Iteration 31700, loss = 1.1054
I0818 12:59:51.774691 20702 solver.cpp:244]     Train net output #0: loss = 0.959678 (* 1 = 0.959678 loss)
I0818 12:59:51.774714 20702 sgd_solver.cpp:106] Iteration 31700, lr = 0.001
I0818 13:00:02.465512 20702 solver.cpp:228] Iteration 31800, loss = 1.09389
I0818 13:00:02.465780 20702 solver.cpp:244]     Train net output #0: loss = 1.03969 (* 1 = 1.03969 loss)
I0818 13:00:02.465808 20702 sgd_solver.cpp:106] Iteration 31800, lr = 0.001
I0818 13:00:13.171888 20702 solver.cpp:228] Iteration 31900, loss = 1.09921
I0818 13:00:13.171963 20702 solver.cpp:244]     Train net output #0: loss = 1.09923 (* 1 = 1.09923 loss)
I0818 13:00:13.171984 20702 sgd_solver.cpp:106] Iteration 31900, lr = 0.001
I0818 13:00:23.752482 20702 solver.cpp:337] Iteration 32000, Testing net (#0)
I0818 13:00:25.873252 20702 solver.cpp:404]     Test net output #0: loss = 1.24606 (* 1 = 1.24606 loss)
I0818 13:00:25.944191 20702 solver.cpp:228] Iteration 32000, loss = 1.10926
I0818 13:00:25.944237 20702 solver.cpp:244]     Train net output #0: loss = 1.02321 (* 1 = 1.02321 loss)
I0818 13:00:25.944262 20702 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0818 13:00:36.631353 20702 solver.cpp:228] Iteration 32100, loss = 1.09886
I0818 13:00:36.631527 20702 solver.cpp:244]     Train net output #0: loss = 1.10923 (* 1 = 1.10923 loss)
I0818 13:00:36.631553 20702 sgd_solver.cpp:106] Iteration 32100, lr = 0.001
I0818 13:00:47.317104 20702 solver.cpp:228] Iteration 32200, loss = 1.09801
I0818 13:00:47.317178 20702 solver.cpp:244]     Train net output #0: loss = 1.01522 (* 1 = 1.01522 loss)
I0818 13:00:47.317200 20702 sgd_solver.cpp:106] Iteration 32200, lr = 0.001
I0818 13:00:58.004318 20702 solver.cpp:228] Iteration 32300, loss = 1.0909
I0818 13:00:58.004401 20702 solver.cpp:244]     Train net output #0: loss = 1.01838 (* 1 = 1.01838 loss)
I0818 13:00:58.004426 20702 sgd_solver.cpp:106] Iteration 32300, lr = 0.001
I0818 13:01:08.691592 20702 solver.cpp:228] Iteration 32400, loss = 1.09235
I0818 13:01:08.691764 20702 solver.cpp:244]     Train net output #0: loss = 1.1003 (* 1 = 1.1003 loss)
I0818 13:01:08.691794 20702 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0818 13:01:19.378290 20702 solver.cpp:228] Iteration 32500, loss = 1.09781
I0818 13:01:19.378365 20702 solver.cpp:244]     Train net output #0: loss = 0.974159 (* 1 = 0.974159 loss)
I0818 13:01:19.378386 20702 sgd_solver.cpp:106] Iteration 32500, lr = 0.001
I0818 13:01:30.064709 20702 solver.cpp:228] Iteration 32600, loss = 1.08967
I0818 13:01:30.064796 20702 solver.cpp:244]     Train net output #0: loss = 1.14355 (* 1 = 1.14355 loss)
I0818 13:01:30.064820 20702 sgd_solver.cpp:106] Iteration 32600, lr = 0.001
I0818 13:01:40.750831 20702 solver.cpp:228] Iteration 32700, loss = 1.0882
I0818 13:01:40.750993 20702 solver.cpp:244]     Train net output #0: loss = 1.01404 (* 1 = 1.01404 loss)
I0818 13:01:40.751019 20702 sgd_solver.cpp:106] Iteration 32700, lr = 0.001
I0818 13:01:51.437404 20702 solver.cpp:228] Iteration 32800, loss = 1.07758
I0818 13:01:51.437479 20702 solver.cpp:244]     Train net output #0: loss = 1.01927 (* 1 = 1.01927 loss)
I0818 13:01:51.437501 20702 sgd_solver.cpp:106] Iteration 32800, lr = 0.001
I0818 13:02:02.122234 20702 solver.cpp:228] Iteration 32900, loss = 1.08555
I0818 13:02:02.122323 20702 solver.cpp:244]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0818 13:02:02.122344 20702 sgd_solver.cpp:106] Iteration 32900, lr = 0.001
I0818 13:02:12.811231 20702 solver.cpp:228] Iteration 33000, loss = 1.08969
I0818 13:02:12.811388 20702 solver.cpp:244]     Train net output #0: loss = 0.991587 (* 1 = 0.991587 loss)
I0818 13:02:12.811414 20702 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0818 13:02:23.511983 20702 solver.cpp:228] Iteration 33100, loss = 1.08407
I0818 13:02:23.512058 20702 solver.cpp:244]     Train net output #0: loss = 1.11683 (* 1 = 1.11683 loss)
I0818 13:02:23.512080 20702 sgd_solver.cpp:106] Iteration 33100, lr = 0.001
I0818 13:02:34.212990 20702 solver.cpp:228] Iteration 33200, loss = 1.07647
I0818 13:02:34.213076 20702 solver.cpp:244]     Train net output #0: loss = 0.946312 (* 1 = 0.946312 loss)
I0818 13:02:34.213099 20702 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0818 13:02:44.900009 20702 solver.cpp:228] Iteration 33300, loss = 1.07361
I0818 13:02:44.900267 20702 solver.cpp:244]     Train net output #0: loss = 1.03176 (* 1 = 1.03176 loss)
I0818 13:02:44.900300 20702 sgd_solver.cpp:106] Iteration 33300, lr = 0.001
I0818 13:02:55.611034 20702 solver.cpp:228] Iteration 33400, loss = 1.07394
I0818 13:02:55.611119 20702 solver.cpp:244]     Train net output #0: loss = 1.07268 (* 1 = 1.07268 loss)
I0818 13:02:55.611141 20702 sgd_solver.cpp:106] Iteration 33400, lr = 0.001
I0818 13:03:06.297767 20702 solver.cpp:228] Iteration 33500, loss = 1.08125
I0818 13:03:06.297838 20702 solver.cpp:244]     Train net output #0: loss = 0.97727 (* 1 = 0.97727 loss)
I0818 13:03:06.297860 20702 sgd_solver.cpp:106] Iteration 33500, lr = 0.001
I0818 13:03:16.982334 20702 solver.cpp:228] Iteration 33600, loss = 1.07729
I0818 13:03:16.982561 20702 solver.cpp:244]     Train net output #0: loss = 1.12464 (* 1 = 1.12464 loss)
I0818 13:03:16.982591 20702 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0818 13:03:27.702474 20702 solver.cpp:228] Iteration 33700, loss = 1.07283
I0818 13:03:27.702564 20702 solver.cpp:244]     Train net output #0: loss = 0.960304 (* 1 = 0.960304 loss)
I0818 13:03:27.702589 20702 sgd_solver.cpp:106] Iteration 33700, lr = 0.001
I0818 13:03:38.388931 20702 solver.cpp:228] Iteration 33800, loss = 1.06111
I0818 13:03:38.388993 20702 solver.cpp:244]     Train net output #0: loss = 0.997178 (* 1 = 0.997178 loss)
I0818 13:03:38.389017 20702 sgd_solver.cpp:106] Iteration 33800, lr = 0.001
I0818 13:03:49.075253 20702 solver.cpp:228] Iteration 33900, loss = 1.0697
I0818 13:03:49.075471 20702 solver.cpp:244]     Train net output #0: loss = 1.07036 (* 1 = 1.07036 loss)
I0818 13:03:49.075497 20702 sgd_solver.cpp:106] Iteration 33900, lr = 0.001
I0818 13:03:59.656107 20702 solver.cpp:337] Iteration 34000, Testing net (#0)
I0818 13:04:01.779022 20702 solver.cpp:404]     Test net output #0: loss = 1.22864 (* 1 = 1.22864 loss)
I0818 13:04:01.849872 20702 solver.cpp:228] Iteration 34000, loss = 1.07617
I0818 13:04:01.849922 20702 solver.cpp:244]     Train net output #0: loss = 0.967489 (* 1 = 0.967489 loss)
I0818 13:04:01.849946 20702 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0818 13:04:12.534761 20702 solver.cpp:228] Iteration 34100, loss = 1.06705
I0818 13:04:12.534840 20702 solver.cpp:244]     Train net output #0: loss = 1.13743 (* 1 = 1.13743 loss)
I0818 13:04:12.534862 20702 sgd_solver.cpp:106] Iteration 34100, lr = 0.001
I0818 13:04:23.220283 20702 solver.cpp:228] Iteration 34200, loss = 1.06657
I0818 13:04:23.220504 20702 solver.cpp:244]     Train net output #0: loss = 0.936045 (* 1 = 0.936045 loss)
I0818 13:04:23.220536 20702 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0818 13:04:33.924929 20702 solver.cpp:228] Iteration 34300, loss = 1.05608
I0818 13:04:33.925017 20702 solver.cpp:244]     Train net output #0: loss = 0.986027 (* 1 = 0.986027 loss)
I0818 13:04:33.925040 20702 sgd_solver.cpp:106] Iteration 34300, lr = 0.001
I0818 13:04:44.609283 20702 solver.cpp:228] Iteration 34400, loss = 1.06411
I0818 13:04:44.609357 20702 solver.cpp:244]     Train net output #0: loss = 1.07457 (* 1 = 1.07457 loss)
I0818 13:04:44.609380 20702 sgd_solver.cpp:106] Iteration 34400, lr = 0.001
I0818 13:04:55.296969 20702 solver.cpp:228] Iteration 34500, loss = 1.06399
I0818 13:04:55.297245 20702 solver.cpp:244]     Train net output #0: loss = 0.983844 (* 1 = 0.983844 loss)
I0818 13:04:55.297276 20702 sgd_solver.cpp:106] Iteration 34500, lr = 0.001
I0818 13:05:06.023123 20702 solver.cpp:228] Iteration 34600, loss = 1.06118
I0818 13:05:06.023207 20702 solver.cpp:244]     Train net output #0: loss = 1.08899 (* 1 = 1.08899 loss)
I0818 13:05:06.023231 20702 sgd_solver.cpp:106] Iteration 34600, lr = 0.001
I0818 13:05:16.718211 20702 solver.cpp:228] Iteration 34700, loss = 1.06035
I0818 13:05:16.718278 20702 solver.cpp:244]     Train net output #0: loss = 0.957061 (* 1 = 0.957061 loss)
I0818 13:05:16.718299 20702 sgd_solver.cpp:106] Iteration 34700, lr = 0.001
I0818 13:05:27.404781 20702 solver.cpp:228] Iteration 34800, loss = 1.04799
I0818 13:05:27.405066 20702 solver.cpp:244]     Train net output #0: loss = 0.970976 (* 1 = 0.970976 loss)
I0818 13:05:27.405097 20702 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0818 13:05:38.111169 20702 solver.cpp:228] Iteration 34900, loss = 1.05988
I0818 13:05:38.111248 20702 solver.cpp:244]     Train net output #0: loss = 1.07878 (* 1 = 1.07878 loss)
I0818 13:05:38.111269 20702 sgd_solver.cpp:106] Iteration 34900, lr = 0.001
I0818 13:05:48.796310 20702 solver.cpp:228] Iteration 35000, loss = 1.0587
I0818 13:05:48.796385 20702 solver.cpp:244]     Train net output #0: loss = 0.960401 (* 1 = 0.960401 loss)
I0818 13:05:48.796406 20702 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0818 13:05:59.481350 20702 solver.cpp:228] Iteration 35100, loss = 1.06264
I0818 13:05:59.481585 20702 solver.cpp:244]     Train net output #0: loss = 1.11 (* 1 = 1.11 loss)
I0818 13:05:59.481616 20702 sgd_solver.cpp:106] Iteration 35100, lr = 0.001
I0818 13:06:10.189873 20702 solver.cpp:228] Iteration 35200, loss = 1.05415
I0818 13:06:10.189952 20702 solver.cpp:244]     Train net output #0: loss = 0.939717 (* 1 = 0.939717 loss)
I0818 13:06:10.189975 20702 sgd_solver.cpp:106] Iteration 35200, lr = 0.001
I0818 13:06:20.874301 20702 solver.cpp:228] Iteration 35300, loss = 1.04563
I0818 13:06:20.874373 20702 solver.cpp:244]     Train net output #0: loss = 0.958603 (* 1 = 0.958603 loss)
I0818 13:06:20.874394 20702 sgd_solver.cpp:106] Iteration 35300, lr = 0.001
I0818 13:06:31.559311 20702 solver.cpp:228] Iteration 35400, loss = 1.05576
I0818 13:06:31.559540 20702 solver.cpp:244]     Train net output #0: loss = 1.07119 (* 1 = 1.07119 loss)
I0818 13:06:31.559571 20702 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0818 13:06:42.242964 20702 solver.cpp:228] Iteration 35500, loss = 1.05532
I0818 13:06:42.243044 20702 solver.cpp:244]     Train net output #0: loss = 0.942328 (* 1 = 0.942328 loss)
I0818 13:06:42.243067 20702 sgd_solver.cpp:106] Iteration 35500, lr = 0.001
I0818 13:06:52.926009 20702 solver.cpp:228] Iteration 35600, loss = 1.04902
I0818 13:06:52.926085 20702 solver.cpp:244]     Train net output #0: loss = 1.07756 (* 1 = 1.07756 loss)
I0818 13:06:52.926106 20702 sgd_solver.cpp:106] Iteration 35600, lr = 0.001
I0818 13:07:03.609009 20702 solver.cpp:228] Iteration 35700, loss = 1.04686
I0818 13:07:03.609221 20702 solver.cpp:244]     Train net output #0: loss = 0.937333 (* 1 = 0.937333 loss)
I0818 13:07:03.609247 20702 sgd_solver.cpp:106] Iteration 35700, lr = 0.001
I0818 13:07:14.327472 20702 solver.cpp:228] Iteration 35800, loss = 1.03547
I0818 13:07:14.327590 20702 solver.cpp:244]     Train net output #0: loss = 0.95333 (* 1 = 0.95333 loss)
I0818 13:07:14.327635 20702 sgd_solver.cpp:106] Iteration 35800, lr = 0.001
I0818 13:07:25.081924 20702 solver.cpp:228] Iteration 35900, loss = 1.0456
I0818 13:07:25.082005 20702 solver.cpp:244]     Train net output #0: loss = 1.06025 (* 1 = 1.06025 loss)
I0818 13:07:25.082026 20702 sgd_solver.cpp:106] Iteration 35900, lr = 0.001
I0818 13:07:35.661559 20702 solver.cpp:337] Iteration 36000, Testing net (#0)
I0818 13:07:37.783125 20702 solver.cpp:404]     Test net output #0: loss = 1.22846 (* 1 = 1.22846 loss)
I0818 13:07:37.854082 20702 solver.cpp:228] Iteration 36000, loss = 1.04688
I0818 13:07:37.854122 20702 solver.cpp:244]     Train net output #0: loss = 0.954365 (* 1 = 0.954365 loss)
I0818 13:07:37.854146 20702 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0818 13:07:48.538055 20702 solver.cpp:228] Iteration 36100, loss = 1.0439
I0818 13:07:48.538130 20702 solver.cpp:244]     Train net output #0: loss = 1.07425 (* 1 = 1.07425 loss)
I0818 13:07:48.538152 20702 sgd_solver.cpp:106] Iteration 36100, lr = 0.001
I0818 13:07:59.225389 20702 solver.cpp:228] Iteration 36200, loss = 1.04425
I0818 13:07:59.225474 20702 solver.cpp:244]     Train net output #0: loss = 0.939878 (* 1 = 0.939878 loss)
I0818 13:07:59.225497 20702 sgd_solver.cpp:106] Iteration 36200, lr = 0.001
I0818 13:08:09.909220 20702 solver.cpp:228] Iteration 36300, loss = 1.03877
I0818 13:08:09.909533 20702 solver.cpp:244]     Train net output #0: loss = 0.962054 (* 1 = 0.962054 loss)
I0818 13:08:09.909571 20702 sgd_solver.cpp:106] Iteration 36300, lr = 0.001
I0818 13:08:20.630794 20702 solver.cpp:228] Iteration 36400, loss = 1.04352
I0818 13:08:20.630872 20702 solver.cpp:244]     Train net output #0: loss = 1.09533 (* 1 = 1.09533 loss)
I0818 13:08:20.630894 20702 sgd_solver.cpp:106] Iteration 36400, lr = 0.001
I0818 13:08:31.317749 20702 solver.cpp:228] Iteration 36500, loss = 1.04279
I0818 13:08:31.317833 20702 solver.cpp:244]     Train net output #0: loss = 0.9765 (* 1 = 0.9765 loss)
I0818 13:08:31.317857 20702 sgd_solver.cpp:106] Iteration 36500, lr = 0.001
I0818 13:08:42.003991 20702 solver.cpp:228] Iteration 36600, loss = 1.03935
I0818 13:08:42.004250 20702 solver.cpp:244]     Train net output #0: loss = 1.09358 (* 1 = 1.09358 loss)
I0818 13:08:42.004292 20702 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0818 13:08:52.687832 20702 solver.cpp:228] Iteration 36700, loss = 1.0339
I0818 13:08:52.687907 20702 solver.cpp:244]     Train net output #0: loss = 0.953021 (* 1 = 0.953021 loss)
I0818 13:08:52.687929 20702 sgd_solver.cpp:106] Iteration 36700, lr = 0.001
I0818 13:09:03.371132 20702 solver.cpp:228] Iteration 36800, loss = 1.02684
I0818 13:09:03.371219 20702 solver.cpp:244]     Train net output #0: loss = 0.924584 (* 1 = 0.924584 loss)
I0818 13:09:03.371242 20702 sgd_solver.cpp:106] Iteration 36800, lr = 0.001
I0818 13:09:14.055474 20702 solver.cpp:228] Iteration 36900, loss = 1.0343
I0818 13:09:14.055687 20702 solver.cpp:244]     Train net output #0: loss = 1.11566 (* 1 = 1.11566 loss)
I0818 13:09:14.055718 20702 sgd_solver.cpp:106] Iteration 36900, lr = 0.001
I0818 13:09:24.739270 20702 solver.cpp:228] Iteration 37000, loss = 1.03846
I0818 13:09:24.739347 20702 solver.cpp:244]     Train net output #0: loss = 0.930865 (* 1 = 0.930865 loss)
I0818 13:09:24.739369 20702 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0818 13:09:35.426218 20702 solver.cpp:228] Iteration 37100, loss = 1.03817
I0818 13:09:35.426301 20702 solver.cpp:244]     Train net output #0: loss = 1.09303 (* 1 = 1.09303 loss)
I0818 13:09:35.426323 20702 sgd_solver.cpp:106] Iteration 37100, lr = 0.001
I0818 13:09:46.113343 20702 solver.cpp:228] Iteration 37200, loss = 1.03198
I0818 13:09:46.113566 20702 solver.cpp:244]     Train net output #0: loss = 0.901188 (* 1 = 0.901188 loss)
I0818 13:09:46.113592 20702 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0818 13:09:56.798547 20702 solver.cpp:228] Iteration 37300, loss = 1.02076
I0818 13:09:56.798630 20702 solver.cpp:244]     Train net output #0: loss = 0.954094 (* 1 = 0.954094 loss)
I0818 13:09:56.798651 20702 sgd_solver.cpp:106] Iteration 37300, lr = 0.001
I0818 13:10:07.499267 20702 solver.cpp:228] Iteration 37400, loss = 1.02903
I0818 13:10:07.499342 20702 solver.cpp:244]     Train net output #0: loss = 1.05801 (* 1 = 1.05801 loss)
I0818 13:10:07.499363 20702 sgd_solver.cpp:106] Iteration 37400, lr = 0.001
I0818 13:10:18.187779 20702 solver.cpp:228] Iteration 37500, loss = 1.02969
I0818 13:10:18.187979 20702 solver.cpp:244]     Train net output #0: loss = 0.962178 (* 1 = 0.962178 loss)
I0818 13:10:18.188016 20702 sgd_solver.cpp:106] Iteration 37500, lr = 0.001
I0818 13:10:28.873165 20702 solver.cpp:228] Iteration 37600, loss = 1.02775
I0818 13:10:28.873250 20702 solver.cpp:244]     Train net output #0: loss = 1.08834 (* 1 = 1.08834 loss)
I0818 13:10:28.873271 20702 sgd_solver.cpp:106] Iteration 37600, lr = 0.001
I0818 13:10:39.559084 20702 solver.cpp:228] Iteration 37700, loss = 1.02113
I0818 13:10:39.559161 20702 solver.cpp:244]     Train net output #0: loss = 0.889518 (* 1 = 0.889518 loss)
I0818 13:10:39.559182 20702 sgd_solver.cpp:106] Iteration 37700, lr = 0.001
I0818 13:10:50.245606 20702 solver.cpp:228] Iteration 37800, loss = 1.01361
I0818 13:10:50.245882 20702 solver.cpp:244]     Train net output #0: loss = 0.957572 (* 1 = 0.957572 loss)
I0818 13:10:50.245911 20702 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0818 13:11:00.933398 20702 solver.cpp:228] Iteration 37900, loss = 1.02215
I0818 13:11:00.933481 20702 solver.cpp:244]     Train net output #0: loss = 1.05384 (* 1 = 1.05384 loss)
I0818 13:11:00.933504 20702 sgd_solver.cpp:106] Iteration 37900, lr = 0.001
I0818 13:11:11.513111 20702 solver.cpp:337] Iteration 38000, Testing net (#0)
I0818 13:11:13.636497 20702 solver.cpp:404]     Test net output #0: loss = 1.2437 (* 1 = 1.2437 loss)
I0818 13:11:13.707399 20702 solver.cpp:228] Iteration 38000, loss = 1.02137
I0818 13:11:13.707448 20702 solver.cpp:244]     Train net output #0: loss = 0.955717 (* 1 = 0.955717 loss)
I0818 13:11:13.707471 20702 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0818 13:11:24.393061 20702 solver.cpp:228] Iteration 38100, loss = 1.02038
I0818 13:11:24.393296 20702 solver.cpp:244]     Train net output #0: loss = 1.09174 (* 1 = 1.09174 loss)
I0818 13:11:24.393322 20702 sgd_solver.cpp:106] Iteration 38100, lr = 0.001
I0818 13:11:35.100531 20702 solver.cpp:228] Iteration 38200, loss = 1.02301
I0818 13:11:35.100621 20702 solver.cpp:244]     Train net output #0: loss = 0.876548 (* 1 = 0.876548 loss)
I0818 13:11:35.100646 20702 sgd_solver.cpp:106] Iteration 38200, lr = 0.001
I0818 13:11:45.785761 20702 solver.cpp:228] Iteration 38300, loss = 1.0141
I0818 13:11:45.785836 20702 solver.cpp:244]     Train net output #0: loss = 0.931627 (* 1 = 0.931627 loss)
I0818 13:11:45.785858 20702 sgd_solver.cpp:106] Iteration 38300, lr = 0.001
I0818 13:11:56.471483 20702 solver.cpp:228] Iteration 38400, loss = 1.02069
I0818 13:11:56.471679 20702 solver.cpp:244]     Train net output #0: loss = 1.07304 (* 1 = 1.07304 loss)
I0818 13:11:56.471705 20702 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0818 13:12:07.157557 20702 solver.cpp:228] Iteration 38500, loss = 1.01258
I0818 13:12:07.157634 20702 solver.cpp:244]     Train net output #0: loss = 0.952151 (* 1 = 0.952151 loss)
I0818 13:12:07.157655 20702 sgd_solver.cpp:106] Iteration 38500, lr = 0.001
I0818 13:12:17.861604 20702 solver.cpp:228] Iteration 38600, loss = 1.01873
I0818 13:12:17.861671 20702 solver.cpp:244]     Train net output #0: loss = 1.08945 (* 1 = 1.08945 loss)
I0818 13:12:17.861693 20702 sgd_solver.cpp:106] Iteration 38600, lr = 0.001
I0818 13:12:28.554669 20702 solver.cpp:228] Iteration 38700, loss = 1.01341
I0818 13:12:28.554836 20702 solver.cpp:244]     Train net output #0: loss = 0.89567 (* 1 = 0.89567 loss)
I0818 13:12:28.554863 20702 sgd_solver.cpp:106] Iteration 38700, lr = 0.001
I0818 13:12:39.238829 20702 solver.cpp:228] Iteration 38800, loss = 1.00649
I0818 13:12:39.238907 20702 solver.cpp:244]     Train net output #0: loss = 0.96505 (* 1 = 0.96505 loss)
I0818 13:12:39.238930 20702 sgd_solver.cpp:106] Iteration 38800, lr = 0.001
I0818 13:12:49.924098 20702 solver.cpp:228] Iteration 38900, loss = 1.01012
I0818 13:12:49.924172 20702 solver.cpp:244]     Train net output #0: loss = 1.0569 (* 1 = 1.0569 loss)
I0818 13:12:49.924195 20702 sgd_solver.cpp:106] Iteration 38900, lr = 0.001
I0818 13:13:00.607667 20702 solver.cpp:228] Iteration 39000, loss = 1.00865
I0818 13:13:00.607844 20702 solver.cpp:244]     Train net output #0: loss = 0.985825 (* 1 = 0.985825 loss)
I0818 13:13:00.607873 20702 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0818 13:13:11.293494 20702 solver.cpp:228] Iteration 39100, loss = 1.01389
I0818 13:13:11.293570 20702 solver.cpp:244]     Train net output #0: loss = 1.04622 (* 1 = 1.04622 loss)
I0818 13:13:11.293592 20702 sgd_solver.cpp:106] Iteration 39100, lr = 0.001
I0818 13:13:21.976948 20702 solver.cpp:228] Iteration 39200, loss = 1.003
I0818 13:13:21.977026 20702 solver.cpp:244]     Train net output #0: loss = 0.849222 (* 1 = 0.849222 loss)
I0818 13:13:21.977049 20702 sgd_solver.cpp:106] Iteration 39200, lr = 0.001
I0818 13:13:32.662060 20702 solver.cpp:228] Iteration 39300, loss = 0.999755
I0818 13:13:32.662361 20702 solver.cpp:244]     Train net output #0: loss = 0.931722 (* 1 = 0.931722 loss)
I0818 13:13:32.662395 20702 sgd_solver.cpp:106] Iteration 39300, lr = 0.001
I0818 13:13:43.346614 20702 solver.cpp:228] Iteration 39400, loss = 1.0055
I0818 13:13:43.346690 20702 solver.cpp:244]     Train net output #0: loss = 1.02819 (* 1 = 1.02819 loss)
I0818 13:13:43.346714 20702 sgd_solver.cpp:106] Iteration 39400, lr = 0.001
I0818 13:13:54.032284 20702 solver.cpp:228] Iteration 39500, loss = 0.997183
I0818 13:13:54.032361 20702 solver.cpp:244]     Train net output #0: loss = 0.918236 (* 1 = 0.918236 loss)
I0818 13:13:54.032382 20702 sgd_solver.cpp:106] Iteration 39500, lr = 0.001
I0818 13:14:04.717748 20702 solver.cpp:228] Iteration 39600, loss = 1.00702
I0818 13:14:04.717941 20702 solver.cpp:244]     Train net output #0: loss = 1.05421 (* 1 = 1.05421 loss)
I0818 13:14:04.717968 20702 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0818 13:14:15.401926 20702 solver.cpp:228] Iteration 39700, loss = 0.998736
I0818 13:14:15.402003 20702 solver.cpp:244]     Train net output #0: loss = 0.861121 (* 1 = 0.861121 loss)
I0818 13:14:15.402025 20702 sgd_solver.cpp:106] Iteration 39700, lr = 0.001
I0818 13:14:26.086376 20702 solver.cpp:228] Iteration 39800, loss = 0.988113
I0818 13:14:26.086457 20702 solver.cpp:244]     Train net output #0: loss = 0.921167 (* 1 = 0.921167 loss)
I0818 13:14:26.086480 20702 sgd_solver.cpp:106] Iteration 39800, lr = 0.001
I0818 13:14:36.772120 20702 solver.cpp:228] Iteration 39900, loss = 0.99782
I0818 13:14:36.772325 20702 solver.cpp:244]     Train net output #0: loss = 1.02553 (* 1 = 1.02553 loss)
I0818 13:14:36.772361 20702 sgd_solver.cpp:106] Iteration 39900, lr = 0.001
I0818 13:14:47.374019 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_40000.caffemodel
I0818 13:14:47.422032 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_40000.solverstate
I0818 13:14:47.427507 20702 solver.cpp:337] Iteration 40000, Testing net (#0)
I0818 13:14:49.515300 20702 solver.cpp:404]     Test net output #0: loss = 1.24242 (* 1 = 1.24242 loss)
I0818 13:14:49.586158 20702 solver.cpp:228] Iteration 40000, loss = 0.99035
I0818 13:14:49.586197 20702 solver.cpp:244]     Train net output #0: loss = 0.910332 (* 1 = 0.910332 loss)
I0818 13:14:49.586226 20702 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0818 13:15:00.269762 20702 solver.cpp:228] Iteration 40100, loss = 0.995565
I0818 13:15:00.269850 20702 solver.cpp:244]     Train net output #0: loss = 1.06015 (* 1 = 1.06015 loss)
I0818 13:15:00.269872 20702 sgd_solver.cpp:106] Iteration 40100, lr = 0.001
I0818 13:15:10.974340 20702 solver.cpp:228] Iteration 40200, loss = 0.998986
I0818 13:15:10.974529 20702 solver.cpp:244]     Train net output #0: loss = 0.860926 (* 1 = 0.860926 loss)
I0818 13:15:10.974553 20702 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0818 13:15:21.660367 20702 solver.cpp:228] Iteration 40300, loss = 0.986078
I0818 13:15:21.660442 20702 solver.cpp:244]     Train net output #0: loss = 0.870306 (* 1 = 0.870306 loss)
I0818 13:15:21.660464 20702 sgd_solver.cpp:106] Iteration 40300, lr = 0.001
I0818 13:15:32.344725 20702 solver.cpp:228] Iteration 40400, loss = 0.992328
I0818 13:15:32.344810 20702 solver.cpp:244]     Train net output #0: loss = 1.02425 (* 1 = 1.02425 loss)
I0818 13:15:32.344833 20702 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0818 13:15:43.027405 20702 solver.cpp:228] Iteration 40500, loss = 0.986049
I0818 13:15:43.027528 20702 solver.cpp:244]     Train net output #0: loss = 0.940967 (* 1 = 0.940967 loss)
I0818 13:15:43.027551 20702 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0818 13:15:53.713675 20702 solver.cpp:228] Iteration 40600, loss = 0.989968
I0818 13:15:53.713752 20702 solver.cpp:244]     Train net output #0: loss = 1.06961 (* 1 = 1.06961 loss)
I0818 13:15:53.713774 20702 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0818 13:16:04.399595 20702 solver.cpp:228] Iteration 40700, loss = 0.988913
I0818 13:16:04.399680 20702 solver.cpp:244]     Train net output #0: loss = 0.871499 (* 1 = 0.871499 loss)
I0818 13:16:04.399701 20702 sgd_solver.cpp:106] Iteration 40700, lr = 0.001
I0818 13:16:15.106284 20702 solver.cpp:228] Iteration 40800, loss = 0.980764
I0818 13:16:15.106580 20702 solver.cpp:244]     Train net output #0: loss = 0.933922 (* 1 = 0.933922 loss)
I0818 13:16:15.106611 20702 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0818 13:16:25.790873 20702 solver.cpp:228] Iteration 40900, loss = 0.987116
I0818 13:16:25.790959 20702 solver.cpp:244]     Train net output #0: loss = 1.03545 (* 1 = 1.03545 loss)
I0818 13:16:25.790982 20702 sgd_solver.cpp:106] Iteration 40900, lr = 0.001
I0818 13:16:36.476511 20702 solver.cpp:228] Iteration 41000, loss = 0.98197
I0818 13:16:36.476585 20702 solver.cpp:244]     Train net output #0: loss = 0.906596 (* 1 = 0.906596 loss)
I0818 13:16:36.476613 20702 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0818 13:16:47.161991 20702 solver.cpp:228] Iteration 41100, loss = 0.987076
I0818 13:16:47.162174 20702 solver.cpp:244]     Train net output #0: loss = 1.0431 (* 1 = 1.0431 loss)
I0818 13:16:47.162202 20702 sgd_solver.cpp:106] Iteration 41100, lr = 0.001
I0818 13:16:57.847561 20702 solver.cpp:228] Iteration 41200, loss = 0.982352
I0818 13:16:57.847640 20702 solver.cpp:244]     Train net output #0: loss = 0.87337 (* 1 = 0.87337 loss)
I0818 13:16:57.847662 20702 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0818 13:17:08.532286 20702 solver.cpp:228] Iteration 41300, loss = 0.973417
I0818 13:17:08.532359 20702 solver.cpp:244]     Train net output #0: loss = 0.858335 (* 1 = 0.858335 loss)
I0818 13:17:08.532382 20702 sgd_solver.cpp:106] Iteration 41300, lr = 0.001
I0818 13:17:19.232431 20702 solver.cpp:228] Iteration 41400, loss = 0.985096
I0818 13:17:19.232589 20702 solver.cpp:244]     Train net output #0: loss = 1.0338 (* 1 = 1.0338 loss)
I0818 13:17:19.232621 20702 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0818 13:17:29.923566 20702 solver.cpp:228] Iteration 41500, loss = 0.979005
I0818 13:17:29.923640 20702 solver.cpp:244]     Train net output #0: loss = 0.876986 (* 1 = 0.876986 loss)
I0818 13:17:29.923666 20702 sgd_solver.cpp:106] Iteration 41500, lr = 0.001
I0818 13:17:40.608144 20702 solver.cpp:228] Iteration 41600, loss = 0.984419
I0818 13:17:40.608220 20702 solver.cpp:244]     Train net output #0: loss = 1.072 (* 1 = 1.072 loss)
I0818 13:17:40.608242 20702 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0818 13:17:51.291400 20702 solver.cpp:228] Iteration 41700, loss = 0.975122
I0818 13:17:51.291637 20702 solver.cpp:244]     Train net output #0: loss = 0.840959 (* 1 = 0.840959 loss)
I0818 13:17:51.291667 20702 sgd_solver.cpp:106] Iteration 41700, lr = 0.001
I0818 13:18:01.998188 20702 solver.cpp:228] Iteration 41800, loss = 0.969952
I0818 13:18:01.998275 20702 solver.cpp:244]     Train net output #0: loss = 0.896784 (* 1 = 0.896784 loss)
I0818 13:18:01.998297 20702 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0818 13:18:12.718423 20702 solver.cpp:228] Iteration 41900, loss = 0.977924
I0818 13:18:12.718508 20702 solver.cpp:244]     Train net output #0: loss = 1.00518 (* 1 = 1.00518 loss)
I0818 13:18:12.718531 20702 sgd_solver.cpp:106] Iteration 41900, lr = 0.001
I0818 13:18:31.468098 20702 solver.cpp:337] Iteration 42000, Testing net (#0)
I0818 13:18:36.960898 20702 solver.cpp:404]     Test net output #0: loss = 1.21958 (* 1 = 1.21958 loss)
I0818 13:18:37.123426 20702 solver.cpp:228] Iteration 42000, loss = 0.972426
I0818 13:18:37.123466 20702 solver.cpp:244]     Train net output #0: loss = 0.888045 (* 1 = 0.888045 loss)
I0818 13:18:37.123488 20702 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0818 13:18:52.205775 20702 solver.cpp:228] Iteration 42100, loss = 0.973205
I0818 13:18:52.205859 20702 solver.cpp:244]     Train net output #0: loss = 1.05928 (* 1 = 1.05928 loss)
I0818 13:18:52.205883 20702 sgd_solver.cpp:106] Iteration 42100, lr = 0.001
I0818 13:19:17.643635 20702 solver.cpp:228] Iteration 42200, loss = 0.968251
I0818 13:19:17.643929 20702 solver.cpp:244]     Train net output #0: loss = 0.843899 (* 1 = 0.843899 loss)
I0818 13:19:17.643954 20702 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0818 13:19:28.621970 20702 solver.cpp:228] Iteration 42300, loss = 0.955666
I0818 13:19:28.622052 20702 solver.cpp:244]     Train net output #0: loss = 0.907082 (* 1 = 0.907082 loss)
I0818 13:19:28.622076 20702 sgd_solver.cpp:106] Iteration 42300, lr = 0.001
I0818 13:19:39.292955 20702 solver.cpp:228] Iteration 42400, loss = 0.97393
I0818 13:19:39.293028 20702 solver.cpp:244]     Train net output #0: loss = 1.00931 (* 1 = 1.00931 loss)
I0818 13:19:39.293051 20702 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0818 13:19:49.962970 20702 solver.cpp:228] Iteration 42500, loss = 0.967448
I0818 13:19:49.963121 20702 solver.cpp:244]     Train net output #0: loss = 0.878983 (* 1 = 0.878983 loss)
I0818 13:19:49.963150 20702 sgd_solver.cpp:106] Iteration 42500, lr = 0.001
I0818 13:20:00.642143 20702 solver.cpp:228] Iteration 42600, loss = 0.966775
I0818 13:20:00.642225 20702 solver.cpp:244]     Train net output #0: loss = 1.00949 (* 1 = 1.00949 loss)
I0818 13:20:00.642246 20702 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0818 13:20:11.339186 20702 solver.cpp:228] Iteration 42700, loss = 0.961216
I0818 13:20:11.339262 20702 solver.cpp:244]     Train net output #0: loss = 0.861369 (* 1 = 0.861369 loss)
I0818 13:20:11.339282 20702 sgd_solver.cpp:106] Iteration 42700, lr = 0.001
I0818 13:20:22.013095 20702 solver.cpp:228] Iteration 42800, loss = 0.952568
I0818 13:20:22.013262 20702 solver.cpp:244]     Train net output #0: loss = 0.870304 (* 1 = 0.870304 loss)
I0818 13:20:22.013288 20702 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0818 13:20:32.689393 20702 solver.cpp:228] Iteration 42900, loss = 0.967603
I0818 13:20:32.689479 20702 solver.cpp:244]     Train net output #0: loss = 1.01628 (* 1 = 1.01628 loss)
I0818 13:20:32.689502 20702 sgd_solver.cpp:106] Iteration 42900, lr = 0.001
I0818 13:20:43.364467 20702 solver.cpp:228] Iteration 43000, loss = 0.957592
I0818 13:20:43.364542 20702 solver.cpp:244]     Train net output #0: loss = 0.876684 (* 1 = 0.876684 loss)
I0818 13:20:43.364565 20702 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0818 13:20:54.041116 20702 solver.cpp:228] Iteration 43100, loss = 0.95875
I0818 13:20:54.041301 20702 solver.cpp:244]     Train net output #0: loss = 1.02502 (* 1 = 1.02502 loss)
I0818 13:20:54.041332 20702 sgd_solver.cpp:106] Iteration 43100, lr = 0.001
I0818 13:21:04.751888 20702 solver.cpp:228] Iteration 43200, loss = 0.961872
I0818 13:21:04.751969 20702 solver.cpp:244]     Train net output #0: loss = 0.818648 (* 1 = 0.818648 loss)
I0818 13:21:04.752002 20702 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0818 13:21:15.450767 20702 solver.cpp:228] Iteration 43300, loss = 0.943736
I0818 13:21:15.450847 20702 solver.cpp:244]     Train net output #0: loss = 0.885934 (* 1 = 0.885934 loss)
I0818 13:21:15.450870 20702 sgd_solver.cpp:106] Iteration 43300, lr = 0.001
I0818 13:21:26.209878 20702 solver.cpp:228] Iteration 43400, loss = 0.956194
I0818 13:21:26.210048 20702 solver.cpp:244]     Train net output #0: loss = 1.00831 (* 1 = 1.00831 loss)
I0818 13:21:26.210077 20702 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0818 13:21:36.890820 20702 solver.cpp:228] Iteration 43500, loss = 0.954237
I0818 13:21:36.890898 20702 solver.cpp:244]     Train net output #0: loss = 0.881833 (* 1 = 0.881833 loss)
I0818 13:21:36.890921 20702 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0818 13:21:47.572337 20702 solver.cpp:228] Iteration 43600, loss = 0.958278
I0818 13:21:47.572413 20702 solver.cpp:244]     Train net output #0: loss = 1.00281 (* 1 = 1.00281 loss)
I0818 13:21:47.572435 20702 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0818 13:21:58.250820 20702 solver.cpp:228] Iteration 43700, loss = 0.951214
I0818 13:21:58.250982 20702 solver.cpp:244]     Train net output #0: loss = 0.817807 (* 1 = 0.817807 loss)
I0818 13:21:58.251005 20702 sgd_solver.cpp:106] Iteration 43700, lr = 0.001
I0818 13:22:08.929185 20702 solver.cpp:228] Iteration 43800, loss = 0.941377
I0818 13:22:08.929257 20702 solver.cpp:244]     Train net output #0: loss = 0.841465 (* 1 = 0.841465 loss)
I0818 13:22:08.929278 20702 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0818 13:22:19.622680 20702 solver.cpp:228] Iteration 43900, loss = 0.956207
I0818 13:22:19.622755 20702 solver.cpp:244]     Train net output #0: loss = 0.980079 (* 1 = 0.980079 loss)
I0818 13:22:19.622777 20702 sgd_solver.cpp:106] Iteration 43900, lr = 0.001
I0818 13:22:30.203161 20702 solver.cpp:337] Iteration 44000, Testing net (#0)
I0818 13:22:32.323159 20702 solver.cpp:404]     Test net output #0: loss = 1.20286 (* 1 = 1.20286 loss)
I0818 13:22:32.394176 20702 solver.cpp:228] Iteration 44000, loss = 0.951
I0818 13:22:32.394217 20702 solver.cpp:244]     Train net output #0: loss = 0.875137 (* 1 = 0.875137 loss)
I0818 13:22:32.394243 20702 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0818 13:22:43.073967 20702 solver.cpp:228] Iteration 44100, loss = 0.949553
I0818 13:22:43.074033 20702 solver.cpp:244]     Train net output #0: loss = 1.00221 (* 1 = 1.00221 loss)
I0818 13:22:43.074057 20702 sgd_solver.cpp:106] Iteration 44100, lr = 0.001
I0818 13:22:53.753752 20702 solver.cpp:228] Iteration 44200, loss = 0.951404
I0818 13:22:53.753820 20702 solver.cpp:244]     Train net output #0: loss = 0.811679 (* 1 = 0.811679 loss)
I0818 13:22:53.753844 20702 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0818 13:23:04.433703 20702 solver.cpp:228] Iteration 44300, loss = 0.935843
I0818 13:23:04.433874 20702 solver.cpp:244]     Train net output #0: loss = 0.838855 (* 1 = 0.838855 loss)
I0818 13:23:04.433900 20702 sgd_solver.cpp:106] Iteration 44300, lr = 0.001
I0818 13:23:15.115730 20702 solver.cpp:228] Iteration 44400, loss = 0.945168
I0818 13:23:15.115804 20702 solver.cpp:244]     Train net output #0: loss = 0.965479 (* 1 = 0.965479 loss)
I0818 13:23:15.115826 20702 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0818 13:23:25.798362 20702 solver.cpp:228] Iteration 44500, loss = 0.942222
I0818 13:23:25.798444 20702 solver.cpp:244]     Train net output #0: loss = 0.86758 (* 1 = 0.86758 loss)
I0818 13:23:25.798470 20702 sgd_solver.cpp:106] Iteration 44500, lr = 0.001
I0818 13:23:36.476075 20702 solver.cpp:228] Iteration 44600, loss = 0.943171
I0818 13:23:36.476305 20702 solver.cpp:244]     Train net output #0: loss = 0.981374 (* 1 = 0.981374 loss)
I0818 13:23:36.476328 20702 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0818 13:23:47.154691 20702 solver.cpp:228] Iteration 44700, loss = 0.944099
I0818 13:23:47.154767 20702 solver.cpp:244]     Train net output #0: loss = 0.856548 (* 1 = 0.856548 loss)
I0818 13:23:47.154855 20702 sgd_solver.cpp:106] Iteration 44700, lr = 0.001
I0818 13:23:57.833045 20702 solver.cpp:228] Iteration 44800, loss = 0.930768
I0818 13:23:57.833128 20702 solver.cpp:244]     Train net output #0: loss = 0.890673 (* 1 = 0.890673 loss)
I0818 13:23:57.833148 20702 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0818 13:24:08.510478 20702 solver.cpp:228] Iteration 44900, loss = 0.943747
I0818 13:24:08.510679 20702 solver.cpp:244]     Train net output #0: loss = 0.969056 (* 1 = 0.969056 loss)
I0818 13:24:08.510710 20702 sgd_solver.cpp:106] Iteration 44900, lr = 0.001
I0818 13:24:19.188318 20702 solver.cpp:228] Iteration 45000, loss = 0.939282
I0818 13:24:19.188390 20702 solver.cpp:244]     Train net output #0: loss = 0.851256 (* 1 = 0.851256 loss)
I0818 13:24:19.188410 20702 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0818 13:24:29.868042 20702 solver.cpp:228] Iteration 45100, loss = 0.948122
I0818 13:24:29.868126 20702 solver.cpp:244]     Train net output #0: loss = 1.0442 (* 1 = 1.0442 loss)
I0818 13:24:29.868149 20702 sgd_solver.cpp:106] Iteration 45100, lr = 0.001
I0818 13:24:40.548177 20702 solver.cpp:228] Iteration 45200, loss = 0.941075
I0818 13:24:40.548341 20702 solver.cpp:244]     Train net output #0: loss = 0.791 (* 1 = 0.791 loss)
I0818 13:24:40.548363 20702 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0818 13:24:51.264806 20702 solver.cpp:228] Iteration 45300, loss = 0.925309
I0818 13:24:51.264885 20702 solver.cpp:244]     Train net output #0: loss = 0.863902 (* 1 = 0.863902 loss)
I0818 13:24:51.264907 20702 sgd_solver.cpp:106] Iteration 45300, lr = 0.001
I0818 13:25:01.966610 20702 solver.cpp:228] Iteration 45400, loss = 0.940986
I0818 13:25:01.966701 20702 solver.cpp:244]     Train net output #0: loss = 0.954727 (* 1 = 0.954727 loss)
I0818 13:25:01.966724 20702 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0818 13:25:12.674733 20702 solver.cpp:228] Iteration 45500, loss = 0.935917
I0818 13:25:12.674985 20702 solver.cpp:244]     Train net output #0: loss = 0.869966 (* 1 = 0.869966 loss)
I0818 13:25:12.675010 20702 sgd_solver.cpp:106] Iteration 45500, lr = 0.001
I0818 13:25:23.354702 20702 solver.cpp:228] Iteration 45600, loss = 0.940402
I0818 13:25:23.354775 20702 solver.cpp:244]     Train net output #0: loss = 1.00929 (* 1 = 1.00929 loss)
I0818 13:25:23.354796 20702 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0818 13:25:34.036545 20702 solver.cpp:228] Iteration 45700, loss = 0.939566
I0818 13:25:34.036636 20702 solver.cpp:244]     Train net output #0: loss = 0.807968 (* 1 = 0.807968 loss)
I0818 13:25:34.036660 20702 sgd_solver.cpp:106] Iteration 45700, lr = 0.001
I0818 13:25:44.715885 20702 solver.cpp:228] Iteration 45800, loss = 0.929464
I0818 13:25:44.716054 20702 solver.cpp:244]     Train net output #0: loss = 0.893011 (* 1 = 0.893011 loss)
I0818 13:25:44.716080 20702 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0818 13:25:55.396105 20702 solver.cpp:228] Iteration 45900, loss = 0.943105
I0818 13:25:55.396191 20702 solver.cpp:244]     Train net output #0: loss = 0.931172 (* 1 = 0.931172 loss)
I0818 13:25:55.396219 20702 sgd_solver.cpp:106] Iteration 45900, lr = 0.001
I0818 13:26:05.970855 20702 solver.cpp:337] Iteration 46000, Testing net (#0)
I0818 13:26:08.090327 20702 solver.cpp:404]     Test net output #0: loss = 1.21248 (* 1 = 1.21248 loss)
I0818 13:26:08.161170 20702 solver.cpp:228] Iteration 46000, loss = 0.934719
I0818 13:26:08.161209 20702 solver.cpp:244]     Train net output #0: loss = 0.897858 (* 1 = 0.897858 loss)
I0818 13:26:08.161240 20702 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0818 13:26:18.844311 20702 solver.cpp:228] Iteration 46100, loss = 0.934424
I0818 13:26:18.844529 20702 solver.cpp:244]     Train net output #0: loss = 0.973213 (* 1 = 0.973213 loss)
I0818 13:26:18.844566 20702 sgd_solver.cpp:106] Iteration 46100, lr = 0.001
I0818 13:26:29.581706 20702 solver.cpp:228] Iteration 46200, loss = 0.932746
I0818 13:26:29.581784 20702 solver.cpp:244]     Train net output #0: loss = 0.823095 (* 1 = 0.823095 loss)
I0818 13:26:29.581815 20702 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0818 13:26:40.263371 20702 solver.cpp:228] Iteration 46300, loss = 0.922968
I0818 13:26:40.263438 20702 solver.cpp:244]     Train net output #0: loss = 0.875882 (* 1 = 0.875882 loss)
I0818 13:26:40.263461 20702 sgd_solver.cpp:106] Iteration 46300, lr = 0.001
I0818 13:26:50.943066 20702 solver.cpp:228] Iteration 46400, loss = 0.929715
I0818 13:26:50.943281 20702 solver.cpp:244]     Train net output #0: loss = 0.94165 (* 1 = 0.94165 loss)
I0818 13:26:50.943320 20702 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0818 13:27:01.663377 20702 solver.cpp:228] Iteration 46500, loss = 0.924972
I0818 13:27:01.663451 20702 solver.cpp:244]     Train net output #0: loss = 0.874864 (* 1 = 0.874864 loss)
I0818 13:27:01.663480 20702 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0818 13:27:12.343503 20702 solver.cpp:228] Iteration 46600, loss = 0.930564
I0818 13:27:12.343582 20702 solver.cpp:244]     Train net output #0: loss = 1.05434 (* 1 = 1.05434 loss)
I0818 13:27:12.343605 20702 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0818 13:27:23.037636 20702 solver.cpp:228] Iteration 46700, loss = 0.934617
I0818 13:27:23.037791 20702 solver.cpp:244]     Train net output #0: loss = 0.779774 (* 1 = 0.779774 loss)
I0818 13:27:23.037816 20702 sgd_solver.cpp:106] Iteration 46700, lr = 0.001
I0818 13:27:33.718217 20702 solver.cpp:228] Iteration 46800, loss = 0.920874
I0818 13:27:33.718304 20702 solver.cpp:244]     Train net output #0: loss = 0.887875 (* 1 = 0.887875 loss)
I0818 13:27:33.718327 20702 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0818 13:27:44.395328 20702 solver.cpp:228] Iteration 46900, loss = 0.934825
I0818 13:27:44.395406 20702 solver.cpp:244]     Train net output #0: loss = 1.02328 (* 1 = 1.02328 loss)
I0818 13:27:44.395426 20702 sgd_solver.cpp:106] Iteration 46900, lr = 0.001
I0818 13:27:55.074693 20702 solver.cpp:228] Iteration 47000, loss = 0.924106
I0818 13:27:55.074946 20702 solver.cpp:244]     Train net output #0: loss = 0.897788 (* 1 = 0.897788 loss)
I0818 13:27:55.074978 20702 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0818 13:28:05.754182 20702 solver.cpp:228] Iteration 47100, loss = 0.933403
I0818 13:28:05.754269 20702 solver.cpp:244]     Train net output #0: loss = 1.03972 (* 1 = 1.03972 loss)
I0818 13:28:05.754290 20702 sgd_solver.cpp:106] Iteration 47100, lr = 0.001
I0818 13:28:16.431915 20702 solver.cpp:228] Iteration 47200, loss = 0.937374
I0818 13:28:16.431984 20702 solver.cpp:244]     Train net output #0: loss = 0.813612 (* 1 = 0.813612 loss)
I0818 13:28:16.432008 20702 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0818 13:28:27.109542 20702 solver.cpp:228] Iteration 47300, loss = 0.905986
I0818 13:28:27.109766 20702 solver.cpp:244]     Train net output #0: loss = 0.868779 (* 1 = 0.868779 loss)
I0818 13:28:27.109796 20702 sgd_solver.cpp:106] Iteration 47300, lr = 0.001
I0818 13:28:37.787916 20702 solver.cpp:228] Iteration 47400, loss = 0.936105
I0818 13:28:37.787986 20702 solver.cpp:244]     Train net output #0: loss = 0.962635 (* 1 = 0.962635 loss)
I0818 13:28:37.788009 20702 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0818 13:28:48.467016 20702 solver.cpp:228] Iteration 47500, loss = 0.929576
I0818 13:28:48.467082 20702 solver.cpp:244]     Train net output #0: loss = 0.899878 (* 1 = 0.899878 loss)
I0818 13:28:48.467109 20702 sgd_solver.cpp:106] Iteration 47500, lr = 0.001
I0818 13:28:59.144528 20702 solver.cpp:228] Iteration 47600, loss = 0.923451
I0818 13:28:59.144649 20702 solver.cpp:244]     Train net output #0: loss = 0.996324 (* 1 = 0.996324 loss)
I0818 13:28:59.144673 20702 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0818 13:29:09.822273 20702 solver.cpp:228] Iteration 47700, loss = 0.935526
I0818 13:29:09.822343 20702 solver.cpp:244]     Train net output #0: loss = 0.834246 (* 1 = 0.834246 loss)
I0818 13:29:09.822367 20702 sgd_solver.cpp:106] Iteration 47700, lr = 0.001
I0818 13:29:20.500715 20702 solver.cpp:228] Iteration 47800, loss = 0.901495
I0818 13:29:20.500792 20702 solver.cpp:244]     Train net output #0: loss = 0.830078 (* 1 = 0.830078 loss)
I0818 13:29:20.500814 20702 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0818 13:29:31.180765 20702 solver.cpp:228] Iteration 47900, loss = 0.924281
I0818 13:29:31.180940 20702 solver.cpp:244]     Train net output #0: loss = 0.983532 (* 1 = 0.983532 loss)
I0818 13:29:31.180963 20702 sgd_solver.cpp:106] Iteration 47900, lr = 0.001
I0818 13:29:41.751619 20702 solver.cpp:337] Iteration 48000, Testing net (#0)
I0818 13:29:43.869384 20702 solver.cpp:404]     Test net output #0: loss = 1.20446 (* 1 = 1.20446 loss)
I0818 13:29:43.940071 20702 solver.cpp:228] Iteration 48000, loss = 0.922925
I0818 13:29:43.940120 20702 solver.cpp:244]     Train net output #0: loss = 0.880605 (* 1 = 0.880605 loss)
I0818 13:29:43.940145 20702 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0818 13:29:54.619318 20702 solver.cpp:228] Iteration 48100, loss = 0.922054
I0818 13:29:54.619395 20702 solver.cpp:244]     Train net output #0: loss = 1.00538 (* 1 = 1.00538 loss)
I0818 13:29:54.619416 20702 sgd_solver.cpp:106] Iteration 48100, lr = 0.001
I0818 13:30:05.305806 20702 solver.cpp:228] Iteration 48200, loss = 0.92896
I0818 13:30:05.306033 20702 solver.cpp:244]     Train net output #0: loss = 0.820765 (* 1 = 0.820765 loss)
I0818 13:30:05.306068 20702 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0818 13:30:16.025012 20702 solver.cpp:228] Iteration 48300, loss = 0.899411
I0818 13:30:16.025081 20702 solver.cpp:244]     Train net output #0: loss = 0.842897 (* 1 = 0.842897 loss)
I0818 13:30:16.025104 20702 sgd_solver.cpp:106] Iteration 48300, lr = 0.001
I0818 13:30:26.703282 20702 solver.cpp:228] Iteration 48400, loss = 0.916334
I0818 13:30:26.703367 20702 solver.cpp:244]     Train net output #0: loss = 0.967259 (* 1 = 0.967259 loss)
I0818 13:30:26.703390 20702 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0818 13:30:37.380239 20702 solver.cpp:228] Iteration 48500, loss = 0.91494
I0818 13:30:37.380508 20702 solver.cpp:244]     Train net output #0: loss = 0.863906 (* 1 = 0.863906 loss)
I0818 13:30:37.380539 20702 sgd_solver.cpp:106] Iteration 48500, lr = 0.001
I0818 13:30:48.057097 20702 solver.cpp:228] Iteration 48600, loss = 0.914018
I0818 13:30:48.057174 20702 solver.cpp:244]     Train net output #0: loss = 0.98185 (* 1 = 0.98185 loss)
I0818 13:30:48.057200 20702 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0818 13:30:58.735520 20702 solver.cpp:228] Iteration 48700, loss = 0.921632
I0818 13:30:58.735601 20702 solver.cpp:244]     Train net output #0: loss = 0.798396 (* 1 = 0.798396 loss)
I0818 13:30:58.735623 20702 sgd_solver.cpp:106] Iteration 48700, lr = 0.001
I0818 13:31:09.413214 20702 solver.cpp:228] Iteration 48800, loss = 0.890869
I0818 13:31:09.413403 20702 solver.cpp:244]     Train net output #0: loss = 0.852068 (* 1 = 0.852068 loss)
I0818 13:31:09.413434 20702 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0818 13:31:20.128916 20702 solver.cpp:228] Iteration 48900, loss = 0.906868
I0818 13:31:20.128993 20702 solver.cpp:244]     Train net output #0: loss = 0.972166 (* 1 = 0.972166 loss)
I0818 13:31:20.129015 20702 sgd_solver.cpp:106] Iteration 48900, lr = 0.001
I0818 13:31:30.809823 20702 solver.cpp:228] Iteration 49000, loss = 0.902691
I0818 13:31:30.809906 20702 solver.cpp:244]     Train net output #0: loss = 0.835628 (* 1 = 0.835628 loss)
I0818 13:31:30.809929 20702 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0818 13:31:41.487534 20702 solver.cpp:228] Iteration 49100, loss = 0.901467
I0818 13:31:41.487748 20702 solver.cpp:244]     Train net output #0: loss = 0.991331 (* 1 = 0.991331 loss)
I0818 13:31:41.487777 20702 sgd_solver.cpp:106] Iteration 49100, lr = 0.001
I0818 13:31:52.166143 20702 solver.cpp:228] Iteration 49200, loss = 0.916751
I0818 13:31:52.166221 20702 solver.cpp:244]     Train net output #0: loss = 0.771945 (* 1 = 0.771945 loss)
I0818 13:31:52.166244 20702 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0818 13:32:02.845417 20702 solver.cpp:228] Iteration 49300, loss = 0.88365
I0818 13:32:02.845499 20702 solver.cpp:244]     Train net output #0: loss = 0.78265 (* 1 = 0.78265 loss)
I0818 13:32:02.845521 20702 sgd_solver.cpp:106] Iteration 49300, lr = 0.001
I0818 13:32:13.531431 20702 solver.cpp:228] Iteration 49400, loss = 0.897831
I0818 13:32:13.531600 20702 solver.cpp:244]     Train net output #0: loss = 0.955412 (* 1 = 0.955412 loss)
I0818 13:32:13.531625 20702 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0818 13:32:24.225649 20702 solver.cpp:228] Iteration 49500, loss = 0.903265
I0818 13:32:24.225718 20702 solver.cpp:244]     Train net output #0: loss = 0.830841 (* 1 = 0.830841 loss)
I0818 13:32:24.225739 20702 sgd_solver.cpp:106] Iteration 49500, lr = 0.001
I0818 13:32:34.913277 20702 solver.cpp:228] Iteration 49600, loss = 0.898655
I0818 13:32:34.913362 20702 solver.cpp:244]     Train net output #0: loss = 0.962534 (* 1 = 0.962534 loss)
I0818 13:32:34.913384 20702 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0818 13:32:45.592214 20702 solver.cpp:228] Iteration 49700, loss = 0.908271
I0818 13:32:45.592430 20702 solver.cpp:244]     Train net output #0: loss = 0.799073 (* 1 = 0.799073 loss)
I0818 13:32:45.592460 20702 sgd_solver.cpp:106] Iteration 49700, lr = 0.001
I0818 13:32:56.290289 20702 solver.cpp:228] Iteration 49800, loss = 0.881434
I0818 13:32:56.290375 20702 solver.cpp:244]     Train net output #0: loss = 0.797152 (* 1 = 0.797152 loss)
I0818 13:32:56.290398 20702 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0818 13:33:06.970124 20702 solver.cpp:228] Iteration 49900, loss = 0.896776
I0818 13:33:06.970201 20702 solver.cpp:244]     Train net output #0: loss = 0.916559 (* 1 = 0.916559 loss)
I0818 13:33:06.970223 20702 sgd_solver.cpp:106] Iteration 49900, lr = 0.001
I0818 13:33:17.543256 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_50000.caffemodel
I0818 13:33:17.591115 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_50000.solverstate
I0818 13:33:17.596427 20702 solver.cpp:337] Iteration 50000, Testing net (#0)
I0818 13:33:19.682481 20702 solver.cpp:404]     Test net output #0: loss = 1.19843 (* 1 = 1.19843 loss)
I0818 13:33:19.753387 20702 solver.cpp:228] Iteration 50000, loss = 0.895509
I0818 13:33:19.753434 20702 solver.cpp:244]     Train net output #0: loss = 0.841384 (* 1 = 0.841384 loss)
I0818 13:33:19.753458 20702 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0818 13:33:30.432106 20702 solver.cpp:228] Iteration 50100, loss = 0.89082
I0818 13:33:30.432190 20702 solver.cpp:244]     Train net output #0: loss = 0.935141 (* 1 = 0.935141 loss)
I0818 13:33:30.432212 20702 sgd_solver.cpp:106] Iteration 50100, lr = 0.001
I0818 13:33:41.111482 20702 solver.cpp:228] Iteration 50200, loss = 0.906487
I0818 13:33:41.111557 20702 solver.cpp:244]     Train net output #0: loss = 0.7797 (* 1 = 0.7797 loss)
I0818 13:33:41.111578 20702 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0818 13:33:51.791705 20702 solver.cpp:228] Iteration 50300, loss = 0.87455
I0818 13:33:51.791918 20702 solver.cpp:244]     Train net output #0: loss = 0.819808 (* 1 = 0.819808 loss)
I0818 13:33:51.791949 20702 sgd_solver.cpp:106] Iteration 50300, lr = 0.001
I0818 13:34:02.469234 20702 solver.cpp:228] Iteration 50400, loss = 0.890185
I0818 13:34:02.469321 20702 solver.cpp:244]     Train net output #0: loss = 0.91658 (* 1 = 0.91658 loss)
I0818 13:34:02.469343 20702 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0818 13:34:13.148723 20702 solver.cpp:228] Iteration 50500, loss = 0.891959
I0818 13:34:13.148800 20702 solver.cpp:244]     Train net output #0: loss = 0.819548 (* 1 = 0.819548 loss)
I0818 13:34:13.148821 20702 sgd_solver.cpp:106] Iteration 50500, lr = 0.001
I0818 13:34:23.828310 20702 solver.cpp:228] Iteration 50600, loss = 0.889301
I0818 13:34:23.828590 20702 solver.cpp:244]     Train net output #0: loss = 0.946204 (* 1 = 0.946204 loss)
I0818 13:34:23.828639 20702 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0818 13:34:34.526024 20702 solver.cpp:228] Iteration 50700, loss = 0.895905
I0818 13:34:34.526109 20702 solver.cpp:244]     Train net output #0: loss = 0.779902 (* 1 = 0.779902 loss)
I0818 13:34:34.526132 20702 sgd_solver.cpp:106] Iteration 50700, lr = 0.001
I0818 13:34:45.203094 20702 solver.cpp:228] Iteration 50800, loss = 0.871028
I0818 13:34:45.203168 20702 solver.cpp:244]     Train net output #0: loss = 0.830464 (* 1 = 0.830464 loss)
I0818 13:34:45.203191 20702 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0818 13:34:55.880879 20702 solver.cpp:228] Iteration 50900, loss = 0.887339
I0818 13:34:55.881005 20702 solver.cpp:244]     Train net output #0: loss = 0.929408 (* 1 = 0.929408 loss)
I0818 13:34:55.881031 20702 sgd_solver.cpp:106] Iteration 50900, lr = 0.001
I0818 13:35:06.572661 20702 solver.cpp:228] Iteration 51000, loss = 0.882413
I0818 13:35:06.572731 20702 solver.cpp:244]     Train net output #0: loss = 0.804595 (* 1 = 0.804595 loss)
I0818 13:35:06.572753 20702 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0818 13:35:17.258083 20702 solver.cpp:228] Iteration 51100, loss = 0.884399
I0818 13:35:17.258163 20702 solver.cpp:244]     Train net output #0: loss = 0.93394 (* 1 = 0.93394 loss)
I0818 13:35:17.258186 20702 sgd_solver.cpp:106] Iteration 51100, lr = 0.001
I0818 13:35:27.936411 20702 solver.cpp:228] Iteration 51200, loss = 0.891785
I0818 13:35:27.936609 20702 solver.cpp:244]     Train net output #0: loss = 0.77109 (* 1 = 0.77109 loss)
I0818 13:35:27.936632 20702 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0818 13:35:38.613090 20702 solver.cpp:228] Iteration 51300, loss = 0.865069
I0818 13:35:38.613163 20702 solver.cpp:244]     Train net output #0: loss = 0.815367 (* 1 = 0.815367 loss)
I0818 13:35:38.613186 20702 sgd_solver.cpp:106] Iteration 51300, lr = 0.001
I0818 13:35:49.290225 20702 solver.cpp:228] Iteration 51400, loss = 0.881642
I0818 13:35:49.290300 20702 solver.cpp:244]     Train net output #0: loss = 0.908276 (* 1 = 0.908276 loss)
I0818 13:35:49.290321 20702 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0818 13:35:59.965051 20702 solver.cpp:228] Iteration 51500, loss = 0.885633
I0818 13:35:59.965340 20702 solver.cpp:244]     Train net output #0: loss = 0.809303 (* 1 = 0.809303 loss)
I0818 13:35:59.965371 20702 sgd_solver.cpp:106] Iteration 51500, lr = 0.001
I0818 13:36:10.672857 20702 solver.cpp:228] Iteration 51600, loss = 0.87289
I0818 13:36:10.672935 20702 solver.cpp:244]     Train net output #0: loss = 0.968159 (* 1 = 0.968159 loss)
I0818 13:36:10.672956 20702 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0818 13:36:21.349354 20702 solver.cpp:228] Iteration 51700, loss = 0.897463
I0818 13:36:21.349432 20702 solver.cpp:244]     Train net output #0: loss = 0.773547 (* 1 = 0.773547 loss)
I0818 13:36:21.349458 20702 sgd_solver.cpp:106] Iteration 51700, lr = 0.001
I0818 13:36:32.027144 20702 solver.cpp:228] Iteration 51800, loss = 0.863245
I0818 13:36:32.027370 20702 solver.cpp:244]     Train net output #0: loss = 0.824666 (* 1 = 0.824666 loss)
I0818 13:36:32.027401 20702 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0818 13:36:42.704347 20702 solver.cpp:228] Iteration 51900, loss = 0.880581
I0818 13:36:42.704423 20702 solver.cpp:244]     Train net output #0: loss = 0.91118 (* 1 = 0.91118 loss)
I0818 13:36:42.704447 20702 sgd_solver.cpp:106] Iteration 51900, lr = 0.001
I0818 13:36:53.275632 20702 solver.cpp:337] Iteration 52000, Testing net (#0)
I0818 13:36:55.397133 20702 solver.cpp:404]     Test net output #0: loss = 1.19532 (* 1 = 1.19532 loss)
I0818 13:36:55.468075 20702 solver.cpp:228] Iteration 52000, loss = 0.885779
I0818 13:36:55.468124 20702 solver.cpp:244]     Train net output #0: loss = 0.786562 (* 1 = 0.786562 loss)
I0818 13:36:55.468150 20702 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0818 13:37:06.146633 20702 solver.cpp:228] Iteration 52100, loss = 0.874564
I0818 13:37:06.146872 20702 solver.cpp:244]     Train net output #0: loss = 0.922335 (* 1 = 0.922335 loss)
I0818 13:37:06.146908 20702 sgd_solver.cpp:106] Iteration 52100, lr = 0.001
I0818 13:37:16.859318 20702 solver.cpp:228] Iteration 52200, loss = 0.893926
I0818 13:37:16.859402 20702 solver.cpp:244]     Train net output #0: loss = 0.74865 (* 1 = 0.74865 loss)
I0818 13:37:16.859424 20702 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0818 13:37:27.548209 20702 solver.cpp:228] Iteration 52300, loss = 0.865414
I0818 13:37:27.548297 20702 solver.cpp:244]     Train net output #0: loss = 0.824852 (* 1 = 0.824852 loss)
I0818 13:37:27.548319 20702 sgd_solver.cpp:106] Iteration 52300, lr = 0.001
I0818 13:37:38.225479 20702 solver.cpp:228] Iteration 52400, loss = 0.874649
I0818 13:37:38.225656 20702 solver.cpp:244]     Train net output #0: loss = 0.848919 (* 1 = 0.848919 loss)
I0818 13:37:38.225687 20702 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0818 13:37:48.904626 20702 solver.cpp:228] Iteration 52500, loss = 0.882746
I0818 13:37:48.904706 20702 solver.cpp:244]     Train net output #0: loss = 0.800517 (* 1 = 0.800517 loss)
I0818 13:37:48.904727 20702 sgd_solver.cpp:106] Iteration 52500, lr = 0.001
I0818 13:37:59.581856 20702 solver.cpp:228] Iteration 52600, loss = 0.87091
I0818 13:37:59.581933 20702 solver.cpp:244]     Train net output #0: loss = 0.943375 (* 1 = 0.943375 loss)
I0818 13:37:59.581956 20702 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0818 13:38:10.259999 20702 solver.cpp:228] Iteration 52700, loss = 0.887568
I0818 13:38:10.260228 20702 solver.cpp:244]     Train net output #0: loss = 0.74826 (* 1 = 0.74826 loss)
I0818 13:38:10.260262 20702 sgd_solver.cpp:106] Iteration 52700, lr = 0.001
I0818 13:38:20.960870 20702 solver.cpp:228] Iteration 52800, loss = 0.857771
I0818 13:38:20.960947 20702 solver.cpp:244]     Train net output #0: loss = 0.834174 (* 1 = 0.834174 loss)
I0818 13:38:20.960968 20702 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0818 13:38:31.638221 20702 solver.cpp:228] Iteration 52900, loss = 0.869492
I0818 13:38:31.638301 20702 solver.cpp:244]     Train net output #0: loss = 0.870711 (* 1 = 0.870711 loss)
I0818 13:38:31.638322 20702 sgd_solver.cpp:106] Iteration 52900, lr = 0.001
I0818 13:38:42.317292 20702 solver.cpp:228] Iteration 53000, loss = 0.864817
I0818 13:38:42.317579 20702 solver.cpp:244]     Train net output #0: loss = 0.785017 (* 1 = 0.785017 loss)
I0818 13:38:42.317613 20702 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0818 13:38:53.016083 20702 solver.cpp:228] Iteration 53100, loss = 0.862931
I0818 13:38:53.016150 20702 solver.cpp:244]     Train net output #0: loss = 0.865009 (* 1 = 0.865009 loss)
I0818 13:38:53.016178 20702 sgd_solver.cpp:106] Iteration 53100, lr = 0.001
I0818 13:39:03.701694 20702 solver.cpp:228] Iteration 53200, loss = 0.873488
I0818 13:39:03.701778 20702 solver.cpp:244]     Train net output #0: loss = 0.753132 (* 1 = 0.753132 loss)
I0818 13:39:03.701802 20702 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0818 13:39:14.382216 20702 solver.cpp:228] Iteration 53300, loss = 0.851326
I0818 13:39:14.382447 20702 solver.cpp:244]     Train net output #0: loss = 0.83498 (* 1 = 0.83498 loss)
I0818 13:39:14.382478 20702 sgd_solver.cpp:106] Iteration 53300, lr = 0.001
I0818 13:39:25.084898 20702 solver.cpp:228] Iteration 53400, loss = 0.860363
I0818 13:39:25.084978 20702 solver.cpp:244]     Train net output #0: loss = 0.867918 (* 1 = 0.867918 loss)
I0818 13:39:25.085005 20702 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0818 13:39:35.762969 20702 solver.cpp:228] Iteration 53500, loss = 0.866787
I0818 13:39:35.763053 20702 solver.cpp:244]     Train net output #0: loss = 0.802114 (* 1 = 0.802114 loss)
I0818 13:39:35.763077 20702 sgd_solver.cpp:106] Iteration 53500, lr = 0.001
I0818 13:39:46.439402 20702 solver.cpp:228] Iteration 53600, loss = 0.857835
I0818 13:39:46.439574 20702 solver.cpp:244]     Train net output #0: loss = 0.904227 (* 1 = 0.904227 loss)
I0818 13:39:46.439599 20702 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0818 13:39:57.118383 20702 solver.cpp:228] Iteration 53700, loss = 0.864666
I0818 13:39:57.118469 20702 solver.cpp:244]     Train net output #0: loss = 0.737989 (* 1 = 0.737989 loss)
I0818 13:39:57.118491 20702 sgd_solver.cpp:106] Iteration 53700, lr = 0.001
I0818 13:40:07.809512 20702 solver.cpp:228] Iteration 53800, loss = 0.840637
I0818 13:40:07.809590 20702 solver.cpp:244]     Train net output #0: loss = 0.811705 (* 1 = 0.811705 loss)
I0818 13:40:07.809613 20702 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
I0818 13:40:18.490092 20702 solver.cpp:228] Iteration 53900, loss = 0.854931
I0818 13:40:18.490311 20702 solver.cpp:244]     Train net output #0: loss = 0.897766 (* 1 = 0.897766 loss)
I0818 13:40:18.490345 20702 sgd_solver.cpp:106] Iteration 53900, lr = 0.001
I0818 13:40:29.062319 20702 solver.cpp:337] Iteration 54000, Testing net (#0)
I0818 13:40:31.183965 20702 solver.cpp:404]     Test net output #0: loss = 1.19902 (* 1 = 1.19902 loss)
I0818 13:40:31.254734 20702 solver.cpp:228] Iteration 54000, loss = 0.861003
I0818 13:40:31.254776 20702 solver.cpp:244]     Train net output #0: loss = 0.760966 (* 1 = 0.760966 loss)
I0818 13:40:31.254802 20702 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0818 13:40:41.933862 20702 solver.cpp:228] Iteration 54100, loss = 0.85327
I0818 13:40:41.933943 20702 solver.cpp:244]     Train net output #0: loss = 0.928548 (* 1 = 0.928548 loss)
I0818 13:40:41.933964 20702 sgd_solver.cpp:106] Iteration 54100, lr = 0.001
I0818 13:40:52.610899 20702 solver.cpp:228] Iteration 54200, loss = 0.868602
I0818 13:40:52.611060 20702 solver.cpp:244]     Train net output #0: loss = 0.720189 (* 1 = 0.720189 loss)
I0818 13:40:52.611086 20702 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0818 13:41:03.288018 20702 solver.cpp:228] Iteration 54300, loss = 0.834042
I0818 13:41:03.288102 20702 solver.cpp:244]     Train net output #0: loss = 0.776971 (* 1 = 0.776971 loss)
I0818 13:41:03.288125 20702 sgd_solver.cpp:106] Iteration 54300, lr = 0.001
I0818 13:41:13.965090 20702 solver.cpp:228] Iteration 54400, loss = 0.848114
I0818 13:41:13.965164 20702 solver.cpp:244]     Train net output #0: loss = 0.850622 (* 1 = 0.850622 loss)
I0818 13:41:13.965184 20702 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0818 13:41:24.640733 20702 solver.cpp:228] Iteration 54500, loss = 0.85362
I0818 13:41:24.640986 20702 solver.cpp:244]     Train net output #0: loss = 0.759372 (* 1 = 0.759372 loss)
I0818 13:41:24.641017 20702 sgd_solver.cpp:106] Iteration 54500, lr = 0.001
I0818 13:41:35.318051 20702 solver.cpp:228] Iteration 54600, loss = 0.843026
I0818 13:41:35.318140 20702 solver.cpp:244]     Train net output #0: loss = 0.941357 (* 1 = 0.941357 loss)
I0818 13:41:35.318166 20702 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0818 13:41:45.996667 20702 solver.cpp:228] Iteration 54700, loss = 0.859951
I0818 13:41:45.996745 20702 solver.cpp:244]     Train net output #0: loss = 0.756506 (* 1 = 0.756506 loss)
I0818 13:41:45.996767 20702 sgd_solver.cpp:106] Iteration 54700, lr = 0.001
I0818 13:41:56.672742 20702 solver.cpp:228] Iteration 54800, loss = 0.825881
I0818 13:41:56.672989 20702 solver.cpp:244]     Train net output #0: loss = 0.761255 (* 1 = 0.761255 loss)
I0818 13:41:56.673020 20702 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0818 13:42:07.350497 20702 solver.cpp:228] Iteration 54900, loss = 0.845171
I0818 13:42:07.350572 20702 solver.cpp:244]     Train net output #0: loss = 0.888536 (* 1 = 0.888536 loss)
I0818 13:42:07.350595 20702 sgd_solver.cpp:106] Iteration 54900, lr = 0.001
I0818 13:42:18.038417 20702 solver.cpp:228] Iteration 55000, loss = 0.848132
I0818 13:42:18.038493 20702 solver.cpp:244]     Train net output #0: loss = 0.772835 (* 1 = 0.772835 loss)
I0818 13:42:18.038516 20702 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0818 13:42:28.724843 20702 solver.cpp:228] Iteration 55100, loss = 0.837736
I0818 13:42:28.725037 20702 solver.cpp:244]     Train net output #0: loss = 0.918231 (* 1 = 0.918231 loss)
I0818 13:42:28.725067 20702 sgd_solver.cpp:106] Iteration 55100, lr = 0.001
I0818 13:42:39.424144 20702 solver.cpp:228] Iteration 55200, loss = 0.852267
I0818 13:42:39.424222 20702 solver.cpp:244]     Train net output #0: loss = 0.680177 (* 1 = 0.680177 loss)
I0818 13:42:39.424244 20702 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0818 13:42:50.103050 20702 solver.cpp:228] Iteration 55300, loss = 0.824236
I0818 13:42:50.103121 20702 solver.cpp:244]     Train net output #0: loss = 0.80847 (* 1 = 0.80847 loss)
I0818 13:42:50.103142 20702 sgd_solver.cpp:106] Iteration 55300, lr = 0.001
I0818 13:43:00.781674 20702 solver.cpp:228] Iteration 55400, loss = 0.837437
I0818 13:43:00.781864 20702 solver.cpp:244]     Train net output #0: loss = 0.821299 (* 1 = 0.821299 loss)
I0818 13:43:00.781888 20702 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0818 13:43:11.461647 20702 solver.cpp:228] Iteration 55500, loss = 0.842112
I0818 13:43:11.461720 20702 solver.cpp:244]     Train net output #0: loss = 0.767534 (* 1 = 0.767534 loss)
I0818 13:43:11.461742 20702 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0818 13:43:22.141283 20702 solver.cpp:228] Iteration 55600, loss = 0.831974
I0818 13:43:22.141357 20702 solver.cpp:244]     Train net output #0: loss = 0.919862 (* 1 = 0.919862 loss)
I0818 13:43:22.141378 20702 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0818 13:43:32.820263 20702 solver.cpp:228] Iteration 55700, loss = 0.847416
I0818 13:43:32.820399 20702 solver.cpp:244]     Train net output #0: loss = 0.761436 (* 1 = 0.761436 loss)
I0818 13:43:32.820425 20702 sgd_solver.cpp:106] Iteration 55700, lr = 0.001
I0818 13:43:43.499435 20702 solver.cpp:228] Iteration 55800, loss = 0.816796
I0818 13:43:43.499512 20702 solver.cpp:244]     Train net output #0: loss = 0.756915 (* 1 = 0.756915 loss)
I0818 13:43:43.499534 20702 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0818 13:43:54.176846 20702 solver.cpp:228] Iteration 55900, loss = 0.836155
I0818 13:43:54.176919 20702 solver.cpp:244]     Train net output #0: loss = 0.834775 (* 1 = 0.834775 loss)
I0818 13:43:54.176940 20702 sgd_solver.cpp:106] Iteration 55900, lr = 0.001
I0818 13:44:04.751149 20702 solver.cpp:337] Iteration 56000, Testing net (#0)
I0818 13:44:06.873867 20702 solver.cpp:404]     Test net output #0: loss = 1.21812 (* 1 = 1.21812 loss)
I0818 13:44:06.944614 20702 solver.cpp:228] Iteration 56000, loss = 0.835853
I0818 13:44:06.944664 20702 solver.cpp:244]     Train net output #0: loss = 0.754547 (* 1 = 0.754547 loss)
I0818 13:44:06.944687 20702 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0818 13:44:17.624229 20702 solver.cpp:228] Iteration 56100, loss = 0.82765
I0818 13:44:17.624302 20702 solver.cpp:244]     Train net output #0: loss = 0.893031 (* 1 = 0.893031 loss)
I0818 13:44:17.624325 20702 sgd_solver.cpp:106] Iteration 56100, lr = 0.001
I0818 13:44:28.328157 20702 solver.cpp:228] Iteration 56200, loss = 0.841256
I0818 13:44:28.328238 20702 solver.cpp:244]     Train net output #0: loss = 0.714432 (* 1 = 0.714432 loss)
I0818 13:44:28.328259 20702 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0818 13:44:39.015714 20702 solver.cpp:228] Iteration 56300, loss = 0.81661
I0818 13:44:39.015923 20702 solver.cpp:244]     Train net output #0: loss = 0.771306 (* 1 = 0.771306 loss)
I0818 13:44:39.015946 20702 sgd_solver.cpp:106] Iteration 56300, lr = 0.001
I0818 13:44:49.701995 20702 solver.cpp:228] Iteration 56400, loss = 0.833665
I0818 13:44:49.702076 20702 solver.cpp:244]     Train net output #0: loss = 0.836292 (* 1 = 0.836292 loss)
I0818 13:44:49.702100 20702 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0818 13:45:00.381774 20702 solver.cpp:228] Iteration 56500, loss = 0.835418
I0818 13:45:00.381865 20702 solver.cpp:244]     Train net output #0: loss = 0.748881 (* 1 = 0.748881 loss)
I0818 13:45:00.381889 20702 sgd_solver.cpp:106] Iteration 56500, lr = 0.001
I0818 13:45:11.093695 20702 solver.cpp:228] Iteration 56600, loss = 0.824797
I0818 13:45:11.093852 20702 solver.cpp:244]     Train net output #0: loss = 0.925409 (* 1 = 0.925409 loss)
I0818 13:45:11.093876 20702 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0818 13:45:21.785629 20702 solver.cpp:228] Iteration 56700, loss = 0.832831
I0818 13:45:21.785709 20702 solver.cpp:244]     Train net output #0: loss = 0.710401 (* 1 = 0.710401 loss)
I0818 13:45:21.785732 20702 sgd_solver.cpp:106] Iteration 56700, lr = 0.001
I0818 13:45:32.479964 20702 solver.cpp:228] Iteration 56800, loss = 0.80628
I0818 13:45:32.480057 20702 solver.cpp:244]     Train net output #0: loss = 0.757042 (* 1 = 0.757042 loss)
I0818 13:45:32.480082 20702 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0818 13:45:43.173267 20702 solver.cpp:228] Iteration 56900, loss = 0.821074
I0818 13:45:43.173490 20702 solver.cpp:244]     Train net output #0: loss = 0.858674 (* 1 = 0.858674 loss)
I0818 13:45:43.173513 20702 sgd_solver.cpp:106] Iteration 56900, lr = 0.001
I0818 13:45:53.854967 20702 solver.cpp:228] Iteration 57000, loss = 0.825905
I0818 13:45:53.855039 20702 solver.cpp:244]     Train net output #0: loss = 0.733982 (* 1 = 0.733982 loss)
I0818 13:45:53.855060 20702 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0818 13:46:04.670622 20702 solver.cpp:228] Iteration 57100, loss = 0.813612
I0818 13:46:04.670733 20702 solver.cpp:244]     Train net output #0: loss = 0.882106 (* 1 = 0.882106 loss)
I0818 13:46:04.670769 20702 sgd_solver.cpp:106] Iteration 57100, lr = 0.001
I0818 13:46:15.632146 20702 solver.cpp:228] Iteration 57200, loss = 0.82851
I0818 13:46:15.632390 20702 solver.cpp:244]     Train net output #0: loss = 0.715645 (* 1 = 0.715645 loss)
I0818 13:46:15.632431 20702 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0818 13:46:26.648999 20702 solver.cpp:228] Iteration 57300, loss = 0.804998
I0818 13:46:26.649104 20702 solver.cpp:244]     Train net output #0: loss = 0.745054 (* 1 = 0.745054 loss)
I0818 13:46:26.649144 20702 sgd_solver.cpp:106] Iteration 57300, lr = 0.001
I0818 13:46:37.666471 20702 solver.cpp:228] Iteration 57400, loss = 0.822616
I0818 13:46:37.666565 20702 solver.cpp:244]     Train net output #0: loss = 0.855231 (* 1 = 0.855231 loss)
I0818 13:46:37.666597 20702 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0818 13:46:48.686519 20702 solver.cpp:228] Iteration 57500, loss = 0.81781
I0818 13:46:48.686766 20702 solver.cpp:244]     Train net output #0: loss = 0.724932 (* 1 = 0.724932 loss)
I0818 13:46:48.686803 20702 sgd_solver.cpp:106] Iteration 57500, lr = 0.001
I0818 13:46:59.379046 20702 solver.cpp:228] Iteration 57600, loss = 0.813988
I0818 13:46:59.379127 20702 solver.cpp:244]     Train net output #0: loss = 0.874174 (* 1 = 0.874174 loss)
I0818 13:46:59.379148 20702 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0818 13:47:10.159971 20702 solver.cpp:228] Iteration 57700, loss = 0.824761
I0818 13:47:10.160064 20702 solver.cpp:244]     Train net output #0: loss = 0.677772 (* 1 = 0.677772 loss)
I0818 13:47:10.160097 20702 sgd_solver.cpp:106] Iteration 57700, lr = 0.001
I0818 13:47:21.178360 20702 solver.cpp:228] Iteration 57800, loss = 0.798744
I0818 13:47:21.178568 20702 solver.cpp:244]     Train net output #0: loss = 0.747585 (* 1 = 0.747585 loss)
I0818 13:47:21.178603 20702 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0818 13:47:32.109581 20702 solver.cpp:228] Iteration 57900, loss = 0.811846
I0818 13:47:32.109684 20702 solver.cpp:244]     Train net output #0: loss = 0.806287 (* 1 = 0.806287 loss)
I0818 13:47:32.109724 20702 sgd_solver.cpp:106] Iteration 57900, lr = 0.001
I0818 13:47:43.016454 20702 solver.cpp:337] Iteration 58000, Testing net (#0)
I0818 13:47:45.230690 20702 solver.cpp:404]     Test net output #0: loss = 1.24487 (* 1 = 1.24487 loss)
I0818 13:47:45.313004 20702 solver.cpp:228] Iteration 58000, loss = 0.821769
I0818 13:47:45.313068 20702 solver.cpp:244]     Train net output #0: loss = 0.729482 (* 1 = 0.729482 loss)
I0818 13:47:45.313104 20702 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0818 13:47:56.324380 20702 solver.cpp:228] Iteration 58100, loss = 0.804759
I0818 13:47:56.324595 20702 solver.cpp:244]     Train net output #0: loss = 0.889718 (* 1 = 0.889718 loss)
I0818 13:47:56.324642 20702 sgd_solver.cpp:106] Iteration 58100, lr = 0.001
I0818 13:48:07.164714 20702 solver.cpp:228] Iteration 58200, loss = 0.819431
I0818 13:48:07.164793 20702 solver.cpp:244]     Train net output #0: loss = 0.689703 (* 1 = 0.689703 loss)
I0818 13:48:07.164814 20702 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0818 13:48:17.850237 20702 solver.cpp:228] Iteration 58300, loss = 0.796282
I0818 13:48:17.850320 20702 solver.cpp:244]     Train net output #0: loss = 0.741707 (* 1 = 0.741707 loss)
I0818 13:48:17.850342 20702 sgd_solver.cpp:106] Iteration 58300, lr = 0.001
I0818 13:48:28.540017 20702 solver.cpp:228] Iteration 58400, loss = 0.81021
I0818 13:48:28.540177 20702 solver.cpp:244]     Train net output #0: loss = 0.847997 (* 1 = 0.847997 loss)
I0818 13:48:28.540200 20702 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0818 13:48:39.222513 20702 solver.cpp:228] Iteration 58500, loss = 0.810826
I0818 13:48:39.222582 20702 solver.cpp:244]     Train net output #0: loss = 0.748769 (* 1 = 0.748769 loss)
I0818 13:48:39.222604 20702 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0818 13:48:49.906005 20702 solver.cpp:228] Iteration 58600, loss = 0.80468
I0818 13:48:49.906077 20702 solver.cpp:244]     Train net output #0: loss = 0.905588 (* 1 = 0.905588 loss)
I0818 13:48:49.906100 20702 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0818 13:49:00.612706 20702 solver.cpp:228] Iteration 58700, loss = 0.81572
I0818 13:49:00.612882 20702 solver.cpp:244]     Train net output #0: loss = 0.681944 (* 1 = 0.681944 loss)
I0818 13:49:00.612907 20702 sgd_solver.cpp:106] Iteration 58700, lr = 0.001
I0818 13:49:11.293265 20702 solver.cpp:228] Iteration 58800, loss = 0.795128
I0818 13:49:11.293344 20702 solver.cpp:244]     Train net output #0: loss = 0.737391 (* 1 = 0.737391 loss)
I0818 13:49:11.293365 20702 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0818 13:49:21.978541 20702 solver.cpp:228] Iteration 58900, loss = 0.805071
I0818 13:49:21.978613 20702 solver.cpp:244]     Train net output #0: loss = 0.766957 (* 1 = 0.766957 loss)
I0818 13:49:21.978636 20702 sgd_solver.cpp:106] Iteration 58900, lr = 0.001
I0818 13:49:32.668936 20702 solver.cpp:228] Iteration 59000, loss = 0.812
I0818 13:49:32.669201 20702 solver.cpp:244]     Train net output #0: loss = 0.782306 (* 1 = 0.782306 loss)
I0818 13:49:32.669226 20702 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0818 13:49:43.355052 20702 solver.cpp:228] Iteration 59100, loss = 0.805566
I0818 13:49:43.355129 20702 solver.cpp:244]     Train net output #0: loss = 0.84512 (* 1 = 0.84512 loss)
I0818 13:49:43.355152 20702 sgd_solver.cpp:106] Iteration 59100, lr = 0.001
I0818 13:49:54.040225 20702 solver.cpp:228] Iteration 59200, loss = 0.809741
I0818 13:49:54.040297 20702 solver.cpp:244]     Train net output #0: loss = 0.690989 (* 1 = 0.690989 loss)
I0818 13:49:54.040319 20702 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0818 13:50:04.740658 20702 solver.cpp:228] Iteration 59300, loss = 0.787238
I0818 13:50:04.740888 20702 solver.cpp:244]     Train net output #0: loss = 0.691155 (* 1 = 0.691155 loss)
I0818 13:50:04.740919 20702 sgd_solver.cpp:106] Iteration 59300, lr = 0.001
I0818 13:50:15.408962 20702 solver.cpp:228] Iteration 59400, loss = 0.803741
I0818 13:50:15.409049 20702 solver.cpp:244]     Train net output #0: loss = 0.815256 (* 1 = 0.815256 loss)
I0818 13:50:15.409070 20702 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0818 13:50:26.099475 20702 solver.cpp:228] Iteration 59500, loss = 0.808885
I0818 13:50:26.099560 20702 solver.cpp:244]     Train net output #0: loss = 0.724883 (* 1 = 0.724883 loss)
I0818 13:50:26.099583 20702 sgd_solver.cpp:106] Iteration 59500, lr = 0.001
I0818 13:50:36.784504 20702 solver.cpp:228] Iteration 59600, loss = 0.792696
I0818 13:50:36.784670 20702 solver.cpp:244]     Train net output #0: loss = 0.920787 (* 1 = 0.920787 loss)
I0818 13:50:36.784693 20702 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0818 13:50:47.469563 20702 solver.cpp:228] Iteration 59700, loss = 0.810683
I0818 13:50:47.469638 20702 solver.cpp:244]     Train net output #0: loss = 0.740243 (* 1 = 0.740243 loss)
I0818 13:50:47.469660 20702 sgd_solver.cpp:106] Iteration 59700, lr = 0.001
I0818 13:50:58.150272 20702 solver.cpp:228] Iteration 59800, loss = 0.792014
I0818 13:50:58.150348 20702 solver.cpp:244]     Train net output #0: loss = 0.691756 (* 1 = 0.691756 loss)
I0818 13:50:58.150372 20702 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0818 13:51:08.830194 20702 solver.cpp:228] Iteration 59900, loss = 0.803234
I0818 13:51:08.830363 20702 solver.cpp:244]     Train net output #0: loss = 0.81265 (* 1 = 0.81265 loss)
I0818 13:51:08.830386 20702 sgd_solver.cpp:106] Iteration 59900, lr = 0.001
I0818 13:51:19.404798 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_60000.caffemodel
I0818 13:51:19.452993 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_60000.solverstate
I0818 13:51:19.458519 20702 solver.cpp:337] Iteration 60000, Testing net (#0)
I0818 13:51:21.546144 20702 solver.cpp:404]     Test net output #0: loss = 1.23012 (* 1 = 1.23012 loss)
I0818 13:51:21.616796 20702 solver.cpp:228] Iteration 60000, loss = 0.806926
I0818 13:51:21.616837 20702 solver.cpp:244]     Train net output #0: loss = 0.761237 (* 1 = 0.761237 loss)
I0818 13:51:21.616858 20702 sgd_solver.cpp:46] MultiStep Status: Iteration 60000, step = 1
I0818 13:51:21.616873 20702 sgd_solver.cpp:106] Iteration 60000, lr = 0.0001
I0818 13:51:32.307548 20702 solver.cpp:228] Iteration 60100, loss = 0.813062
I0818 13:51:32.307623 20702 solver.cpp:244]     Train net output #0: loss = 0.807532 (* 1 = 0.807532 loss)
I0818 13:51:32.307647 20702 sgd_solver.cpp:106] Iteration 60100, lr = 0.0001
I0818 13:51:42.991394 20702 solver.cpp:228] Iteration 60200, loss = 0.754146
I0818 13:51:42.991569 20702 solver.cpp:244]     Train net output #0: loss = 0.689374 (* 1 = 0.689374 loss)
I0818 13:51:42.991593 20702 sgd_solver.cpp:106] Iteration 60200, lr = 0.0001
I0818 13:51:53.679322 20702 solver.cpp:228] Iteration 60300, loss = 0.730461
I0818 13:51:53.679420 20702 solver.cpp:244]     Train net output #0: loss = 0.61893 (* 1 = 0.61893 loss)
I0818 13:51:53.679445 20702 sgd_solver.cpp:106] Iteration 60300, lr = 0.0001
I0818 13:52:04.392727 20702 solver.cpp:228] Iteration 60400, loss = 0.748016
I0818 13:52:04.392812 20702 solver.cpp:244]     Train net output #0: loss = 0.753358 (* 1 = 0.753358 loss)
I0818 13:52:04.392835 20702 sgd_solver.cpp:106] Iteration 60400, lr = 0.0001
I0818 13:52:15.082201 20702 solver.cpp:228] Iteration 60500, loss = 0.728983
I0818 13:52:15.082411 20702 solver.cpp:244]     Train net output #0: loss = 0.683906 (* 1 = 0.683906 loss)
I0818 13:52:15.082437 20702 sgd_solver.cpp:106] Iteration 60500, lr = 0.0001
I0818 13:52:25.768373 20702 solver.cpp:228] Iteration 60600, loss = 0.746732
I0818 13:52:25.768450 20702 solver.cpp:244]     Train net output #0: loss = 0.799439 (* 1 = 0.799439 loss)
I0818 13:52:25.768471 20702 sgd_solver.cpp:106] Iteration 60600, lr = 0.0001
I0818 13:52:36.451845 20702 solver.cpp:228] Iteration 60700, loss = 0.736889
I0818 13:52:36.451922 20702 solver.cpp:244]     Train net output #0: loss = 0.659147 (* 1 = 0.659147 loss)
I0818 13:52:36.451946 20702 sgd_solver.cpp:106] Iteration 60700, lr = 0.0001
I0818 13:52:47.135243 20702 solver.cpp:228] Iteration 60800, loss = 0.717397
I0818 13:52:47.135416 20702 solver.cpp:244]     Train net output #0: loss = 0.633518 (* 1 = 0.633518 loss)
I0818 13:52:47.135444 20702 sgd_solver.cpp:106] Iteration 60800, lr = 0.0001
I0818 13:52:57.815551 20702 solver.cpp:228] Iteration 60900, loss = 0.737118
I0818 13:52:57.815623 20702 solver.cpp:244]     Train net output #0: loss = 0.732778 (* 1 = 0.732778 loss)
I0818 13:52:57.815644 20702 sgd_solver.cpp:106] Iteration 60900, lr = 0.0001
I0818 13:53:08.494817 20702 solver.cpp:228] Iteration 61000, loss = 0.721785
I0818 13:53:08.494892 20702 solver.cpp:244]     Train net output #0: loss = 0.677107 (* 1 = 0.677107 loss)
I0818 13:53:08.494915 20702 sgd_solver.cpp:106] Iteration 61000, lr = 0.0001
I0818 13:53:19.174866 20702 solver.cpp:228] Iteration 61100, loss = 0.737013
I0818 13:53:19.175035 20702 solver.cpp:244]     Train net output #0: loss = 0.777632 (* 1 = 0.777632 loss)
I0818 13:53:19.175060 20702 sgd_solver.cpp:106] Iteration 61100, lr = 0.0001
I0818 13:53:29.863301 20702 solver.cpp:228] Iteration 61200, loss = 0.730641
I0818 13:53:29.863382 20702 solver.cpp:244]     Train net output #0: loss = 0.633435 (* 1 = 0.633435 loss)
I0818 13:53:29.863404 20702 sgd_solver.cpp:106] Iteration 61200, lr = 0.0001
I0818 13:53:40.638739 20702 solver.cpp:228] Iteration 61300, loss = 0.712469
I0818 13:53:40.638811 20702 solver.cpp:244]     Train net output #0: loss = 0.632613 (* 1 = 0.632613 loss)
I0818 13:53:40.638839 20702 sgd_solver.cpp:106] Iteration 61300, lr = 0.0001
I0818 13:53:51.348702 20702 solver.cpp:228] Iteration 61400, loss = 0.731404
I0818 13:53:51.348927 20702 solver.cpp:244]     Train net output #0: loss = 0.795935 (* 1 = 0.795935 loss)
I0818 13:53:51.348958 20702 sgd_solver.cpp:106] Iteration 61400, lr = 0.0001
I0818 13:54:02.034945 20702 solver.cpp:228] Iteration 61500, loss = 0.718694
I0818 13:54:02.035037 20702 solver.cpp:244]     Train net output #0: loss = 0.673996 (* 1 = 0.673996 loss)
I0818 13:54:02.035059 20702 sgd_solver.cpp:106] Iteration 61500, lr = 0.0001
I0818 13:54:12.723161 20702 solver.cpp:228] Iteration 61600, loss = 0.73314
I0818 13:54:12.723234 20702 solver.cpp:244]     Train net output #0: loss = 0.755454 (* 1 = 0.755454 loss)
I0818 13:54:12.723255 20702 sgd_solver.cpp:106] Iteration 61600, lr = 0.0001
I0818 13:54:23.410413 20702 solver.cpp:228] Iteration 61700, loss = 0.72788
I0818 13:54:23.410609 20702 solver.cpp:244]     Train net output #0: loss = 0.644628 (* 1 = 0.644628 loss)
I0818 13:54:23.410632 20702 sgd_solver.cpp:106] Iteration 61700, lr = 0.0001
I0818 13:54:34.086783 20702 solver.cpp:228] Iteration 61800, loss = 0.710556
I0818 13:54:34.086858 20702 solver.cpp:244]     Train net output #0: loss = 0.622396 (* 1 = 0.622396 loss)
I0818 13:54:34.086874 20702 sgd_solver.cpp:106] Iteration 61800, lr = 0.0001
I0818 13:54:44.774186 20702 solver.cpp:228] Iteration 61900, loss = 0.726765
I0818 13:54:44.774241 20702 solver.cpp:244]     Train net output #0: loss = 0.742853 (* 1 = 0.742853 loss)
I0818 13:54:44.774263 20702 sgd_solver.cpp:106] Iteration 61900, lr = 0.0001
I0818 13:54:55.354459 20702 solver.cpp:337] Iteration 62000, Testing net (#0)
I0818 13:54:57.479312 20702 solver.cpp:404]     Test net output #0: loss = 1.17345 (* 1 = 1.17345 loss)
I0818 13:54:57.550240 20702 solver.cpp:228] Iteration 62000, loss = 0.71529
I0818 13:54:57.550282 20702 solver.cpp:244]     Train net output #0: loss = 0.639693 (* 1 = 0.639693 loss)
I0818 13:54:57.550312 20702 sgd_solver.cpp:106] Iteration 62000, lr = 0.0001
I0818 13:55:08.322757 20702 solver.cpp:228] Iteration 62100, loss = 0.725793
I0818 13:55:08.322837 20702 solver.cpp:244]     Train net output #0: loss = 0.767453 (* 1 = 0.767453 loss)
I0818 13:55:08.322860 20702 sgd_solver.cpp:106] Iteration 62100, lr = 0.0001
I0818 13:55:19.103799 20702 solver.cpp:228] Iteration 62200, loss = 0.71945
I0818 13:55:19.103888 20702 solver.cpp:244]     Train net output #0: loss = 0.619627 (* 1 = 0.619627 loss)
I0818 13:55:19.103909 20702 sgd_solver.cpp:106] Iteration 62200, lr = 0.0001
I0818 13:55:29.887135 20702 solver.cpp:228] Iteration 62300, loss = 0.708478
I0818 13:55:29.887313 20702 solver.cpp:244]     Train net output #0: loss = 0.638223 (* 1 = 0.638223 loss)
I0818 13:55:29.887337 20702 sgd_solver.cpp:106] Iteration 62300, lr = 0.0001
I0818 13:55:40.666694 20702 solver.cpp:228] Iteration 62400, loss = 0.720917
I0818 13:55:40.666772 20702 solver.cpp:244]     Train net output #0: loss = 0.71689 (* 1 = 0.71689 loss)
I0818 13:55:40.666793 20702 sgd_solver.cpp:106] Iteration 62400, lr = 0.0001
I0818 13:55:51.463546 20702 solver.cpp:228] Iteration 62500, loss = 0.715337
I0818 13:55:51.463632 20702 solver.cpp:244]     Train net output #0: loss = 0.674542 (* 1 = 0.674542 loss)
I0818 13:55:51.463655 20702 sgd_solver.cpp:106] Iteration 62500, lr = 0.0001
I0818 13:56:02.221122 20702 solver.cpp:228] Iteration 62600, loss = 0.721908
I0818 13:56:02.221316 20702 solver.cpp:244]     Train net output #0: loss = 0.768671 (* 1 = 0.768671 loss)
I0818 13:56:02.221340 20702 sgd_solver.cpp:106] Iteration 62600, lr = 0.0001
I0818 13:56:12.916015 20702 solver.cpp:228] Iteration 62700, loss = 0.715634
I0818 13:56:12.916097 20702 solver.cpp:244]     Train net output #0: loss = 0.657325 (* 1 = 0.657325 loss)
I0818 13:56:12.916119 20702 sgd_solver.cpp:106] Iteration 62700, lr = 0.0001
I0818 13:56:23.612627 20702 solver.cpp:228] Iteration 62800, loss = 0.703495
I0818 13:56:23.612715 20702 solver.cpp:244]     Train net output #0: loss = 0.627188 (* 1 = 0.627188 loss)
I0818 13:56:23.612738 20702 sgd_solver.cpp:106] Iteration 62800, lr = 0.0001
I0818 13:56:34.293638 20702 solver.cpp:228] Iteration 62900, loss = 0.716964
I0818 13:56:34.293817 20702 solver.cpp:244]     Train net output #0: loss = 0.711881 (* 1 = 0.711881 loss)
I0818 13:56:34.293848 20702 sgd_solver.cpp:106] Iteration 62900, lr = 0.0001
I0818 13:56:44.973925 20702 solver.cpp:228] Iteration 63000, loss = 0.708528
I0818 13:56:44.974004 20702 solver.cpp:244]     Train net output #0: loss = 0.69029 (* 1 = 0.69029 loss)
I0818 13:56:44.974023 20702 sgd_solver.cpp:106] Iteration 63000, lr = 0.0001
I0818 13:56:55.654287 20702 solver.cpp:228] Iteration 63100, loss = 0.719891
I0818 13:56:55.654376 20702 solver.cpp:244]     Train net output #0: loss = 0.762698 (* 1 = 0.762698 loss)
I0818 13:56:55.654397 20702 sgd_solver.cpp:106] Iteration 63100, lr = 0.0001
I0818 13:57:06.333902 20702 solver.cpp:228] Iteration 63200, loss = 0.718559
I0818 13:57:06.334067 20702 solver.cpp:244]     Train net output #0: loss = 0.613386 (* 1 = 0.613386 loss)
I0818 13:57:06.334091 20702 sgd_solver.cpp:106] Iteration 63200, lr = 0.0001
I0818 13:57:17.022442 20702 solver.cpp:228] Iteration 63300, loss = 0.701275
I0818 13:57:17.022519 20702 solver.cpp:244]     Train net output #0: loss = 0.636882 (* 1 = 0.636882 loss)
I0818 13:57:17.022542 20702 sgd_solver.cpp:106] Iteration 63300, lr = 0.0001
I0818 13:57:27.710443 20702 solver.cpp:228] Iteration 63400, loss = 0.716431
I0818 13:57:27.710533 20702 solver.cpp:244]     Train net output #0: loss = 0.733395 (* 1 = 0.733395 loss)
I0818 13:57:27.710556 20702 sgd_solver.cpp:106] Iteration 63400, lr = 0.0001
I0818 13:57:38.389690 20702 solver.cpp:228] Iteration 63500, loss = 0.70852
I0818 13:57:38.389868 20702 solver.cpp:244]     Train net output #0: loss = 0.626663 (* 1 = 0.626663 loss)
I0818 13:57:38.389894 20702 sgd_solver.cpp:106] Iteration 63500, lr = 0.0001
I0818 13:57:49.072974 20702 solver.cpp:228] Iteration 63600, loss = 0.71578
I0818 13:57:49.073055 20702 solver.cpp:244]     Train net output #0: loss = 0.751218 (* 1 = 0.751218 loss)
I0818 13:57:49.073076 20702 sgd_solver.cpp:106] Iteration 63600, lr = 0.0001
I0818 13:57:59.770503 20702 solver.cpp:228] Iteration 63700, loss = 0.711684
I0818 13:57:59.770591 20702 solver.cpp:244]     Train net output #0: loss = 0.624292 (* 1 = 0.624292 loss)
I0818 13:57:59.770613 20702 sgd_solver.cpp:106] Iteration 63700, lr = 0.0001
I0818 13:58:10.466986 20702 solver.cpp:228] Iteration 63800, loss = 0.695515
I0818 13:58:10.467130 20702 solver.cpp:244]     Train net output #0: loss = 0.625077 (* 1 = 0.625077 loss)
I0818 13:58:10.467154 20702 sgd_solver.cpp:106] Iteration 63800, lr = 0.0001
I0818 13:58:21.159894 20702 solver.cpp:228] Iteration 63900, loss = 0.714078
I0818 13:58:21.159981 20702 solver.cpp:244]     Train net output #0: loss = 0.709721 (* 1 = 0.709721 loss)
I0818 13:58:21.160003 20702 sgd_solver.cpp:106] Iteration 63900, lr = 0.0001
I0818 13:58:31.726255 20702 solver.cpp:337] Iteration 64000, Testing net (#0)
I0818 13:58:33.851094 20702 solver.cpp:404]     Test net output #0: loss = 1.17759 (* 1 = 1.17759 loss)
I0818 13:58:33.922102 20702 solver.cpp:228] Iteration 64000, loss = 0.7055
I0818 13:58:33.922152 20702 solver.cpp:244]     Train net output #0: loss = 0.667303 (* 1 = 0.667303 loss)
I0818 13:58:33.922174 20702 sgd_solver.cpp:106] Iteration 64000, lr = 0.0001
I0818 13:58:44.617833 20702 solver.cpp:228] Iteration 64100, loss = 0.714802
I0818 13:58:44.618021 20702 solver.cpp:244]     Train net output #0: loss = 0.757903 (* 1 = 0.757903 loss)
I0818 13:58:44.618044 20702 sgd_solver.cpp:106] Iteration 64100, lr = 0.0001
I0818 13:58:55.310770 20702 solver.cpp:228] Iteration 64200, loss = 0.710972
I0818 13:58:55.310861 20702 solver.cpp:244]     Train net output #0: loss = 0.617107 (* 1 = 0.617107 loss)
I0818 13:58:55.310884 20702 sgd_solver.cpp:106] Iteration 64200, lr = 0.0001
I0818 13:59:05.997125 20702 solver.cpp:228] Iteration 64300, loss = 0.694853
I0818 13:59:05.997201 20702 solver.cpp:244]     Train net output #0: loss = 0.637667 (* 1 = 0.637667 loss)
I0818 13:59:05.997223 20702 sgd_solver.cpp:106] Iteration 64300, lr = 0.0001
I0818 13:59:16.687770 20702 solver.cpp:228] Iteration 64400, loss = 0.710072
I0818 13:59:16.687934 20702 solver.cpp:244]     Train net output #0: loss = 0.703054 (* 1 = 0.703054 loss)
I0818 13:59:16.687958 20702 sgd_solver.cpp:106] Iteration 64400, lr = 0.0001
I0818 13:59:27.378775 20702 solver.cpp:228] Iteration 64500, loss = 0.69984
I0818 13:59:27.378862 20702 solver.cpp:244]     Train net output #0: loss = 0.662134 (* 1 = 0.662134 loss)
I0818 13:59:27.378887 20702 sgd_solver.cpp:106] Iteration 64500, lr = 0.0001
I0818 13:59:38.067387 20702 solver.cpp:228] Iteration 64600, loss = 0.713208
I0818 13:59:38.067454 20702 solver.cpp:244]     Train net output #0: loss = 0.747781 (* 1 = 0.747781 loss)
I0818 13:59:38.067476 20702 sgd_solver.cpp:106] Iteration 64600, lr = 0.0001
I0818 13:59:48.754382 20702 solver.cpp:228] Iteration 64700, loss = 0.711099
I0818 13:59:48.754547 20702 solver.cpp:244]     Train net output #0: loss = 0.611721 (* 1 = 0.611721 loss)
I0818 13:59:48.754572 20702 sgd_solver.cpp:106] Iteration 64700, lr = 0.0001
I0818 13:59:59.445317 20702 solver.cpp:228] Iteration 64800, loss = 0.694178
I0818 13:59:59.445406 20702 solver.cpp:244]     Train net output #0: loss = 0.626182 (* 1 = 0.626182 loss)
I0818 13:59:59.445430 20702 sgd_solver.cpp:106] Iteration 64800, lr = 0.0001
I0818 14:00:10.154186 20702 solver.cpp:228] Iteration 64900, loss = 0.71076
I0818 14:00:10.154264 20702 solver.cpp:244]     Train net output #0: loss = 0.719348 (* 1 = 0.719348 loss)
I0818 14:00:10.154287 20702 sgd_solver.cpp:106] Iteration 64900, lr = 0.0001
I0818 14:00:20.859364 20702 solver.cpp:228] Iteration 65000, loss = 0.700684
I0818 14:00:20.859634 20702 solver.cpp:244]     Train net output #0: loss = 0.670254 (* 1 = 0.670254 loss)
I0818 14:00:20.859659 20702 sgd_solver.cpp:46] MultiStep Status: Iteration 65000, step = 2
I0818 14:00:20.859674 20702 sgd_solver.cpp:106] Iteration 65000, lr = 1e-05
I0818 14:00:31.555759 20702 solver.cpp:228] Iteration 65100, loss = 0.711485
I0818 14:00:31.555836 20702 solver.cpp:244]     Train net output #0: loss = 0.751529 (* 1 = 0.751529 loss)
I0818 14:00:31.555860 20702 sgd_solver.cpp:106] Iteration 65100, lr = 1e-05
I0818 14:00:42.243130 20702 solver.cpp:228] Iteration 65200, loss = 0.697512
I0818 14:00:42.243207 20702 solver.cpp:244]     Train net output #0: loss = 0.604764 (* 1 = 0.604764 loss)
I0818 14:00:42.243229 20702 sgd_solver.cpp:106] Iteration 65200, lr = 1e-05
I0818 14:00:52.931763 20702 solver.cpp:228] Iteration 65300, loss = 0.683087
I0818 14:00:52.931910 20702 solver.cpp:244]     Train net output #0: loss = 0.578574 (* 1 = 0.578574 loss)
I0818 14:00:52.931937 20702 sgd_solver.cpp:106] Iteration 65300, lr = 1e-05
I0818 14:01:03.621575 20702 solver.cpp:228] Iteration 65400, loss = 0.700583
I0818 14:01:03.621644 20702 solver.cpp:244]     Train net output #0: loss = 0.704713 (* 1 = 0.704713 loss)
I0818 14:01:03.621665 20702 sgd_solver.cpp:106] Iteration 65400, lr = 1e-05
I0818 14:01:14.309923 20702 solver.cpp:228] Iteration 65500, loss = 0.686563
I0818 14:01:14.310000 20702 solver.cpp:244]     Train net output #0: loss = 0.660781 (* 1 = 0.660781 loss)
I0818 14:01:14.310024 20702 sgd_solver.cpp:106] Iteration 65500, lr = 1e-05
I0818 14:01:25.000813 20702 solver.cpp:228] Iteration 65600, loss = 0.699001
I0818 14:01:25.001027 20702 solver.cpp:244]     Train net output #0: loss = 0.726268 (* 1 = 0.726268 loss)
I0818 14:01:25.001058 20702 sgd_solver.cpp:106] Iteration 65600, lr = 1e-05
I0818 14:01:35.637713 20702 solver.cpp:228] Iteration 65700, loss = 0.698325
I0818 14:01:35.637794 20702 solver.cpp:244]     Train net output #0: loss = 0.602551 (* 1 = 0.602551 loss)
I0818 14:01:35.637818 20702 sgd_solver.cpp:106] Iteration 65700, lr = 1e-05
I0818 14:01:46.311878 20702 solver.cpp:228] Iteration 65800, loss = 0.68286
I0818 14:01:46.311951 20702 solver.cpp:244]     Train net output #0: loss = 0.626396 (* 1 = 0.626396 loss)
I0818 14:01:46.311974 20702 sgd_solver.cpp:106] Iteration 65800, lr = 1e-05
I0818 14:01:56.986191 20702 solver.cpp:228] Iteration 65900, loss = 0.699649
I0818 14:01:56.986424 20702 solver.cpp:244]     Train net output #0: loss = 0.725176 (* 1 = 0.725176 loss)
I0818 14:01:56.986449 20702 sgd_solver.cpp:106] Iteration 65900, lr = 1e-05
I0818 14:02:07.528534 20702 solver.cpp:337] Iteration 66000, Testing net (#0)
I0818 14:02:09.649813 20702 solver.cpp:404]     Test net output #0: loss = 1.16199 (* 1 = 1.16199 loss)
I0818 14:02:09.720528 20702 solver.cpp:228] Iteration 66000, loss = 0.686802
I0818 14:02:09.720578 20702 solver.cpp:244]     Train net output #0: loss = 0.661039 (* 1 = 0.661039 loss)
I0818 14:02:09.720607 20702 sgd_solver.cpp:106] Iteration 66000, lr = 1e-05
I0818 14:02:20.401685 20702 solver.cpp:228] Iteration 66100, loss = 0.696772
I0818 14:02:20.401754 20702 solver.cpp:244]     Train net output #0: loss = 0.720848 (* 1 = 0.720848 loss)
I0818 14:02:20.401777 20702 sgd_solver.cpp:106] Iteration 66100, lr = 1e-05
I0818 14:02:31.091380 20702 solver.cpp:228] Iteration 66200, loss = 0.691766
I0818 14:02:31.091570 20702 solver.cpp:244]     Train net output #0: loss = 0.608087 (* 1 = 0.608087 loss)
I0818 14:02:31.091594 20702 sgd_solver.cpp:106] Iteration 66200, lr = 1e-05
I0818 14:02:41.783179 20702 solver.cpp:228] Iteration 66300, loss = 0.682041
I0818 14:02:41.783259 20702 solver.cpp:244]     Train net output #0: loss = 0.607249 (* 1 = 0.607249 loss)
I0818 14:02:41.783282 20702 sgd_solver.cpp:106] Iteration 66300, lr = 1e-05
I0818 14:02:52.472472 20702 solver.cpp:228] Iteration 66400, loss = 0.698643
I0818 14:02:52.472558 20702 solver.cpp:244]     Train net output #0: loss = 0.688399 (* 1 = 0.688399 loss)
I0818 14:02:52.472579 20702 sgd_solver.cpp:106] Iteration 66400, lr = 1e-05
I0818 14:03:03.161722 20702 solver.cpp:228] Iteration 66500, loss = 0.688944
I0818 14:03:03.161960 20702 solver.cpp:244]     Train net output #0: loss = 0.640417 (* 1 = 0.640417 loss)
I0818 14:03:03.161986 20702 sgd_solver.cpp:106] Iteration 66500, lr = 1e-05
I0818 14:03:13.849169 20702 solver.cpp:228] Iteration 66600, loss = 0.695082
I0818 14:03:13.849238 20702 solver.cpp:244]     Train net output #0: loss = 0.734478 (* 1 = 0.734478 loss)
I0818 14:03:13.849259 20702 sgd_solver.cpp:106] Iteration 66600, lr = 1e-05
I0818 14:03:24.536929 20702 solver.cpp:228] Iteration 66700, loss = 0.69455
I0818 14:03:24.537020 20702 solver.cpp:244]     Train net output #0: loss = 0.592185 (* 1 = 0.592185 loss)
I0818 14:03:24.537044 20702 sgd_solver.cpp:106] Iteration 66700, lr = 1e-05
I0818 14:03:35.225715 20702 solver.cpp:228] Iteration 66800, loss = 0.6811
I0818 14:03:35.225873 20702 solver.cpp:244]     Train net output #0: loss = 0.618665 (* 1 = 0.618665 loss)
I0818 14:03:35.225898 20702 sgd_solver.cpp:106] Iteration 66800, lr = 1e-05
I0818 14:03:45.915326 20702 solver.cpp:228] Iteration 66900, loss = 0.695556
I0818 14:03:45.915403 20702 solver.cpp:244]     Train net output #0: loss = 0.697081 (* 1 = 0.697081 loss)
I0818 14:03:45.915426 20702 sgd_solver.cpp:106] Iteration 66900, lr = 1e-05
I0818 14:03:56.604272 20702 solver.cpp:228] Iteration 67000, loss = 0.687133
I0818 14:03:56.604356 20702 solver.cpp:244]     Train net output #0: loss = 0.656836 (* 1 = 0.656836 loss)
I0818 14:03:56.604377 20702 sgd_solver.cpp:106] Iteration 67000, lr = 1e-05
I0818 14:04:07.292258 20702 solver.cpp:228] Iteration 67100, loss = 0.699989
I0818 14:04:07.292428 20702 solver.cpp:244]     Train net output #0: loss = 0.742967 (* 1 = 0.742967 loss)
I0818 14:04:07.292453 20702 sgd_solver.cpp:106] Iteration 67100, lr = 1e-05
I0818 14:04:17.980556 20702 solver.cpp:228] Iteration 67200, loss = 0.694156
I0818 14:04:17.980638 20702 solver.cpp:244]     Train net output #0: loss = 0.616387 (* 1 = 0.616387 loss)
I0818 14:04:17.980659 20702 sgd_solver.cpp:106] Iteration 67200, lr = 1e-05
I0818 14:04:28.670063 20702 solver.cpp:228] Iteration 67300, loss = 0.681933
I0818 14:04:28.670145 20702 solver.cpp:244]     Train net output #0: loss = 0.586781 (* 1 = 0.586781 loss)
I0818 14:04:28.670168 20702 sgd_solver.cpp:106] Iteration 67300, lr = 1e-05
I0818 14:04:39.359717 20702 solver.cpp:228] Iteration 67400, loss = 0.695203
I0818 14:04:39.359833 20702 solver.cpp:244]     Train net output #0: loss = 0.726177 (* 1 = 0.726177 loss)
I0818 14:04:39.359856 20702 sgd_solver.cpp:106] Iteration 67400, lr = 1e-05
I0818 14:04:50.048001 20702 solver.cpp:228] Iteration 67500, loss = 0.685122
I0818 14:04:50.048077 20702 solver.cpp:244]     Train net output #0: loss = 0.63997 (* 1 = 0.63997 loss)
I0818 14:04:50.048100 20702 sgd_solver.cpp:106] Iteration 67500, lr = 1e-05
I0818 14:05:00.737979 20702 solver.cpp:228] Iteration 67600, loss = 0.695074
I0818 14:05:00.738054 20702 solver.cpp:244]     Train net output #0: loss = 0.740175 (* 1 = 0.740175 loss)
I0818 14:05:00.738077 20702 sgd_solver.cpp:106] Iteration 67600, lr = 1e-05
I0818 14:05:11.436866 20702 solver.cpp:228] Iteration 67700, loss = 0.690733
I0818 14:05:11.437135 20702 solver.cpp:244]     Train net output #0: loss = 0.626176 (* 1 = 0.626176 loss)
I0818 14:05:11.437170 20702 sgd_solver.cpp:106] Iteration 67700, lr = 1e-05
I0818 14:05:22.073282 20702 solver.cpp:228] Iteration 67800, loss = 0.681276
I0818 14:05:22.073370 20702 solver.cpp:244]     Train net output #0: loss = 0.62862 (* 1 = 0.62862 loss)
I0818 14:05:22.073392 20702 sgd_solver.cpp:106] Iteration 67800, lr = 1e-05
I0818 14:05:32.748273 20702 solver.cpp:228] Iteration 67900, loss = 0.69681
I0818 14:05:32.748348 20702 solver.cpp:244]     Train net output #0: loss = 0.692093 (* 1 = 0.692093 loss)
I0818 14:05:32.748371 20702 sgd_solver.cpp:106] Iteration 67900, lr = 1e-05
I0818 14:05:43.329644 20702 solver.cpp:337] Iteration 68000, Testing net (#0)
I0818 14:05:45.452894 20702 solver.cpp:404]     Test net output #0: loss = 1.16094 (* 1 = 1.16094 loss)
I0818 14:05:45.523798 20702 solver.cpp:228] Iteration 68000, loss = 0.687319
I0818 14:05:45.523849 20702 solver.cpp:244]     Train net output #0: loss = 0.673259 (* 1 = 0.673259 loss)
I0818 14:05:45.523870 20702 sgd_solver.cpp:106] Iteration 68000, lr = 1e-05
I0818 14:05:56.211900 20702 solver.cpp:228] Iteration 68100, loss = 0.695181
I0818 14:05:56.211982 20702 solver.cpp:244]     Train net output #0: loss = 0.762258 (* 1 = 0.762258 loss)
I0818 14:05:56.212004 20702 sgd_solver.cpp:106] Iteration 68100, lr = 1e-05
I0818 14:06:06.901610 20702 solver.cpp:228] Iteration 68200, loss = 0.694293
I0818 14:06:06.901701 20702 solver.cpp:244]     Train net output #0: loss = 0.600879 (* 1 = 0.600879 loss)
I0818 14:06:06.901724 20702 sgd_solver.cpp:106] Iteration 68200, lr = 1e-05
I0818 14:06:17.588845 20702 solver.cpp:228] Iteration 68300, loss = 0.679566
I0818 14:06:17.589123 20702 solver.cpp:244]     Train net output #0: loss = 0.603089 (* 1 = 0.603089 loss)
I0818 14:06:17.589154 20702 sgd_solver.cpp:106] Iteration 68300, lr = 1e-05
I0818 14:06:28.215725 20702 solver.cpp:228] Iteration 68400, loss = 0.69375
I0818 14:06:28.215775 20702 solver.cpp:244]     Train net output #0: loss = 0.690523 (* 1 = 0.690523 loss)
I0818 14:06:28.215803 20702 sgd_solver.cpp:106] Iteration 68400, lr = 1e-05
I0818 14:06:38.899202 20702 solver.cpp:228] Iteration 68500, loss = 0.688141
I0818 14:06:38.899269 20702 solver.cpp:244]     Train net output #0: loss = 0.6534 (* 1 = 0.6534 loss)
I0818 14:06:38.899284 20702 sgd_solver.cpp:106] Iteration 68500, lr = 1e-05
I0818 14:06:49.565183 20702 solver.cpp:228] Iteration 68600, loss = 0.69686
I0818 14:06:49.565387 20702 solver.cpp:244]     Train net output #0: loss = 0.693774 (* 1 = 0.693774 loss)
I0818 14:06:49.565423 20702 sgd_solver.cpp:106] Iteration 68600, lr = 1e-05
I0818 14:07:00.251785 20702 solver.cpp:228] Iteration 68700, loss = 0.692777
I0818 14:07:00.251888 20702 solver.cpp:244]     Train net output #0: loss = 0.59671 (* 1 = 0.59671 loss)
I0818 14:07:00.251914 20702 sgd_solver.cpp:106] Iteration 68700, lr = 1e-05
I0818 14:07:10.941079 20702 solver.cpp:228] Iteration 68800, loss = 0.677562
I0818 14:07:10.941160 20702 solver.cpp:244]     Train net output #0: loss = 0.602243 (* 1 = 0.602243 loss)
I0818 14:07:10.941184 20702 sgd_solver.cpp:106] Iteration 68800, lr = 1e-05
I0818 14:07:21.628654 20702 solver.cpp:228] Iteration 68900, loss = 0.696487
I0818 14:07:21.628854 20702 solver.cpp:244]     Train net output #0: loss = 0.699645 (* 1 = 0.699645 loss)
I0818 14:07:21.628885 20702 sgd_solver.cpp:106] Iteration 68900, lr = 1e-05
I0818 14:07:32.317808 20702 solver.cpp:228] Iteration 69000, loss = 0.68628
I0818 14:07:32.317898 20702 solver.cpp:244]     Train net output #0: loss = 0.652273 (* 1 = 0.652273 loss)
I0818 14:07:32.317921 20702 sgd_solver.cpp:106] Iteration 69000, lr = 1e-05
I0818 14:07:43.000119 20702 solver.cpp:228] Iteration 69100, loss = 0.6967
I0818 14:07:43.000200 20702 solver.cpp:244]     Train net output #0: loss = 0.740937 (* 1 = 0.740937 loss)
I0818 14:07:43.000221 20702 sgd_solver.cpp:106] Iteration 69100, lr = 1e-05
I0818 14:07:53.681123 20702 solver.cpp:228] Iteration 69200, loss = 0.691226
I0818 14:07:53.681296 20702 solver.cpp:244]     Train net output #0: loss = 0.597812 (* 1 = 0.597812 loss)
I0818 14:07:53.681324 20702 sgd_solver.cpp:106] Iteration 69200, lr = 1e-05
I0818 14:08:04.366300 20702 solver.cpp:228] Iteration 69300, loss = 0.67924
I0818 14:08:04.366379 20702 solver.cpp:244]     Train net output #0: loss = 0.591897 (* 1 = 0.591897 loss)
I0818 14:08:04.366400 20702 sgd_solver.cpp:106] Iteration 69300, lr = 1e-05
I0818 14:08:15.054162 20702 solver.cpp:228] Iteration 69400, loss = 0.690659
I0818 14:08:15.054239 20702 solver.cpp:244]     Train net output #0: loss = 0.685495 (* 1 = 0.685495 loss)
I0818 14:08:15.054262 20702 sgd_solver.cpp:106] Iteration 69400, lr = 1e-05
I0818 14:08:25.743005 20702 solver.cpp:228] Iteration 69500, loss = 0.685953
I0818 14:08:25.743249 20702 solver.cpp:244]     Train net output #0: loss = 0.671441 (* 1 = 0.671441 loss)
I0818 14:08:25.743275 20702 sgd_solver.cpp:106] Iteration 69500, lr = 1e-05
I0818 14:08:36.429841 20702 solver.cpp:228] Iteration 69600, loss = 0.694244
I0818 14:08:36.429919 20702 solver.cpp:244]     Train net output #0: loss = 0.720429 (* 1 = 0.720429 loss)
I0818 14:08:36.429941 20702 sgd_solver.cpp:106] Iteration 69600, lr = 1e-05
I0818 14:08:47.116425 20702 solver.cpp:228] Iteration 69700, loss = 0.692529
I0818 14:08:47.116502 20702 solver.cpp:244]     Train net output #0: loss = 0.593154 (* 1 = 0.593154 loss)
I0818 14:08:47.116523 20702 sgd_solver.cpp:106] Iteration 69700, lr = 1e-05
I0818 14:08:57.805380 20702 solver.cpp:228] Iteration 69800, loss = 0.680582
I0818 14:08:57.805558 20702 solver.cpp:244]     Train net output #0: loss = 0.597282 (* 1 = 0.597282 loss)
I0818 14:08:57.805585 20702 sgd_solver.cpp:106] Iteration 69800, lr = 1e-05
I0818 14:09:08.493711 20702 solver.cpp:228] Iteration 69900, loss = 0.694124
I0818 14:09:08.493785 20702 solver.cpp:244]     Train net output #0: loss = 0.741211 (* 1 = 0.741211 loss)
I0818 14:09:08.493808 20702 sgd_solver.cpp:106] Iteration 69900, lr = 1e-05
I0818 14:09:19.075237 20702 solver.cpp:454] Snapshotting to binary proto file CIFAR-10/cifar10_iter_70000.caffemodel
I0818 14:09:19.123479 20702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file CIFAR-10/cifar10_iter_70000.solverstate
I0818 14:09:19.171263 20702 solver.cpp:317] Iteration 70000, loss = 0.687712
I0818 14:09:19.171308 20702 solver.cpp:337] Iteration 70000, Testing net (#0)
I0818 14:09:21.262158 20702 solver.cpp:404]     Test net output #0: loss = 1.15902 (* 1 = 1.15902 loss)
I0818 14:09:21.262217 20702 solver.cpp:322] Optimization Done.
I0818 14:09:21.262233 20702 caffe.cpp:222] Optimization Done.
